{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khushidubeyokok/BERTopic/blob/main/Copy_of_BERTopic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IczTdrR2Li7w"
      },
      "source": [
        "# Research Paper Topic Modeling with BERTopic (neuralwork/arxiver)\n",
        "\n",
        "In this notebook, we apply BERTopic to the **[neuralwork/arxiver](https://huggingface.co/datasets/neuralwork/arxiver)** dataset from Hugging Face. This dataset includes abstracts from various research papers, ideal for identifying scientific themes through topic modeling.\n",
        "\n",
        "## Steps Covered in This Notebook\n",
        "1. **Load and Explore Dataset**: Inspect the data structure and content.\n",
        "2. **Preprocess Text**: Clean abstracts for analysis.\n",
        "3. **Apply BERTopic**: Generate and interpret topic clusters.\n",
        "4. **Visualize Findings**: Plot and analyze topic distributions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cyi6ydpmLxhf"
      },
      "source": [
        "## Load and Explore Dataset\n",
        "\n",
        "In this section, we load the **neuralwork/arxiver** dataset and examine its structure to better understand what content is available for topic modeling.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "LqhrAtzeLgcP"
      },
      "outputs": [],
      "source": [
        "#Install Required Libraries\n",
        "!pip -q install datasets\n",
        "!pip -q install bertopic\n",
        "!pip -q install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gv9yeag8RgQ5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Z9BhO9QgMcMT"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"neuralwork/arxiver\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "08U6T1kISYLx",
        "outputId": "775abdba-dd1e-4b56-cc4c-1f8fe226c93d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               id                                              title  \\\n",
              "0      2305.00379  Image Completion via Dual-path Cooperative Fil...   \n",
              "1      2307.16362  High Sensitivity Beamformed Observations of th...   \n",
              "2      2301.07687  Maybe, Maybe Not: A Survey on Uncertainty in V...   \n",
              "3      2309.09088  Enhancing GAN-Based Vocoders with Contrastive ...   \n",
              "4      2307.16404      Nonvolatile Magneto-Thermal Switching in MgB2   \n",
              "...           ...                                                ...   \n",
              "63352  2306.06241                      Almost paratopological groups   \n",
              "63353  2301.12293  ACL-Fig: A Dataset for Scientific Figure Class...   \n",
              "63354  2303.04288  Polynomial Time and Private Learning of Unboun...   \n",
              "63355  2308.11291  Improving Knot Prediction in Wood Logs with Lo...   \n",
              "63356  2310.02919  Attention-based Multi-task Learning for Base E...   \n",
              "\n",
              "                                                abstract  \\\n",
              "0      Given the recent advances with image-generatin...   \n",
              "1      We analyzed four epochs of beamformed EVN data...   \n",
              "2      Understanding and evaluating uncertainty play ...   \n",
              "3      Vocoder models have recently achieved substant...   \n",
              "4      Ongoing research explores thermal switching ma...   \n",
              "...                                                  ...   \n",
              "63352  A class of almost paratopological groups is in...   \n",
              "63353  Most existing large-scale academic search engi...   \n",
              "63354  We study the problem of privately estimating t...   \n",
              "63355  The quality of a wood log in the wood industry...   \n",
              "63356  Human genetic diseases often arise from point ...   \n",
              "\n",
              "                                                 authors  \\\n",
              "0      Pourya Shamsolmoali, Masoumeh Zareapoor, Eric ...   \n",
              "1                    Rebecca Lin, Marten H. van Kerkwijk   \n",
              "2                                           Krisha Mehta   \n",
              "3      Haoming Guo, Seth Z. Zhao, Jiachen Lian, Gopal...   \n",
              "4                      Hiroto Arima, Yoshikazu Mizuguchi   \n",
              "...                                                  ...   \n",
              "63352                                Evgenii Reznichenko   \n",
              "63353  Zeba Karishma, Shaurya Rohatgi, Kavya Shriniva...   \n",
              "63354     Jamil Arbas, Hassan Ashtiani, Christopher Liaw   \n",
              "63355         Salim Khazem, Jeremy Fix, CÃ©dric Pradalier   \n",
              "63356   Amina Mollaysa, Ahmed Allam, Michael Krauthammer   \n",
              "\n",
              "             published_date                               link  \\\n",
              "0      2023-04-30T03:54:53Z  http://arxiv.org/abs/2305.00379v1   \n",
              "1      2023-07-31T01:36:55Z  http://arxiv.org/abs/2307.16362v2   \n",
              "2      2022-12-14T00:07:06Z  http://arxiv.org/abs/2301.07687v1   \n",
              "3      2023-09-16T20:04:16Z  http://arxiv.org/abs/2309.09088v2   \n",
              "4      2023-07-31T04:59:19Z  http://arxiv.org/abs/2307.16404v1   \n",
              "...                     ...                                ...   \n",
              "63352  2023-06-09T20:27:33Z  http://arxiv.org/abs/2306.06241v2   \n",
              "63353  2023-01-28T20:27:35Z  http://arxiv.org/abs/2301.12293v1   \n",
              "63354  2023-03-07T23:24:27Z  http://arxiv.org/abs/2303.04288v2   \n",
              "63355  2023-08-22T09:12:11Z  http://arxiv.org/abs/2308.11291v1   \n",
              "63356  2023-10-04T16:01:06Z  http://arxiv.org/abs/2310.02919v2   \n",
              "\n",
              "                                                markdown  \n",
              "0      # Image Completion via Dual-Path Cooperative F...  \n",
              "1      # High Sensitivity Beamformed Observations of ...  \n",
              "2      # Maybe, Maybe Not: A Survey on Uncertainty in...  \n",
              "3      # Enhancing Gan-Based Vocoders with Contrastiv...  \n",
              "4      # Nonvolatile Magneto-Thermal Switching in MgB...  \n",
              "...                                                  ...  \n",
              "63352  # Almost paratopological groups\\n\\n###### Abst...  \n",
              "63353  # ACL-Fig: A Dataset for Scientific Figure Cla...  \n",
              "63354  # Polynomial Time and Private Learning of Unbo...  \n",
              "63355  # Improving Knot Prediction in Wood Logs with ...  \n",
              "63356  # Attention-based Multi-task Learning for Base...  \n",
              "\n",
              "[63357 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e2f01ff5-c774-48d8-b6ec-dee466d0b4b7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>authors</th>\n",
              "      <th>published_date</th>\n",
              "      <th>link</th>\n",
              "      <th>markdown</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2305.00379</td>\n",
              "      <td>Image Completion via Dual-path Cooperative Fil...</td>\n",
              "      <td>Given the recent advances with image-generatin...</td>\n",
              "      <td>Pourya Shamsolmoali, Masoumeh Zareapoor, Eric ...</td>\n",
              "      <td>2023-04-30T03:54:53Z</td>\n",
              "      <td>http://arxiv.org/abs/2305.00379v1</td>\n",
              "      <td># Image Completion via Dual-Path Cooperative F...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2307.16362</td>\n",
              "      <td>High Sensitivity Beamformed Observations of th...</td>\n",
              "      <td>We analyzed four epochs of beamformed EVN data...</td>\n",
              "      <td>Rebecca Lin, Marten H. van Kerkwijk</td>\n",
              "      <td>2023-07-31T01:36:55Z</td>\n",
              "      <td>http://arxiv.org/abs/2307.16362v2</td>\n",
              "      <td># High Sensitivity Beamformed Observations of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2301.07687</td>\n",
              "      <td>Maybe, Maybe Not: A Survey on Uncertainty in V...</td>\n",
              "      <td>Understanding and evaluating uncertainty play ...</td>\n",
              "      <td>Krisha Mehta</td>\n",
              "      <td>2022-12-14T00:07:06Z</td>\n",
              "      <td>http://arxiv.org/abs/2301.07687v1</td>\n",
              "      <td># Maybe, Maybe Not: A Survey on Uncertainty in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2309.09088</td>\n",
              "      <td>Enhancing GAN-Based Vocoders with Contrastive ...</td>\n",
              "      <td>Vocoder models have recently achieved substant...</td>\n",
              "      <td>Haoming Guo, Seth Z. Zhao, Jiachen Lian, Gopal...</td>\n",
              "      <td>2023-09-16T20:04:16Z</td>\n",
              "      <td>http://arxiv.org/abs/2309.09088v2</td>\n",
              "      <td># Enhancing Gan-Based Vocoders with Contrastiv...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2307.16404</td>\n",
              "      <td>Nonvolatile Magneto-Thermal Switching in MgB2</td>\n",
              "      <td>Ongoing research explores thermal switching ma...</td>\n",
              "      <td>Hiroto Arima, Yoshikazu Mizuguchi</td>\n",
              "      <td>2023-07-31T04:59:19Z</td>\n",
              "      <td>http://arxiv.org/abs/2307.16404v1</td>\n",
              "      <td># Nonvolatile Magneto-Thermal Switching in MgB...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63352</th>\n",
              "      <td>2306.06241</td>\n",
              "      <td>Almost paratopological groups</td>\n",
              "      <td>A class of almost paratopological groups is in...</td>\n",
              "      <td>Evgenii Reznichenko</td>\n",
              "      <td>2023-06-09T20:27:33Z</td>\n",
              "      <td>http://arxiv.org/abs/2306.06241v2</td>\n",
              "      <td># Almost paratopological groups\\n\\n###### Abst...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63353</th>\n",
              "      <td>2301.12293</td>\n",
              "      <td>ACL-Fig: A Dataset for Scientific Figure Class...</td>\n",
              "      <td>Most existing large-scale academic search engi...</td>\n",
              "      <td>Zeba Karishma, Shaurya Rohatgi, Kavya Shriniva...</td>\n",
              "      <td>2023-01-28T20:27:35Z</td>\n",
              "      <td>http://arxiv.org/abs/2301.12293v1</td>\n",
              "      <td># ACL-Fig: A Dataset for Scientific Figure Cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63354</th>\n",
              "      <td>2303.04288</td>\n",
              "      <td>Polynomial Time and Private Learning of Unboun...</td>\n",
              "      <td>We study the problem of privately estimating t...</td>\n",
              "      <td>Jamil Arbas, Hassan Ashtiani, Christopher Liaw</td>\n",
              "      <td>2023-03-07T23:24:27Z</td>\n",
              "      <td>http://arxiv.org/abs/2303.04288v2</td>\n",
              "      <td># Polynomial Time and Private Learning of Unbo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63355</th>\n",
              "      <td>2308.11291</td>\n",
              "      <td>Improving Knot Prediction in Wood Logs with Lo...</td>\n",
              "      <td>The quality of a wood log in the wood industry...</td>\n",
              "      <td>Salim Khazem, Jeremy Fix, CÃ©dric Pradalier</td>\n",
              "      <td>2023-08-22T09:12:11Z</td>\n",
              "      <td>http://arxiv.org/abs/2308.11291v1</td>\n",
              "      <td># Improving Knot Prediction in Wood Logs with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63356</th>\n",
              "      <td>2310.02919</td>\n",
              "      <td>Attention-based Multi-task Learning for Base E...</td>\n",
              "      <td>Human genetic diseases often arise from point ...</td>\n",
              "      <td>Amina Mollaysa, Ahmed Allam, Michael Krauthammer</td>\n",
              "      <td>2023-10-04T16:01:06Z</td>\n",
              "      <td>http://arxiv.org/abs/2310.02919v2</td>\n",
              "      <td># Attention-based Multi-task Learning for Base...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63357 rows Ã 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2f01ff5-c774-48d8-b6ec-dee466d0b4b7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e2f01ff5-c774-48d8-b6ec-dee466d0b4b7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e2f01ff5-c774-48d8-b6ec-dee466d0b4b7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-10512e01-f1cd-48f3-b0c9-d29980fde1e1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-10512e01-f1cd-48f3-b0c9-d29980fde1e1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-10512e01-f1cd-48f3-b0c9-d29980fde1e1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9aa666e3-4a7a-4360-9a1c-16107be3c937\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9aa666e3-4a7a-4360-9a1c-16107be3c937 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 63357,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63357,\n        \"samples\": [\n          \"2307.06084\",\n          \"2306.00011\",\n          \"2307.07378\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63348,\n        \"samples\": [\n          \"Approximation-free control for unknown systems with performance and\\n  input constraints\",\n          \"A complex-scaled boundary integral equation for time-harmonic water\\n  waves\",\n          \"Zephyr : Stitching Heterogeneous Training Data with Normalizing Flows\\n  for Photometric Redshift Inference\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63355,\n        \"samples\": [\n          \"In this study, we investigate a cosmological model involving a negative\\ncosmological constant (AdS vacua in the dark energy sector). We consider a\\nquintessence field on top of a negative cosmological constant and study its\\nimpact on cosmological evolution and structure formation. We use the power\\nspectrum of the redshifted HI 21 cm brightness temperature maps from the\\npost-reionization epoch as a cosmological probe. The signature of baryon\\nacoustic oscillations (BAO) on the multipoles of the power spectrum is used to\\nextract measurements of the angular diameter distance $D_A(z)$ and the Hubble\\nparameter $H(z)$. The projected errors on these are then subsequently employed\\nto forecast the constraints on the model parameters ($\\\\Omega_\\\\Lambda, w_0,\\nw_a$) using Markov Chain Monte Carlo techniques. We find that a negative\\ncosmological constant with a phantom dark energy equation of state (EoS) and a\\nhigher value of $H_0$ is viable from BAO distance measurements data derived\\nfrom galaxy samples. We also find that BAO imprints on the 21cm power spectrum\\nobtained from a futuristic SKA-mid like experiment yield a $1-\\\\sigma$ error on\\na negative cosmological constant and the quintessence dark energy EoS\\nparameters to be $\\\\Omega_\\\\Lambda=-1.030^{0.589}_{-1.712}$ and\\n$w_0=-1.023^{0.043}_{-0.060}$, $w_a=-0.141^{0.478}_{-0.409}$ respectively.\",\n          \"Estimating the number of clusters and cluster structures in unlabeled,\\ncomplex, and high-dimensional datasets (like images) is challenging for\\ntraditional clustering algorithms. In recent years, a matrix reordering-based\\nalgorithm called Visual Assessment of Tendency (VAT), and its variants have\\nattracted many researchers from various domains to estimate the number of\\nclusters and inherent cluster structure present in the data. However, these\\nalgorithms face significant challenges when dealing with image data as they\\nfail to effectively capture the crucial features inherent in images. To\\novercome these limitations, we propose a deep-learning-based framework that\\nenables the assessment of cluster structure in complex image datasets. Our\\napproach utilizes a self-supervised deep neural network to generate\\nrepresentative embeddings for the data. These embeddings are then reduced to\\n2-dimension using t-distributed Stochastic Neighbour Embedding (t-SNE) and\\ninputted into VAT based algorithms to estimate the underlying cluster\\nstructure. Importantly, our framework does not rely on any prior knowledge of\\nthe number of clusters. Our proposed approach demonstrates superior performance\\ncompared to state-of-the-art VAT family algorithms and two other deep\\nclustering algorithms on four benchmark image datasets, namely MNIST, FMNIST,\\nCIFAR-10, and INTEL.\",\n          \"The development of computer vision and in-situ monitoring using visual\\nsensors allows the collection of large datasets from the additive manufacturing\\n(AM) process. Such datasets could be used with machine learning techniques to\\nimprove the quality of AM. This paper examines two scenarios: first, using\\nconvolutional neural networks (CNNs) to accurately classify defects in an image\\ndataset from AM and second, applying active learning techniques to the\\ndeveloped classification model. This allows the construction of a\\nhuman-in-the-loop mechanism to reduce the size of the data required to train\\nand generate training data.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60349,\n        \"samples\": [\n          \"Ken Trotti\",\n          \"Andrei O. Barvinsky, Nikita Kolganov\",\n          \"Shuai Jiang, Sayaka Kamei, Chen Li, Shengzhe Hou, Yasuhiko Morimoto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"published_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 62864,\n        \"samples\": [\n          \"2023-05-29T03:51:18Z\",\n          \"2023-10-24T18:55:32Z\",\n          \"2023-04-06T21:22:27Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63357,\n        \"samples\": [\n          \"http://arxiv.org/abs/2307.06084v1\",\n          \"http://arxiv.org/abs/2306.00011v2\",\n          \"http://arxiv.org/abs/2307.07378v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"markdown\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63357,\n        \"samples\": [\n          \"# Neuromorphic analog circuits for robust on-chip always-on learning in spiking neural networks\\n\\n###### Abstract\\n\\nMixed-signal neuromorphic systems represent a promising solution for solving extreme-edge computing tasks without relying on external computing resources. Their spiking neural network circuits are optimized for processing sensory data on-line in continuous-time. However, their low precision and high variability can severely limit their performance. To address this issue and improve their robustness to inhomogeneities and noise in both their internal state variables and external input signals, we designed on-chip learning circuits with short-term analog dynamics and long-term tristate discretization mechanisms. An additional hysteretic stop-learning mechanism is included to improve stability and automatically disable weight updates when necessary, to enable continuous always-on learning. We designed a spiking neural network with these learning circuits in a prototype chip using a \\\\(180\\\\,\\\\mathrm{nm}\\\\) CMOS technology. Simulation and silicon measurement results from the prototype chip are presented. These circuits enable the construction of large-scale spiking neural networks with online learning capabilities for real-world edge computing tasks.\\n\\n always-on learning, edge-computing, on-chip learning online, SNN, hysteresis, tristability.\\n\\n## I Introduction\\n\\nThe requirements of artificial intelligence (AI) systems operating at the edge are similar to those that living organisms face to function in daily life. They need to measure sensory signals in real-time, perform closed-loop interactions with their surroundings, be energy-efficient, and continuously adapt to changes in the environment and in their own internal state. These requisites are well supported by neuromorphic systems and emerging memory technologies that implement brain-inspired mixed-signal spiking neural network (SNN) architectures [1, 2, 3, 4, 5]. These types of SNNs operate in a data-driven manner, with an event-based representation that is typically sparse in both space and time. Since they compute only when data is present, they are very power efficient. Similar to the biological neural systems they model, these SNNs are particularly well-suited to processing real-world signals. They can be designed to operate at the same data-rate of the input streams in real-time by matching the time constants of neural computation with those of the incoming signal dynamics. However, similar to their biological counterparts, these systems are affected by a high degree of variability and sensitivity to noise. One of the most effective strategies that biology uses to cope with noise and variability is to utilize adaptation and plasticity. This strategy has also been adopted by the neuromorphic community: several on-chip implementations of spike-based learning circuits have been proposed in the past [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]. However, few have addressed the problem of being able to operate robustly and autonomously in continuous time, with the ability to switch automatically and reliably between learning and inference modes. Following the original neuromorphic engineering approach [18], we propose a set of analog circuits that faithfully emulate synaptic plasticity mechanisms observed in pyramidal cells of cortical circuits and implement complex spike-based learning and state-dependent mechanisms that support this functionality. In addition, we extend the concept of long-term bi-stability of synaptic weights, proposed to increase robustness to noise and variability in the input signals [14, 19], to a tristate stability and weight discretization circuit that increases the resolution of the (stable and crystallized) synaptic weights. The synaptic plasticity circuits update an internal state variable of the synapse on every pre-synaptic input spike. The change in this state variable is computed in continuous time by the soma block of the neuron. In parallel, depending on its value, the internal variable is driven to one of three possible stable states and converted to a discrete three-state synaptic weight current value. The post-synaptic learning circuits comprise an additional mechanism that gates\\n\\nFig. 1: Micrograph of the prototype chip comprising of the learning circuits in a network of 4 neurons with 64 synapses each (see highlighted area). The chip, comprising of additional test structures, measures \\\\(3\\\\times 5\\\\,\\\\mathrm{mm}^{2}\\\\).\\nthe weight changes, to stop the learning process when the neuron's mean firing rate is outside a defined learning window. The circuits were fabricated on a prototype SNN chip designed in a 180 nm 6M1P CMOS technology and tested within a network of 4 neurons with 64 synapses each (see Fig. 1). In the following sections we describe the main building blocks used at both the synapse and neuron level, demonstrate their expected behavior with circuit simulations, and provide experimental results measured from the chip.\\n\\n## II Network architecture\\n\\nThe block diagram of each neuron in the network is shown in Fig. 2. Input digital events (\\\\(\\\\mathsf{x_{0-N}}\\\\)) arrive at the individual synapses via asynchronous logic [2] and trigger local weight update circuits to induce a change in the voltage stored on a local capacitor by an amount determined by the post-synaptic learning circuits. In parallel, a tristate stability circuit drives this internal voltage to one of three possible stable states. This local internal voltage is then discretized and converted to a low, intermediate or high current value. All currents produced by all synapses are summed spatially and conveyed to a differential pair integrator (DPI), which integrates the weighted sum over time [20]. A parallel and analogous pathway receives input events representing a desired target signal (\\\\(\\\\mathsf{x_{t}}\\\\)), and produces a corresponding current from its dedicated DPI circuit. The target and input currents are both summed to drive the neuron's postsynaptic Integrate & Fire (I&F) circuit [21], and subtracted to drive the soma's Delta rule circuit [22]. The Delta rule circuit produces either positive or negative weight update signals proportional to the difference between the target input and the weighted synaptic input. These signals are broadcast to all the neuron's input synapses in continuous time if learning is enabled. Learning is enabled (or disabled) by means of two hysteretic Winner-Take-All (hWTA) circuits [23] that compare the neuron's mean output firing rate to a low and a high threshold (see Section III-B for details).\\n\\n## III Circuits\\n\\nAs the details of the Delta rule and I&F circuits have already been presented [11, 21, 22], we describe the synapse learning circuits and the soma hWTA circuit.\\n\\n### _Plastic synapse circuit_\\n\\nFigure 3 presents all of the learning circuits used at the synaptic level. With every pre-synaptic spike, the weight update circuit (Fig. 2(a)) increases or decreases the internal analog weight variable \\\\(\\\\mathsf{V_{w}}\\\\) by an amount determined by the voltages \\\\(\\\\mathsf{V_{UP}}\\\\) and \\\\(\\\\mathsf{V_{DN}}\\\\), produced by the post-synaptic Delta rule circuits. The tri-stability supply voltage circuit (Fig. 2(b)), produces the biases that power either of the positive feedback amplifiers of Fig. 2(c), depending on the state of \\\\(\\\\mathsf{V_{w}}\\\\) with respect to \\\\(\\\\mathsf{V_{dd}}/2\\\\). The tri-stability circuit (Fig. 2(c)) consists of two slew-rate limited positive feedback amplifiers which slowly drive \\\\(\\\\mathsf{V_{w}}\\\\) towards ground, \\\\(\\\\mathsf{V_{dd}}/2\\\\), or \\\\(\\\\mathsf{V_{dd}}\\\\) depending on the value of \\\\(\\\\mathsf{V_{w}}\\\\) relative\\n\\nFig. 3: Synapse learning circuits. (a) The weight update circuit increases or decreases the internal analog weight variable \\\\(\\\\mathsf{V_{w}}\\\\) with every input spike \\\\(\\\\mathsf{V_{PRE}}\\\\); (b) The tri-stability supply voltage circuit determines which of the two amplifiers in (c) to power depending on the value of \\\\(\\\\mathsf{V_{w}}\\\\) with respect to \\\\(\\\\mathsf{V_{dd}}/2\\\\) by activating either \\\\(\\\\mathsf{V_{DH}}\\\\) or \\\\(\\\\mathsf{V_{DL}}\\\\). (c) The tristability circuit drives the \\\\(\\\\mathsf{V_{w}}\\\\) voltage towards ground, \\\\(\\\\mathsf{V_{dd}}/2\\\\) or \\\\(\\\\mathsf{V_{dd}}\\\\) depending on its value relative to \\\\(\\\\mathsf{V_{THH}}\\\\) and \\\\(\\\\mathsf{V_{THL}}\\\\). (d) The current discretization circuit converts \\\\(\\\\mathsf{V_{w}}\\\\) into a low (the leakage current \\\\(\\\\mathsf{I_{0}}\\\\)), intermediate, or high current.\\n\\nFig. 2: Block diagram of a single neuron row. The plastic synapses (in red) consist of input logic, a weight update, tristate stability, and a current ADC block. Input spikes arriving at a synapse update the internal weight variable \\\\(\\\\mathsf{V_{w}}\\\\), and change it by an amount that is determined by the post-synaptic learning circuits at the soma (in green). The weight voltage is slowly driven to one of three possible stable states, and converted into a synaptic current by thresholding circuits. A parallel pathway provides a target current (in blue). Both input and target currents are integrated over time by differential pair integrator (DPI) circuits. The soma (in green), comprises of an Integrate & Fire (I&F) block which integrates the sum of target and input currents, a Delta rule block that calculates the difference of the two DPI currents to determine the amplitude of the weight change, and a hysteretic Winner-Take-All (hWTA) block used to determine if and when to \\u201cstop-learning\\u201d.\\nto \\\\(\\\\mathsf{V_{THH}}\\\\) and \\\\(\\\\mathsf{V_{THL}}\\\\). The weight discretization circuit (Fig. (d)d) sets the value of the effective synaptic current \\\\(\\\\mathsf{l_{w}}\\\\) to \\\\(\\\\mathsf{l_{0}}\\\\), \\\\(\\\\mathsf{l_{wb}}\\\\), or \\\\(2\\\\mathsf{l_{wb}}\\\\) depending on the state of \\\\(\\\\mathsf{V_{w}}\\\\) with respect to \\\\(\\\\mathsf{V_{THL}}\\\\) and \\\\(\\\\mathsf{V_{THH}}\\\\).\\n\\n### _Hysteretic WTA for \\\"stop-learning\\\"_\\n\\nFigure 4 shows an instance of a hWTA circuit: it consists of two identical cells, (\\\\(M_{2}\\\\)-\\\\(M_{6}\\\\)) and (\\\\(M_{7}\\\\)-\\\\(M_{11}\\\\)) that compete with each other. As soon as one cell wins (e.g., the left one), the bias current \\\\(\\\\mathsf{l_{bn}}\\\\) is copied and added to the input current of the winning branch (e.g., \\\\(\\\\mathsf{l_{L}}\\\\)). This creates a hysteresis window, such that for the winning (left) cell to lose the competition, its input current has to decrease below the input current of the opposite branch by an additional factor equal to the bias current (\\\\(\\\\mathsf{l_{L}}<\\\\mathsf{l_{R}}-\\\\mathsf{l_{bn}}\\\\)). The output voltage of this circuit \\\\(\\\\mathsf{V_{OUT}}\\\\) switches to \\\"high\\\" when the left cell wins, and to \\\"low\\\" when the right cell becomes the winner.\\n\\nTo implement the \\\"stop-learning\\\" mechanism [14], we produce a current \\\\(\\\\mathsf{l_{Ca}}\\\\) (a surrogate of the neuron's calcium concentration) by integrating the post-synaptic neuron spikes with a DPI circuit [20]. We then compare this current to two thresholds with the two hWTA circuits. The digital output nodes of the two hWTA circuits were connected to logic gates to produce an active high \\\\(\\\\mathsf{Learn}\\\\) signal when the \\\\(\\\\mathsf{l_{Ca}}\\\\) current is within the set bounds (i.e., within the learning region) and a low when it is outside this region. This \\\\(\\\\mathsf{Learn}\\\\) signal is then used as a \\\"third factor\\\" to enable or disable the Delta rule weight circuit, and switch on or off the weight updates. The hysteresis windows of the hWTA circuits are used to distinguish between cases in which the target input is present (to enable learning) or absent (to disable learning and automatically switch to an \\\"inference\\\" mode). The effect of this window is described in Section IV-A.\\n\\n## IV Results\\n\\nWe validate the learning circuits with both circuit simulations and with experimental results measured from the fabricated chip.\\n\\n### _Circuit simulation results_\\n\\nHere, we show simulations of a single neuron and 40 plastic synapses during a learning task and show how the hWTA enables automatic switching from learning to inference.\\n\\nAfter initializing all synaptic weights to zero, we started a training phase by stimulating each plastic synapse with a \\\\(25\\\\,\\\\mathrm{Hz}\\\\) input spike train, and by sending a spike train with a \\\\(1\\\\,\\\\mathrm{kHz}\\\\) frequency to the target synapse. As expected, during this training phase, the weights of the synapses potentiated and the total weighted synaptic input current increased (see the red trace of Fig. 5). During the inference phase, we removed the target input spike train while keeping on stimulating the input synapses. As expected, without this extra input, the average\\n\\nFig. 4: hysteresis WTA circuit used to determine the \\u201cstop-learning\\u201d signals. The digital output voltage \\\\(\\\\mathsf{V_{OUT}}\\\\) switches from low to high only if the left input current \\\\(\\\\mathsf{l_{L}}\\\\) increases above \\\\(\\\\mathsf{l_{R}}\\\\) by an amount at least equal to \\\\(\\\\mathsf{l_{bh}}\\\\).\\n\\nFig. 5: Row simulation results. In the top plots of both sub-figures, the DPI synapse current (in red) follows the DPI target current (in blue) when the target input is high. The neuron\\u2019s membrane activity (in grey) is scaled for visibility. In the lower plots of both sub-figures the calcium current (in black) enables the \\\\(\\\\mathsf{Learn}\\\\) signal when it lies between the learning region\\u2019s low (green line) and high (red line) thresholds. (a) Small hysteresis bias (\\\\(\\\\mathsf{l_{bh}}=100\\\\,\\\\mathrm{pA}\\\\)): after the target current is removed the calcium current drops back into the learning region, the weights are decreased, and the neuron forgets its tuning (b) Large hysteresis bias (\\\\(\\\\mathsf{l_{bh}}=800\\\\,\\\\mathrm{pA}\\\\)): the large hysteresis region around the highest threshold (shaded pink) keeps the learning disabled, despite the fact that the calcium current fell below the high threshold. The weights of the plastic synapses do not change and the neuron maintains its proper tuning to the trained pattern.\\nmean firing rate of the neuron decreased, and the calcium concentration current fell below the upper bound of the learning region. Figure 5 shows this task performed with two values for \\\\(\\\\mathsf{b_{th}}\\\\), which governs the width of the hysteresis window. Without a proper hysteresis window (Fig. 4(a)), when the neuron falls back into a learning region it \\\"forgets\\\" its training (i.e., the learning circuits decrease the weights). On the other hand, by properly tuning the hysteresis window (Fig. 4(b)), the network remains in a \\\"stop-learning\\\" mode, and the neuron retains a high output firing rate response to the trained pattern, even in absence of a target signal. In the larger hysteresis window case, the total estimated power consumption is 1.07 uW, and a maximum (mean) energy of 740 pJ (680 pJ) is required to update the weights.\\n\\n### _Chip measurement results_\\n\\n#### Iv-B1 Tristability\\n\\nThe results from the measurements of the plastic synapse circuits are shown in Fig. 6. Initially, the neuron is presented with a high target activity, triggering large positive weight updates and causing a rapid increase in the synapse weight internal variable. Upon removal of the target, the weight is decreased. By increasing the power to the tristate stability amplifiers (Fig. 4(c)), i.e., by increasing \\\\(\\\\mathsf{b_{bs}}\\\\) of Fig. 4(b), the circuit opposes the weight changes more strongly and drives \\\\(\\\\mathsf{V_{w}}\\\\) to one of the three stable states more quickly. Stability at \\\\(\\\\mathsf{V_{dd}}\\\\) and ground is shown in Fig. 5(a) and at \\\\(\\\\mathsf{V_{dd}}\\\\)/2 in Fig. 5(b). Once the stimulation ends, the tristability circuit crystalizes the weight to one of the three stable states depending on the value of \\\\(\\\\mathsf{b_{bs}}\\\\).\\n\\n#### Iv-B2 Hysteresis for \\\"stop-learning\\\"\\n\\nFigure 7 shows the results of the characterization of the hysteretic calcium-based stop-learning mechanism. Similarly to the previous experiment, the neuron is initially stimulated with a high target activity, bringing it to the learning region. The plastic synapse weight rapidly increases, pushing the neuron into the \\\"stop-learning\\\" region. Once the target activity is removed, the neuron returns to the learning region, and, for small hysteresis window settings (top blue plot in Fig. 7), the plastic synapse decreases its weight as it is stimulated. For higher values of \\\\(\\\\mathsf{b_{th}}\\\\) the hysteresis window increases (orange plot in Fig. 7) and when the target is removed, the neuron's return to the learning mode is delayed. As this delay increases, even though the plastic synapse keeps on being stimulated, the neuron remains in the \\\"stop-learning\\\" region and the weight remains unchanged (purple plot in Fig. 7).\\n\\n## V Conclusions\\n\\nWe presented a set of analog circuits that enable learning in mixed-signal neuromorphic SNNs, with tristate stability and weight discretization circuits. By comparing the neuron's calcium concentration to lower and upper bounds, and by using hysteresis, we demonstrate effective always-on learning features, that automatically switch from learning mode to inference mode, without having to manually disable or enable learning. Comparisons to previous efforts are provided in Table I.\\n\\n## Acknowledgment\\n\\nThe authors thank Shyam Narayanan, Charlotte Frenkel, and Junren Chen for fruitful discussions and contributions.\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l l l l l} \\\\hline \\\\hline  & [24] & [25] & [17] & [11] & [This work] \\\\\\\\ \\\\hline \\\\begin{tabular}{l} **Technology** \\\\\\\\ **Design** \\\\\\\\ **Learning** \\\\\\\\ **Stop** \\\\\\\\ **learning** \\\\\\\\ **Weight** \\\\\\\\ **resolution** \\\\\\\\ **Energy/SOP** \\\\\\\\ **Power** \\\\\\\\ **supply** \\\\\\\\ \\\\end{tabular} & \\\\begin{tabular}{l} 28 nm \\\\\\\\ digital \\\\\\\\ semi super- \\\\\\\\ vised \\\\\\\\ yes \\\\\\\\ yes \\\\\\\\ **Weight** \\\\\\\\ **22.7 pJ** \\\\\\\\ 0.55 V \\\\\\\\ \\\\end{tabular} & \\\\begin{tabular}{l} 14 nm \\\\\\\\ digital \\\\\\\\ program- \\\\\\\\ mobile \\\\\\\\ no \\\\\\\\ 120.75 V \\\\\\\\ \\\\end{tabular} & \\\\begin{tabular}{l} 180 nm \\\\\\\\ mixed- \\\\\\\\ signal super- \\\\\\\\ error based \\\\\\\\ yes \\\\\\\\ no \\\\\\\\ 120.75 V \\\\\\\\ \\\\end{tabular} & \\n\\\\begin{tabular}{l} 180 nm \\\\\\\\ mixed- \\\\\\\\ signal \\\\\\\\ error based \\\\\\\\ yes \\\\\\\\ yes \\\\\\\\ \\\\end{tabular} \\\\\\\\ \\\\hline \\\\hline \\\\end{tabular}\\n\\\\end{table} TABLE I: Comparison to the state-of-the-art\\n\\nFig. 6: Tristability chip measurements. (a) Stability at \\\\(\\\\mathsf{V_{dd}}\\\\) and ground: When the target is presented, the plastic synapse weight is increased by the post-synaptic learning circuits (\\\\(\\\\overline{\\\\mathsf{V_{up}}}\\\\) and \\\\(\\\\mathsf{V_{dn}}\\\\) scaled for visibility). As the tristability bias increases, the circuit opposes the weight update more strongly. When the target is removed, the tristability maintains the weight value around \\\\(\\\\mathsf{V_{dd}}\\\\) for larger values of \\\\(\\\\mathsf{b_{bs}}\\\\) (in orange and purple). (b) Stability at \\\\(\\\\mathsf{V_{dd}}\\\\)/2: as \\\\(\\\\mathsf{b_{bs}}\\\\) increases the tristability opposes the learning with more strength.\\n\\nFig. 7: Hysteresis chip measurements. The hysteresis window is shown for three different values of \\\\(\\\\mathsf{b_{th}}\\\\). Increases in \\\\(\\\\mathsf{b_{th}}\\\\) produce larger hysteresis windows which are useful for tuning the \\u201cstop-learning\\u201d properties of the network.\",\n          \"# DeepVAT: A Self-Supervised Technique for Cluster Assessment in Image Datasets\\n\\n###### Abstract\\n\\nEstimating the number of clusters and cluster structures in unlabeled, complex, and high-dimensional datasets (like images) is challenging for traditional clustering algorithms. In recent years, a matrix reordering-based algorithm called Visual Assessment of Tendency (VAT), and its variants have attracted many researchers from various domains to estimate the number of clusters and inherent cluster structure present in the data. However, these algorithms face significant challenges when dealing with image data as they fail to effectively capture the crucial features inherent in images. To overcome these limitations, we propose a deep-learning-based framework that enables the assessment of cluster structure in complex image datasets. Our approach utilizes a self-supervised deep neural network to generate representative embeddings for the data. These embeddings are then reduced to 2-dimension using t-distributed Stochastic Neighbour Embedding (t-SNE) and inputted into VAT based algorithms to estimate the underlying cluster structure. Importantly, our framework does not rely on any prior knowledge of the number of clusters. Our proposed approach demonstrates superior performance compared to state-of-the-art VAT family algorithms and two other deep clustering algorithms on four benchmark image datasets, namely MNIST, FMNIST, CIFAR-10, and INTEL.\\n\\n## 1 Introduction\\n\\nData clustering is a widely used unsupervised learning technique that involves dividing a collection of unlabeled objects into \\\\(k\\\\) groups of similar objects. Various clustering algorithms are available in the literature, such as hierarchical clustering, centroid-based approaches, density-based algorithms, and distribution-based clustering. Most clustering algorithms require \\\\(k\\\\), the number of clusters to seek, as an input, which is the clustering tendency assessment problem. One common method to determine the number of clusters and their underlying structure is to visualize the data points using a 2D or 3D plot. However, this approach is only feasible for two- or three-dimensional datasets. For high-dimensional datasets such as images, time-series, visualizing and interpreting cluster structures using 2D or 3D visualization is not practical. Although various dimensionality reduction techniques, such as principal component analysis (PCA) and linear discriminant analysis (LDA), exist in the literature, these techniques often result in a low-dimensional representation of complex, high-dimensional datasets that may not fully reflect the inherent cluster structure due to information loss.\\n\\nThere are various formal (based on statistics) and informal (other approaches) techniques [1, 2] available in the literature for cluster structure assessment, but they are not completely effective. In contrast, visual approaches [3] have been in use for many years and serve as the foundation for many visual data analysis methods. The _Visual Assessment of Clustering Tendency_ (VAT) [4], a matrix reordering-based visual-analytical method, is one of such algorithm which provides a visual way to assess the clustering tendency of various datasets. There are several variants of VAT available for different types of data, which are collectively known as the VAT family of algorithms. The VAT family of algorithms has become an acceptable and widely used tool in several domains like biomedical applications, speech processing, image segmentation, transportation applications, and _etc_ for exploratory data analysis.\\n\\nVAT algorithm employs a variant of Prim's minimum spanning tree algorithm [5] to perform matrix reordering of the pairwise dissimilarity matrix to generate a reordered dissimilarity matrix. The reordered dissimilarity matrix can be viewed as a monochrome image called a _Reordered Dissimilarity Image_ (RDI) or cluster heat map. The RDI displays\\na possible cluster structure of the data set by showing dark blocks (data points of low dissimilarity values) along the diagonal. One method to obtain an accurate estimate of the number of clusters (\\\\(k\\\\)) from the RDI in the data is to count the number of dark blocks along the diagonal of the RDI. That means VAT not only can be used for cluster tendency assessment but also can be used for subsequent clustering of the input datasets, without needing the number of clusters.\\n\\nThis method is particularly effective for datasets with well-separated, compact clusters since the dark blocks along the diagonal are easily identifiable. However, for complex datasets (e.g., images, time series) having overlapping cluster structures (which is the case for most real-life datasets), existing VAT approaches perform poorly as the RDI quality degrades and the contrast between dark blocks along the diagonal and the rest of the image decrease. This makes it difficult to count the dark blocks along the diagonal.\\n\\nThere have been some efforts [6, 7, 8] to improve the quality of VAT generated RDI to accurately estimate the number of clusters for various complex geometry datasets. The VAT family algorithms, commonly used for analyzing cluster structures, exhibit poor performance when applied to image datasets, especially those with overlapping clusters. In the typical workflow, images are flattened before employing the VAT algorithms, resulting in the loss of their crucial spatial features. Consequently, the pixel-wise Euclidean distance becomes less effective in accurately capturing similarities or dissimilarities between images due to the feature loss incurred during flattening and the curse of dimensionality. Figure 1 shows an _improved Visual Assessment of Tendency_ (iVAT) [6] RDI for a synthetic, high-dimensional dataset (number of samples = 1000, dimensions= \\\\(100\\\\)) having three well-separated Gaussian mixtures (so \\\\(k\\\\)=3) in View (a), and RDI for a sample of popular MNIST dataset (number of samples = 1000 dimensions= \\\\(784\\\\), \\\\(k=10\\\\) classes) in View (b). It is evident from the figure that iVAT performs well when the data has inherently well separated clusters as we can clearly see three dark blocks along the diagonal in its RDI representing three clusters. However, when it comes to image datasets like MNIST, it struggles to provide meaningful results, as the resulting RDI does not exhibit clear dark blocks along the diagonal. This limitation highlights the need for a VAT variant that can effectively preserve the essential features of images, enabling more accurate assessments of cluster structures in image datasets.\\n\\nAs unsupervised deep learning methods (like autoencoders [9] and contrastive learning [10]) excel at extracting robust features from complex images, it makes them well-suited for developing a dedicated VAT algorithm for image datasets.\\n\\nTo address the above concerns, we propose a novel visual-analytical framework called DeepVAT. DeepVAT utilizes deep learning techniques to extract meaningful deep features from images, enabling more effective assessment of cluster structures. Unlike traditional VAT approaches, DeepVAT can uncover hidden cluster structures within image data, even in situations where ground truth labels or information about the number of classes are unavailable. Our major contributions are as follows:\\n\\n1. We proposed a deep, self-supervised learning framework, DeepVAT, that can provide visual evidence of the number of clusters present in complex image datasets.\\n2. In our method, we did not incorporate any prior knowledge about the ground truth number of clusters of data.\\n3. We performed experiments on four real-world, publicly available, large image datasets to show the superiority of DeepVAT over other state-of-the-art VAT family algorithms (proposed for high-dimensional data) in terms of quality of RDI, clustering accuracy, and normalized mutual information (NMI) score.\\n\\nTo the best of our knowledge, our work represents the first investigation in the literature exploring the utilization of deep features from images in the context of VAT methods. This contribution highlights the importance of incorporating deep learning techniques in the development of VAT models for accurate and insightful analysis of image datasets.\\n\\nHere is an outline of the rest of this article. Section 2 presents the preliminaries for the VAT/iVAT algorithm and reviews related work. The proposed algorithm, DeepVAT, is discussed in Section 3. Section 4 discusses the experiments and results, followed by conclusions in Section 5.\\n\\n## 2 Preliminaries and Related work\\n\\n### VAT and iVAT\\n\\nConsider we have a set of \\\\(N\\\\) objects, denoted as \\\\(O=o_{1},o_{2},\\\\ldots,o_{N}\\\\), where each object in \\\\(O\\\\) is described by a \\\\(p\\\\)-dimensional feature vector (\\\\(\\\\in\\\\mathbb{R}^{p}\\\\)). Alternatively, the data can be represented as a dissimilarity matrix, denoted\\n\\nFigure 1: (a) iVAT image of 100-dimensional Compact and Separated (CS) Gaussian mixture data (3 Gaussians); (b) iVAT image of flattened MNIST data (784 dimensional)\\nas \\\\(D_{N}=[d_{ij}]\\\\), where \\\\(d_{ij}\\\\) indicates the dissimilarity between object \\\\(o_{i}\\\\) and object \\\\(o_{j}\\\\) computed using a suitable distance measure. The VAT algorithm considers the dissimilarity matrix, \\\\(D_{N}\\\\) as input and reorders (by shuffling the rows and columns) using a modified Prim's algorithm. The image \\\\(I(D_{N})\\\\) of the reordered distance matrix \\\\(D_{N}\\\\) displays each pixel's intensity to indicate the dissimilarity between the corresponding row and column objects. When dark blocks appear along the diagonal, they might represent distinct clusters, ideally \\\\(k\\\\) (the original number of clusters in data) clusters. As single-linkage clusters are always diagonally aligned in VAT ordered images [11], \\\\(k_{p}\\\\) aligned clusters can be obtained by cutting the largest \\\\((k_{p}-1)\\\\) edges (given by the MST cut magnitude order \\\\(d\\\\)) from the MST. Here, \\\\(k_{p}\\\\) is the estimated number of clusters from VAT/iVAT RDI.\\n\\nThe improved-VAT (iVAT) [6] enhances the quality of VAT [4] RDI by using path-based distance transformation. The iVAT transformed matrix \\\\(D_{N}^{{}^{\\\\prime}}=[d_{ij}^{{}^{\\\\prime}}]\\\\) is generated using a path-based minimax distance [5]:\\n\\n\\\\[d_{ij}^{{}^{\\\\prime}}=\\\\min_{p\\\\in P_{ij}}\\\\max_{1<h<|p|}\\\\textbf{D}_{p[h]p[h+1]} \\\\tag{1}\\\\]\\n\\nwhere \\\\(p\\\\in P_{ij}\\\\) is an acyclic path in the set of all acyclic paths between objects \\\\((o_{i})\\\\) and \\\\((o_{j})\\\\) (vertices \\\\(i\\\\) and \\\\(j\\\\)) in \\\\(O\\\\).\\n\\n### VAT Variants for Large Volumes of High-Dimensional Data\\n\\nAlthough the VAT tool, discussed above, finds its usefulness in many applications, it can be computationally expensive as the size of the data set grows due to its \\\\(\\\\mathcal{O}(N^{2})\\\\) complexity. To understand the clustering structure for large volume datasets, a scalable version of VAT called _scalable VAT_ (sVAT) was developed by Hathaway _et al._[12], which utilizes a smart sampling based approach. To begin, sVAT extracts a smart sample of size \\\\(n\\\\) (where \\\\(n<<N\\\\)) from the large data set \\\\(X\\\\) using _Maximin Random Sampling_ (MMRS) [13]. The extracted sample is then used to compute the distance matrix \\\\(D_{n}\\\\), which is input into VAT.\\n\\nTo handle large volumes of high-dimensional datasets, Rathore _et. al_ in [7] proposed FensiVAT, an ensemble-based, hybrid clustering framework that combines fast data-space reduction using random projection with an intelligent sampling strategy to assess the clustering tendency of high-dimensional data. Recently, Zhang _et al._[8] proposed another method that leverages a kernel-based dissimilarity matrix to refine the RDI further, called kernel-based iVAT (KernelVAT). They use a Gaussian kernel and Isolation kernel (data-dependent) to transform the RDI.\\n\\nThe SpecVAT [14] algorithm is another approach that improves the quality of the RDI produced by VAT. It utilizes spectral graph theory to transform the raw distance matrix into a graph embedding space using graph Laplacian. It then creates an alternative feature representation of the data by selecting the \\\\(r\\\\) most significant eigenvectors that correspond to the highest eigenvalues. VAT is then applied to this transformed representation, resulting in a much-improved RDI.\\n\\nTo our knowledge, none of the existing VAT family of algorithms, including those reviewed in this section, have been investigated thoroughly on image datasets. Moreover, they have been shown to perform poorly on image datasets in their numerical experiments. Below, we discuss our proposed framework, DeepVAT.\\n\\n## 3 Proposed Framework: DeepVAT\\n\\nIn this paper, we propose a deep learning-based framework, DeepVAT, to advance the VAT family of algorithms for cluster structure assessment in complex image datasets.\\n\\nFigure 2: The proposed architecture of DeepVAT\\nFigure 2 presents each step of our proposed framework. Below, we briefly explain each step of DeepVAT keyed to the blocks shown in figure 2.\\n\\n### Generating Image Embeddings\\n\\nThe first step in our framework is representation learning by employing deep learning architectures. The objective of this step is to attain a _cluster-friendly_ representation of images, which involves bringing similar data points closer to each other and pushing dissimilar points further away. While deep learning architectures like autoencoders can be explored for this purpose, they may lack the inherent capability to produce a truly _cluster-friendly_ representation.\\n\\nRecently, a wide range of self-supervised approaches such as contrastive learning based models has been proposed that can provide _cluster-friendly_ representations for images using deep neural networks, without the need for ground truth information. These models include _Simple Contrastive Learning of Representations_ (SimCLR) [10], Barlow Twins [15], _Decoupled Contrastive Learning_ (DCL) [16], SimSiam [17], _Bootstrap Your Own Latent_ (BYOL) [18], and many others.\\n\\nWe observed that incorporating SimCLR as the feature extractor in the DeepVAT pipeline led to significantly superior iVAT images compared to when an autoencoder was used as the feature extractor. The significant difference observed can be attributed to the inherent capabilities of SimCLR compared to basic autoencoders. SimCLR has the ability to effectively group similar points together and push dissimilar points apart, thanks to the InfoNCE loss it minimizes [19]. In contrast, basic autoencoders lack this inherent capability. Additionally, a recent study [20] suggests that the InfoNCE loss aids in learning cluster-preserving representations of images, further highlighting the suitability of SimCLR for DeepVAT. Hence, we chose SimCLR as our primary model for creating embeddings in our proposed framework.\\n\\nIn SimCLR, the first stage includes performing auxiliary tasks or a given batch of images, such as corrupting the data, adding noise, and creating augmented views of the same data. These transformations generate fresh views of the same images, effectively enlarging the training set. Gray-scale images cannot undergo certain transformations such as color jitters. Instead, an affine stretch is utilized along with rotation, resizing, and blurring. Through these tasks, the models can acquire a rich and beneficial representation of the data.\\n\\nSimCLR consists of an encoder network and a non-linear projection head. The augmented images are fed into the encoder to extract high-level features. The encoder consists of several convolutional and fully connected layers and is trained using a contrastive loss function. The SimCLR framework utilizes an InfoNCE loss function [19] to measure the similarity between different views of an image. The model aims to maximize the similarity between the two views of the same image and minimize the similarity between views of different images. By doing so, SimCLR learns to extract valuable features robust to variations in the input data, which is helpful for generalization in real-world scenarios. The encoder projects the images into (say) \\\\(d\\\\)-dimensional space.\\n\\nThen, the projection head, a small neural network, further maps the encoded features (\\\\(d\\\\)-dimensional) to a (lower) \\\\(m\\\\)-dimensional set of embeddings, and then back to a lower-manifold of \\\\(d\\\\)-dimensional space, resulting in a rank-deficient weight matrix. This projection head is trained alongside the encoder during training. After training successfully, the projection head is discarded, and the data is passed through the trained encoder to generate embeddings. The projection head serves as an additional non-linear transformation that helps to increase the quality of the learned features.\\n\\n### Dimensional Reduction using t-SNE\\n\\nDespite the fact that SimCLR embeddings (shown with a pink bar in figure 2) can be used to compute the dissimilarity matrix for VAT/iVAT, the high dimensionality of the SimCLR embeddings can lead to the curse of dimensionality problem, which can affect the quality of the resulting visualization. In our experiments, as discussed in Section 4, we observed that using SimCLR embeddings to compute the dissimilarity matrix did not result in a significant improvement in the quality of the resulting RDI for complex image datasets (CIFAR-10 [21] and INTEL [22]).\\n\\nOne way to tackle this issue is to apply t-SNE on a data representation obtained from SimCLR. Compared to the original flattened image data, t-SNE works better on SimCLR embeddings because SimCLR is a deep-layer architecture that can more efficiently represent the highly varying data manifold in multiple nonlinear layers [10, 23]. The projections generated by SimCLR's projection head can identify highly varying manifolds better than a local method like t-SNE, resulting in a higher quality visualization compared to using t-SNE on the original high-dimensional data [23]. However, it is important to acknowledge that representing the complete structure of intrinsically high-dimensional data in just two or three dimensions is fundamentally impossible, highlighting a fundamental limitation.\\n\\n### Smart Sampling: Maximin Random Sampling (MMRS)\\n\\nComputing and analyzing VAT RDI using t-SNE embeddings (shown with a pink bar in figure 2), generated in the last step, may be infeasible for image datasets with large samples \\\\((N)\\\\) due to \\\\(\\\\mathcal{O}(N^{2})\\\\) complexity of VAT. To deal with large image datasets, we exploit a smart sampling ap\\nproach called _Maximin and Random Sampling_ (MMRS).\\n\\nLet \\\\(\\\\textbf{X}=\\\\{x_{i}\\\\}_{i=1}^{N}\\\\) represent the set of t-SNE reduced embeddings obtained from the trained encoder, where \\\\(x_{i}\\\\in\\\\mathbb{R}^{2}\\\\). The MMRS technique is an intelligent way to obtain samples in large batch data sets by combining MaxiMin (MM) and Random Sampling (RS). The MM sampling process starts by identifying a set of \\\\(k^{{}^{\\\\prime}}\\\\) (an overestimate of \\\\(k\\\\)) distinguished objects, which are the farthest from each other in the input data **X**. Then each point in the set **X** is grouped with its nearest distinguished object using the nearest prototype rule (NPR) (mentioned in [7]), which divides the entire dataset into \\\\(k^{\\\\prime}\\\\) groups \\\\(\\\\{G_{i}\\\\}_{i=1}^{k^{{}^{\\\\prime}}}\\\\) where \\\\(G_{i}\\\\subseteq\\\\textbf{X}\\\\), \\\\(\\\\forall i\\\\in\\\\{1,2,\\\\ldots,k^{{}^{\\\\prime}}\\\\}\\\\) by associating \\\\(|G_{i}|\\\\) points to \\\\(i^{th}\\\\)_MM sample_, which represents each of the \\\\(k^{{}^{\\\\prime}}\\\\) group. Finally, the sample \\\\(\\\\mathcal{S}\\\\) of size \\\\(n<<N\\\\) is formed by selecting random data-points from each of the \\\\(k^{{}^{\\\\prime}}\\\\) groups \\\\(\\\\{G_{i}\\\\}_{i=1}^{k^{{}^{\\\\prime}}}\\\\). The number of points \\\\(n_{j}\\\\) extracted from group \\\\(G_{j}\\\\) is proportional to the cardinality of \\\\(G_{j}\\\\), i.e \\\\(n_{j}\\\\propto|G_{j}|\\\\). To be precise, \\\\(n_{j}=\\\\lceil n\\\\times|G_{j}|/N\\\\rceil\\\\), where \\\\(\\\\lceil\\\\cdot\\\\rceil\\\\) is the ceiling function. This step gives us a smart sample of size \\\\(n<<N\\\\) in lower dimensional space. Rather than feeding a large number of embeddings directly into iVAT for visualization, we feed a _smart sample_ of size \\\\(n\\\\), obtained using MMRS.\\n\\n### Dissimilarity Matrix Computation for VAT/iVAT\\n\\nThe reduced-dimension, smart samples are used to compute dissimilarity matrix \\\\(D_{n}\\\\) which is fed to the VAT/iVAT algorithm to obtain reordered dissimilarity matrix \\\\(D_{n}^{{}^{\\\\prime}}\\\\). The visualization of \\\\(I(D_{n}^{{}^{\\\\prime}})\\\\) suggests the number of clusters \\\\(k\\\\) present in the dataset.\\n\\n## 4 Experiments\\n\\nWe performed experiments on four publicly available, real, image datasets. We evaluated the ability of DeepVAT to suggest the number of clusters in image datasets and compared its performance with other VAT family methods that are claimed to work better with high-dimensional data. We also compare DeepVAT with two well known deep-clustering based methods. The experiments were conducted on a regular PC with the following configuration: OS: Ubuntu \\\\(22.04.2\\\\) LTS (64 bit); processor: Intel(R) Xeon(R) Gold \\\\(5220\\\\)R CPU @ \\\\(2.20\\\\)GHz; RAM: \\\\(62\\\\) GB; GPU: Nvidia Quadro RTX \\\\(6000\\\\), \\\\(24\\\\) GB.\\n\\n### Datasets\\n\\nWe performed our experiments on the following datasets:\\n\\n1. **MNIST**[24]: It has a total of \\\\(60,000\\\\) grayscale training images of digits with a dimension of \\\\(28*28\\\\) ranging from 0 to 9, i.e., total 10 classes, with each class having 6,000 images. The full training set is used in all experiments (60,000 images).\\n2. **FMNIST**[25]: It has a total of 60,000 grayscale training images of fashion apparel with a dimension of \\\\(28*28\\\\), i.e., it has a total of \\\\(10\\\\) classes, with each class having 6,000 images. The full training set is used in all experiments (60,000 images).\\n3. **CIFAR10**[21]: It has a total of \\\\(50,000\\\\) natural RGB training images with a dimension of \\\\(32*32*3\\\\). It has a total of \\\\(10\\\\) classes, with each class having \\\\(5,000\\\\) images. The full training set is used in all experiments (50,000 images).\\n4. **Intel Image Dataset**[22]: It has \\\\(14,034\\\\) natural RGB training images and 3,000 testing images with \\\\(6\\\\) classes. We clubbed both sets and used the final count of \\\\(17,000\\\\) images to perform various experiments. Each image has a dimension of \\\\(32*32*3\\\\).\\n\\n### Evaluation Criteria\\n\\nWe show all (best) iVAT images with an estimated number of clusters (\\\\(k_{p}\\\\)) for all the compared algorithms in Table 1. To estimate \\\\(k_{p}\\\\), we used the algorithm presented in [26]. As mentioned in section 2.1, \\\\(k_{p}\\\\) clusters can be obtained by cutting (\\\\(k_{p}\\\\)-_1_) edges in MST provided by VAT/iVAT algorithm. We used the predicted labels and ground truth information of each dataset to compute the partition accuracy (PA) for the estimated value of \\\\(k\\\\) (from iVAT image) and normalized mutual information (NMI). The PA of a clustering algorithm is the percentage (%) ratio of the number of samples with matching ground truth and algorithmic labels to the total number of samples in the dataset. To ensure consistent label mapping between the predicted and true labels, the Kuhn-Munkres algorithm [27] is employed to find the best mapping between the predicted and ground truth labels. A higher value of PA and NMI implies a better match to the ground truth partition.\\n\\n### Comparison of DeepVAT with other Models\\n\\nIn this section, we make a qualitative and quantitative comparison of DeepVAT with existing state-of-the-art VAT family methods that claim to work with high-dimensional and complex data (images when flattened can be seen as high-dimensional data). Specifically, we compare DeepVAT with the following methods:\\n\\n1. **VAT family methods** 1. **FensiVAT**: FensiiVAT [7] is applied on a small MMRS subset of the embeddings extracted from the trained encoder of SimCLR.\\n2. **KernelVAT**: KernelVAT [8]. is applied on a small MMRS subset of the embeddings extracted from the trained encoder of SimCLR. 3. **SpecVAT**: SpecVAT [14] is applied on a small MMRS subset of the embeddings extracted from the trained encoder of SimCLR.\\n2. **Deep-Clustering methods** 1. **DEC**[28]: iVAT is applied to the t-SNE reduced embeddings, extracted from the trained encoder of DEC. Specifically, iVAT is applied to a smaller MMRS subset. 2. **LSD-C**[29]: The t-SNE reduced embeddings, extracted from the trained encoder of DEC, are utilized for applying iVAT. More specifically, iVAT is applied to a smaller MMRS subset. 3. **Autoencoder + iVAT**: We trained a vanilla autoencoder and obtained embeddings from the trained encoder network. Subsequently, t-SNE is applied to these embeddings, and iVAT is then applied specifically to a smaller MMRS subset of the reduced embeddings.\\n\\n#### 4.3.1 Parameter Settings\\n\\nIn DeepVAT, the SimCLR model was trained using the LARS optimizer [30] for each dataset, with \\\\(1,000\\\\) epochs. The output dimension of the encoder network was set to \\\\(d=2,048\\\\), and the projection head network was chosen to have \\\\(m=128\\\\). We performed each experiment five times on each dataset and reported the average results. We use a batch size of \\\\(700\\\\) for MNIST and FMNIST and \\\\(256\\\\) for CIFAR10 and Intel Image Dataset. The parameters for MMRS sampling are \\\\(k^{\\\\prime}\\\\) = 15 for MNIST, FMNIST, and CIFAR10, and 10 for INTEL, number of samples, \\\\(n\\\\): 4,000 for all datasets.\\n\\nEuclidean distance is utilized as the metric to generate the RDI for the t-SNE reduced embeddings of the MNIST dataset. Likewise, in the ablation study discussed in Section 4.4, Euclidean distance is employed to generate the RDI for the t-SNE reduced embeddings of the raw-flattened MNIST data. For all other experiments, cosine dissimilarity is utilized as the dissimilarity measure to generate the RDI.\\n\\nThe input to all three VAT based methods is 2048-dimensional SimCLR embeddings as these methods transform the original data into a suitable embedding space/low dimensional space by virtue of their design. In KernelVAT, radial basis function (RBF) kernel is used, with the precision parameter (\\\\(\\\\gamma\\\\)) set to \\\\(0.05\\\\). In FensiVAT, the down-space (reduced) dimension for random projection is chosen \\\\(100\\\\) when FensiVAT is applied to a \\\\(2048\\\\)-dimensional SimCLR embedding. In SpecVAT, we performed iterations over the parameter _number of eigen-values_\\\\((r)\\\\) ranging from 1 to 10 and noted the best result.\\n\\nDEC [28] and LSD-C [29] heavily rely on prior information about the number of clusters in a dataset, while DeepVAT do not require this specific information. As stated in Section 4.3.1, we deliberately choose an overestimate for the number of clusters in all our experiments involving VAT algorithms. Consequently, for a fair comparison, we adopt the same overestimate (\\\\(k^{{}^{\\\\prime}}\\\\) = 15 for MNIST, FMNIST, and CIFAR-10, and \\\\(k^{{}^{\\\\prime}}\\\\) = 10 for INTEL) for DEC (which requires the value of \\\\(k\\\\) for performing \\\\(k\\\\)-means) and LSD-C (where the linear layer after the encoder has the same number of neurons as the number of classes).\\n\\nTo ensure fairness in the assessment, just like DeepVAT utilized t-SNE reduced embeddings from the SimCLR encoder, we also apply t-SNE to reduce the embeddings generated from the encoders of DEC and LSD-C to 2 dimensions before generating the RDI.\\n\\nWe keep all the parameter settings the same unless stated otherwise.\\n\\n### Ablation Study\\n\\n#### 4.4.1 Results and Discussions\\n\\nTable 1 shows the comparison of all six models based on the RDI quality and their ability to estimate the underlying clusters (\\\\(k_{p}\\\\)) accurately. Table 2 shows the comparison of DeepVAT with all the six methods mentioned above based on the PA and NMI.\\n\\nWe can see that the DeepVAT method generates much clearer and sharper dark blocks compared to the SpecVAT, KernelVAT, and FensiVAT models. Consequently, the number of dark blocks generated by DeepVAT (\\\\(k_{p}\\\\)) is close to the original number of classes (\\\\(k\\\\)) in the dataset, making it the most accurate in estimating the potential number of clusters compared to other algorithms. When applying FensiVAT and KernelVAT directly to the high-dimensional embedding, we observed that they produced blurry RDI (the cluster count is good but the quality of RDI is poor) and only achieved moderate quantitative results in terms of PA and NMI (refer Table 2) for simple datasets such as MNIST and FMNIST. However, when dealing with complex datasets like CIFAR-10 and INTEL, both algorithms failed to generate high-quality RDI and quantitative results (refer Table 2). Note that clustering algorithms face significant challenges when dealing with these datasets, as the ground truth labels may not accurately reflect distinct clusters within the feature vector representation of the data points. These results suggest that our approach produces more visually appealing and informative representations of the data.\\n\\nBased on the results presented in Table 2, DeepVAT demonstrates a significant performance advantage over state-of-the-art VAT family methods in terms of both PA and\\nNMI metrics. DeepVAT demonstrates its superiority over deep-clustering algorithms by achieving a 35% improvement in PA and 30% improvement in NMI. Furthermore, it outperforms simple autoencoders by an impressive 95% on PA and 203% on NMI metrics, clearly highlighting its remarkable performance. As a result, DeepVAT surpasses all six competitive models in both PA and NMI measures.\\n\\nThe success of DeepVAT can be attributed to the use of SimCLR and t-SNE. SimCLR is effective at generating a robust representation of the dataset by leveraging non-linear functions, such as deep CNN encoders and projection heads, to approximate its intrinsic dimensionality. By applying the proposed model to the best-performing model, DeepVAT achieves a better performance than the other models.\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{|c|c|c|c|c|c|c|c|} \\\\hline\\n**Dataset** & _FensiVAT_ & _KernelVAT_ & _SpecVAT_ & _DEC_ & _LSD-C_ & _Autoencoder_ & **Ours** \\\\\\\\ \\\\hline \\\\multirow{3}{*}{_MNIST_} & \\\\multirow{3}{*}{\\\\(k=10\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=10\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=8\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=3\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=15\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=7\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=10\\\\)} \\\\\\\\  & & & & & & & \\\\\\\\ \\\\cline{1-1} \\\\cline{5-8} \\\\cline{8\\nplying t-SNE on the representation produced by SimCLR, we obtain a better low-dimensional embedding, as SimCLR is better equipped to detect highly varying manifolds than t-SNE alone.\\n\\nTo examine the impact of various components in our model, we perform a three-part ablation study on all four datasets. We systematically eliminate one component at a time from the DeepVAT pipeline (Fig. 2) to assess its reliance within the complete pipeline. Our model is summarised as **DeepVAT = SimCLR + t-SNE + MMRS + iVAT**.\\n\\n1. **DeepVAT _minus_ SimCLR**: We flatten each image in the dataset and apply t-SNE on top of them. Then we sample using MMRS and compute the final iVAT image for the samples. This will show that our model not only benefits from the t-SNE block.\\n2. **DeepVAT _minus_ t-SNE**: Images are passed through a trained SimCLR encoder, and we sample the learned high-dimensional embeddings using MMRS. The final iVAT image is computed on the sampled embeddings.\\n3. **DeepVAT _minus_ MMRS: iVAT image is computed on full set of embeddings. However, as iVAT/VAT family algorithms require computation of dissimilarity matrix, which has a time complexity of order \\\\(\\\\mathcal{O}(N^{2})\\\\), it will take hours to get the results. Hence, due to such large time complexity and resource constraint, we are not reporting the results of this ablation.\\n4. **DeepVAT _minus_ tSNE _minus_ SimCLR**: We apply iVAT directly on the MMRS sub-set of raw flattened images.\\n\\nThe findings of the ablation study (1) (Table 3) suggest that the generation of RDI by DeepVAT is not solely reliant on t-SNE. Although t-SNE applied directly to raw flattened images produces reasonably good results, it is not as accurate as DeepVAT. However, when dealing with complex datasets like CIFAR-10, utilizing t-SNE on raw flattened images fails to provide meaningful information about the cluster structure. Additionally, the role of the SimCLR module in DeepVAT is investigated in the study (2). The results in Table 3 indicate that SimCLR alone does not yield satisfactory outcomes, although it still demonstrates limited interpretability for simple datasets like MNIST and FM-NIST. Nevertheless, when iVAT is applied to SimCLR embeddings for complex datasets, it fails to convey meaningful results. This limitation may be attributed to the high dimensionality of the SimCLR embeddings (2048), which hinders the accurate inference of cluster presence by iVAT.\\n\\n## 5 Conclusions and Future Work\\n\\nThis article proposes a deep, self-supervised learning based VAT framework, DeepVAT, for cluster structure assessment in image data. The self-supervised learning method SimCLR significantly improved the performance of iVAT both qualitatively and quantitatively. Our experimental results suggest that when t-SNE is used as dimensionality reduction on top of SimCLR embeddings, the iVAT yields a much sharper RDI, thus a more accurate estimate of the number of clusters. This is because SimCLR can capture the intrinsic dimensionality of image datasets which helped t-SNE in generating a good low dimensional representation. Based on our numerical experiments on four image datasets, we have also shown that DeepVAT significantly outperformed other VAT family methods (FensiVAT, KernelVAT and SpecVAT) and two deep clustering methods (DEC and LSD-C) based on clustering partition accuracy (PA) and NMI. We believe that deploying more deep learning based models like deep metric learning and semi-supervised, which have partial access to labels can further improve the iVAT image for complex datasets.\\n\\nAt present, the training time for major self-supervised contrastive learning models is quite extensive. As part of our future work, we aim to focus on reducing the training time required for such models. Our objective is to develop methods that can generate high-quality iVAT images using self-supervised contrastive learning models in significantly less time.\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{|l|c|c|c|c|c|c|c|c|} \\\\hline \\\\multirow{2}{*}{\\n\\\\begin{tabular}{} \\\\end{tabular} } & \\\\multicolumn{2}{c|}{_MNIST_} & \\\\multicolumn{2}{c|}{_FMNIST_} & \\\\multicolumn{2}{c|}{_CIFAR-10_} & \\\\multicolumn{2}{c|}{_INTEL_} \\\\\\\\ \\\\cline{2-9}  & PA (\\\\%) & NMI & PA (\\\\%) & NMI & PA (\\\\%) & NMI & PA (\\\\%) & NMI \\\\\\\\ \\\\hline \\\\hline _Full DeepVAT_ & **82.02** & **0.89** & **43.76** & **0.61** & **51.26** & **0.47** & **56.84** & **0.46** \\\\\\\\ \\\\hline _DeepVAT_ minus _SimCLR_ & 37.27 & 0.51 & 29.87 & 0.51 & 18.25 & 0.07 & 31.27 & 0.15 \\\\\\\\ \\\\hline _DeepVAT_ minus _t-SNE_ & 40.73 & 0.60 & 30.61 & 0.52 & 10.14 & 0.01 & 17.52 & 0.007 \\\\\\\\ \\\\hline _DeepVAT_ minus _MMRS_ & \\u2013 & \\u2013 & \\u2013 & \\u2013 & \\u2013 & \\u2013 & \\u2013 & \\u2013 \\\\\\\\ \\\\hline _DeepVAT_ minus _SimCLR_ minus _t-SNE_ & 11.27 & 0.009 & 10.01 & 0.007 & 10.12 & 0.06 & 15.12 & 0.005 \\\\\\\\ \\\\hline \\\\end{tabular}\\n\\\\end{table}\\nTable 3: **Ablation study.** We analyze the effects of removing different blocks from the DeepVAT pipeline on PA and NMI.\",\n          \"# Defect Classification in Additive Manufacturing Using CNN-Based Vision Processing\\n\\n###### Abstract\\n\\nThe development of computer vision and in-situ monitoring using visual sensors allows the collection of large datasets from the additive manufacturing (AM) process. Such datasets could be used with machine learning techniques to improve the quality of AM. This paper examines two scenarios: first, using convolutional neural networks (CNNs) to accurately classify defects in an image dataset from AM and second, applying active learning techniques to the developed classification model. This allows the construction of a human-in-the-loop mechanism to reduce the size of the data required to train and generate training data.\\n\\n**Keywords:** Convolutional neural networks, additive manufacturing, defect classification, active learning\\n\\n## 1 Introduction\\n\\nLarge and openly available datasets of annotated images containing up to millions of training examples such as Pascal VOC [1] are available to machine learning researchers for many applications. This has enabled huge improvements in machine learning over recent years. By contrast, such openly available datasets are not available in the domain of Additive Manufacturing (AM) or 3D printing because labelled samples are difficult, expensive, and time-consuming to obtain as shown in [13] and [14]. As a result of poor data availability, researches in AM often have to use only a limited amount of labelled samples for training tasks before then leveraging a large number of unlabelled image data. Some researchers have called this the \\\"small data challenge in the big data era\\\" [15].\\n\\nTo overcome this challenge, we present a method that applies transfer learning and fine-tuning on a CNN-based neural network model to achieve accurate classification of manufacturing defects. This uses a dataset of images of the melt pool, created from the interaction between a laser and the materials used in manufacturing, taken during the AM process. Structural defects in the resulting output can sometimes be detected during manufacture from observations of the melt pool. Our technique involves using active learning algorithms to reduce the number of labelled samples required in the training process. We perform automatic labelling using the model to generate larger datasets of labelled images from unlabelled samples, for use in training.\\n\\n## 2 Methods\\n\\n_Transfer learning_ is a method that performs training a neural network model using data from a source domain then later applying the trained model to a target domain that is different from the source. This allows rapid progress in re-training and significantly reduces the required number of training samples in the target domain. It is commonly used in computer vision tasks such as classification to support improved performance in domains which are data-poor. In recent years, transfer learning has proved to be effective in the task of defect classification in AM, such as the work presented in [10] and [21] where transfer learning and fine-tuning were applied to the training of CNN based neural network architectures.\\n_Active learning_[Settles, 2009] is a technique for labelling data that selects and prioritises the most informative data points to submit to an annotator for labelling. Such prioritised data points have the highest potential impact on the supervised training of a machine learning model, thus accelerating the training process. The combination of transfer learning and active learning allows leveraging small amounts of labelled data to improve the performance of the training process of a deep learning model.\\n\\n## 3 Classification Experiments in Additive Manufacturing\\n\\nTo investigate the potential for transfer learning and active learning in the task of defect detection in AM, a case study was carried out using the open image dataset from [Westphal and Seitz, 2021]. This contains 4,000 images, manually divided into 2 different defect detection classes in AM. The images in this dataset are clearly separated into 3 balanced subsets for training (2,000), testing (1,000) and validation (1,000).\\n\\nTo conduct experiments, we employed a VGG16 based classifier from previous work which proved to be accurate in the task of defect classification on images generated from emission monitoring during additive manufacturing [Liu et al., 2022]. This classifier relies on transfer learning in which 13 convolutional layers from a pre-trained VGG16 model are used for feature extraction and the weights in these layers had been trained using ImageNet data. After the convolutional layers, 2 dense layers with ReLU activation function are added followed by 1 dense layer as the output layer using Sigmoid as the activation function, since the targeted dataset are divided into 2 classes for binary classification. In the original paper [Westphal and Seitz, 2021], the best classification performance is generated using a VGG16 based CNN model which is the reason we do not use a more recent model such as ResNet. We consider that as a baseline for further investigation in this study.\\n\\nThe tuning of hyperparameters involves adjusting the optimiser, learning rate, batch size and training epochs. There are 3 optimisers in the test we use which are Adam, SGD and RMSprop in combination with learning rate in a range from \\\\(10^{-2}\\\\) to \\\\(10^{-5}\\\\). We have also conducted training using different batch sizes (4, 32, 64) and training epochs (30, 60, 120). The cost function used in all tests is binary cross entropy. To reduce overfitting, weight regularisers are added to the 2 dense layers with the ReLU activation function mentioned above. The weight decay regulariser, also known as L2 regulariser which calculates the sum of the squared weights, is applied when initialising the keras model. The tuning of this hyperparameter is in a range from \\\\(10^{-1}\\\\) to \\\\(10^{-4}\\\\) and tested for multiple times until no obvious overfitting issue appears in the training and validation.\\n\\nAfter tuning on hyperparameters for multiple combinations, the best preforming combinations regarding the 3 types of optimisers are shown in Table 1 together with classification results on the validation dataset in comparison with the baseline from [Westphal and Seitz, 2021]. These initial tests were performed to check how adaptive our approach is on this dataset. The results show that all 3 optimisers can reach a value around 98% of the validation accuracy and our classification model is well-adapted to this dataset. The results also show that for this dataset a smaller batch size used in the training process such as 4, gives better performance and this can be explained as smaller batch sizes require more frequent weight updates during training. In turn this can help the model adjust its parameters more quickly and respond to changes in the data distribution which increases the model's ability to adapt to a new dataset. Finally, although not shown here, accuracy is stable thoughout the training showing no overfitting.\\n\\n## 4 Active Learning Experiments in Additive Manufacturing\\n\\nHaving developed a classifier which uses domain transfer across AM image datasets, we extended training to include active learning applied to further investigate classification performance during the progression of AL iterations. The second experiment was performed in a series of steps of (1) active sample section, (2) query for label, (3) train with queried sample, and (4) validate for current query iteration. The cycle iterates until a human supervisor decides to complete the training phase when validation accuracy achieves a target level.\\n\\nHere we apply a pool-based sampling scenario and an uncertainty sampling query strategy [Settles, 2009]. This is the most commonly used query strategy to start generalised sampling on this particular AM dataset.\\nThe implementation of active learning uses Python 3 and Google Colab. During the experiment, a classifier model is initialised and the optimser chosen is SGD as we found this gives more stabilised performance in the validation test and has minimal overfitting even when training is continued long after convergence. While Adam and RMSprop converge faster, there are larger fluctuations in the validation and minor overfitting after training reaches convergence. In addition, though SGD yields a result lower than the other 2 optimisers, it has slightly better potential that can be improved by applying active learning. During this experiment, 2,000 training samples were fed to the classifier with a total of 40 queries and for each query 50 samples were actively selected by the uncertainty sampling query strategy.\\n\\nThe selected and queried samples were assigned a label by an annotator after which the newly labelled samples were used to fine-tune the classifier to improve performance. This was evaluated using classification accuracy on the validation dataset at the end of each query iteration and later we show results on the test set.\\n\\nFollowing the inclusion of active learning, validation accuracy in each query iteration is shown in Figure 1 where results show that with the aid of active learning, the model reaches convergence after the 13th query and the value of validation accuracy is around 98%. More specifically, the calculated mean value from the 13th to 40th queries is 0.981 with a standard deviation of 0.0246 and a peak of 0.990. This is slightly higher than the result of the SGD optimiser based model shown in Table 1 and 1% higher than the baseline. Overall performance after convergence is also relatively stable. Results also show that the model only needs the first 650 most informative samples to achieve the best performance which is only 37.5% of the total 2,000 labelled training data.\\n\\nThis trained model was used to classify the labels on the testing dataset mentioned in Section 3, which is a balanced dataset consisting of 1,000 samples and the results are shown in Table 2.\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l c c|c|c c c c c} \\\\hline \\\\hline Experiment: & \\\\multirow{2}{*}{Batch} & \\\\multirow{2}{*}{Epochs} & \\\\multicolumn{2}{c}{Confusion} & \\\\multirow{2}{*}{Accuracy} & \\\\multirow{2}{*}{Precision} & \\\\multirow{2}{*}{Recall} & \\\\multirow{2}{*}{F1-Score} & \\\\multirow{2}{*}{AUC} \\\\\\\\ Optimiser, learning rate & & & & matrix & & & & \\\\\\\\ \\\\hline Baseline & 64 & 30 & 496 & 4* & 0.977* & 0.992* & 0.963* & 0.977* & 0.993 \\\\\\\\ \\\\cline{3-10}  & & & 19 & 481 & & & & \\\\\\\\ \\\\hline SGD, lr=0.01 & 4 & 60 & 483 & 17 & 0.979 & 0.967 & 0.992 & 0.979 & 0.998 \\\\\\\\ \\\\cline{3-10}  & & & 4 & 496 & & & & \\\\\\\\ \\\\hline Adam, lr =0.00001 & 4 & 120 & 490 & 10 & 0.988 & 0.980 & 0.996 & 0.988 & 0.998 \\\\\\\\ \\\\cline{3-10}  & & & 2 & 498 & & & & \\\\\\\\ \\\\hline RMSprop lr =0.00001 & 4 & 60 & 485 & 15 & 0.982 & 0.971 & 0.994 & 0.982 & 0.997 \\\\\\\\ \\\\cline{3-10}  & & & 3 & 497 & & & & \\\\\\\\ \\\\hline \\\\hline \\\\end{tabular}\\n\\\\end{table}\\nTable 1: Best performing hyperparameters for each optimiser, performance results on the validation set. Results marked \\u2018*\\u2019 are updates provided directly to us by the authors of [21] in response to us pointing out errors in the original paper. An author correction to the copy of record is now underway.\\n\\nFigure 1: classification accuracy on the validation dataset at the end of each query iteration\\n## 5 Conclusions\\n\\nThis paper presents an investigation into performance of a computer vision based classification task on a dataset from the additive manufacturing process. We use a CNN based classifier in combination with transfer learning and active learning strategies. We improved the overall validation accuracy to about 98%. We also conducted experiments to investigate the approximate minimum number of labelled samples needed to reach convergence in training. In future work we plan to further investigate the sampling strategies for active learning especially regarding class imbalance problems. We will involve approaches from semi-supervised learning to reinforce the labelling and self training as an extension to the current active learning mechanism.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train_dataset = dataset[\"train\"]\n",
        "df = train_dataset.to_pandas()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqeQsvfCN5Z0"
      },
      "source": [
        "## Text Preprocessing\n",
        "\n",
        "To improve the quality of topic modeling, weâll perform several preprocessing steps on the abstracts:\n",
        "1. **Remove Stop Words**: Words that donât add much meaning, like \"the,\" \"and,\" \"is.\"\n",
        "2. **Lemmatization**: Reduce words to their root forms to handle variations.\n",
        "3. **Remove Numbers and Special Characters**: Clean up any non-alphabetic characters.\n",
        "4. **Remove Extra Whitespace and Convert to Lowercase**: Ensure consistent formatting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pllnXtc6fLY1"
      },
      "outputs": [],
      "source": [
        "abstracts=dataset['train']['abstract']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "ncdFD-7jfeCi",
        "outputId": "98fa6f42-f18a-4b7d-c3be-2d8eb3741492"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'We analyzed four epochs of beamformed EVN data of the Crab Pulsar at 1658.49\\nMHz. With the high sensitivity resulting from resolving out the Crab Nebula, we\\nare able to detect even the faint high-frequency components in the folded\\nprofile. We also detect a total of 65951 giant pulses, which we use to\\ninvestigate the rates, fluence, phase, and arrival time distributions. We find\\nthat for the main pulse component, our giant pulses represent about 80% of the\\ntotal flux. This suggests we have a nearly complete giant pulse energy\\ndistribution, although it is not obvious how the observed distribution could be\\nextended to cover the remaining 20% of the flux without invoking large numbers\\nof faint bursts for every rotation. Looking at the difference in arrival time\\nbetween subsequent bursts in single rotations, we confirm that the likelihood\\nof finding giant pulses close to each other is increased beyond that expected\\nfor randomly occurring bursts - some giant pulses consist of causally related\\nmicrobursts, with typical separations of $\\\\sim\\\\!30{\\\\rm\\\\;\\\\mu s}$ - but also find\\nevidence that at separations $\\\\gtrsim\\\\!100{\\\\rm\\\\;\\\\mu s}$ the likelihood of\\nfinding another giant pulse is suppressed. In addition, our high sensitivity\\nenabled us to detect weak echo features in the brightest pulses (at\\n$\\\\sim\\\\!0.4\\\\%$ of the peak giant pulse flux), which are delayed by up to\\n$\\\\sim\\\\!300{\\\\rm\\\\;\\\\mu s}$.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "abstracts[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2Nk-DGxN0KZ",
        "outputId": "d5512852-0342-4d10-c6b8-9a945f24ae5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "# Download stopwords if needed\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "# Initialize stopwords and lemmatizer\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove numbers and special characters\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    text = re.sub(r'\\W+', ' ', text)\n",
        "\n",
        "    # Remove stop words and lemmatize\n",
        "    words = text.split()\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "\n",
        "    # Join words back into a single string\n",
        "    processed_text = ' '.join(words)\n",
        "\n",
        "    return processed_text\n",
        "\n",
        "# Apply preprocessing to all abstracts\n",
        "processed_abstracts = [preprocess_text(abstract) for abstract in abstracts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "MiMbi5uKOHqd",
        "outputId": "5cc8b719-ba44-46dc-e013-3889d143a1d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'analyzed four epoch beamformed evn data crab pulsar mhz high sensitivity resulting resolving crab nebula able detect even faint high frequency component folded profile also detect total giant pulse use investigate rate fluence phase arrival time distribution find main pulse component giant pulse represent total flux suggests nearly complete giant pulse energy distribution although obvious observed distribution could extended cover remaining flux without invoking large number faint burst every rotation looking difference arrival time subsequent burst single rotation confirm likelihood finding giant pulse close increased beyond expected randomly occurring burst giant pulse consist causally related microbursts typical separation sim rm mu also find evidence separation gtrsim rm mu likelihood finding another giant pulse suppressed addition high sensitivity enabled u detect weak echo feature brightest pulse sim peak giant pulse flux delayed sim rm mu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Display a processed abstract\n",
        "processed_abstracts[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "aGmD3sLQZdRk",
        "outputId": "a922c467-03c3-4bbe-8c94-edae0f724f02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                              title  \\\n",
              "0  2305.00379  Image Completion via Dual-path Cooperative Fil...   \n",
              "1  2307.16362  High Sensitivity Beamformed Observations of th...   \n",
              "2  2301.07687  Maybe, Maybe Not: A Survey on Uncertainty in V...   \n",
              "3  2309.09088  Enhancing GAN-Based Vocoders with Contrastive ...   \n",
              "4  2307.16404      Nonvolatile Magneto-Thermal Switching in MgB2   \n",
              "\n",
              "                                            abstract  \\\n",
              "0  Given the recent advances with image-generatin...   \n",
              "1  We analyzed four epochs of beamformed EVN data...   \n",
              "2  Understanding and evaluating uncertainty play ...   \n",
              "3  Vocoder models have recently achieved substant...   \n",
              "4  Ongoing research explores thermal switching ma...   \n",
              "\n",
              "                                             authors        published_date  \\\n",
              "0  Pourya Shamsolmoali, Masoumeh Zareapoor, Eric ...  2023-04-30T03:54:53Z   \n",
              "1                Rebecca Lin, Marten H. van Kerkwijk  2023-07-31T01:36:55Z   \n",
              "2                                       Krisha Mehta  2022-12-14T00:07:06Z   \n",
              "3  Haoming Guo, Seth Z. Zhao, Jiachen Lian, Gopal...  2023-09-16T20:04:16Z   \n",
              "4                  Hiroto Arima, Yoshikazu Mizuguchi  2023-07-31T04:59:19Z   \n",
              "\n",
              "                                link  \\\n",
              "0  http://arxiv.org/abs/2305.00379v1   \n",
              "1  http://arxiv.org/abs/2307.16362v2   \n",
              "2  http://arxiv.org/abs/2301.07687v1   \n",
              "3  http://arxiv.org/abs/2309.09088v2   \n",
              "4  http://arxiv.org/abs/2307.16404v1   \n",
              "\n",
              "                                            markdown  \\\n",
              "0  # Image Completion via Dual-Path Cooperative F...   \n",
              "1  # High Sensitivity Beamformed Observations of ...   \n",
              "2  # Maybe, Maybe Not: A Survey on Uncertainty in...   \n",
              "3  # Enhancing Gan-Based Vocoders with Contrastiv...   \n",
              "4  # Nonvolatile Magneto-Thermal Switching in MgB...   \n",
              "\n",
              "                                 processed_abstracts  \n",
              "0  given recent advance image generating algorith...  \n",
              "1  analyzed four epoch beamformed evn data crab p...  \n",
              "2  understanding evaluating uncertainty play key ...  \n",
              "3  vocoder model recently achieved substantial pr...  \n",
              "4  ongoing research explores thermal switching ma...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38fbe754-8b92-4fe8-9c6c-b93861937a47\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>authors</th>\n",
              "      <th>published_date</th>\n",
              "      <th>link</th>\n",
              "      <th>markdown</th>\n",
              "      <th>processed_abstracts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2305.00379</td>\n",
              "      <td>Image Completion via Dual-path Cooperative Fil...</td>\n",
              "      <td>Given the recent advances with image-generatin...</td>\n",
              "      <td>Pourya Shamsolmoali, Masoumeh Zareapoor, Eric ...</td>\n",
              "      <td>2023-04-30T03:54:53Z</td>\n",
              "      <td>http://arxiv.org/abs/2305.00379v1</td>\n",
              "      <td># Image Completion via Dual-Path Cooperative F...</td>\n",
              "      <td>given recent advance image generating algorith...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2307.16362</td>\n",
              "      <td>High Sensitivity Beamformed Observations of th...</td>\n",
              "      <td>We analyzed four epochs of beamformed EVN data...</td>\n",
              "      <td>Rebecca Lin, Marten H. van Kerkwijk</td>\n",
              "      <td>2023-07-31T01:36:55Z</td>\n",
              "      <td>http://arxiv.org/abs/2307.16362v2</td>\n",
              "      <td># High Sensitivity Beamformed Observations of ...</td>\n",
              "      <td>analyzed four epoch beamformed evn data crab p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2301.07687</td>\n",
              "      <td>Maybe, Maybe Not: A Survey on Uncertainty in V...</td>\n",
              "      <td>Understanding and evaluating uncertainty play ...</td>\n",
              "      <td>Krisha Mehta</td>\n",
              "      <td>2022-12-14T00:07:06Z</td>\n",
              "      <td>http://arxiv.org/abs/2301.07687v1</td>\n",
              "      <td># Maybe, Maybe Not: A Survey on Uncertainty in...</td>\n",
              "      <td>understanding evaluating uncertainty play key ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2309.09088</td>\n",
              "      <td>Enhancing GAN-Based Vocoders with Contrastive ...</td>\n",
              "      <td>Vocoder models have recently achieved substant...</td>\n",
              "      <td>Haoming Guo, Seth Z. Zhao, Jiachen Lian, Gopal...</td>\n",
              "      <td>2023-09-16T20:04:16Z</td>\n",
              "      <td>http://arxiv.org/abs/2309.09088v2</td>\n",
              "      <td># Enhancing Gan-Based Vocoders with Contrastiv...</td>\n",
              "      <td>vocoder model recently achieved substantial pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2307.16404</td>\n",
              "      <td>Nonvolatile Magneto-Thermal Switching in MgB2</td>\n",
              "      <td>Ongoing research explores thermal switching ma...</td>\n",
              "      <td>Hiroto Arima, Yoshikazu Mizuguchi</td>\n",
              "      <td>2023-07-31T04:59:19Z</td>\n",
              "      <td>http://arxiv.org/abs/2307.16404v1</td>\n",
              "      <td># Nonvolatile Magneto-Thermal Switching in MgB...</td>\n",
              "      <td>ongoing research explores thermal switching ma...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38fbe754-8b92-4fe8-9c6c-b93861937a47')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-38fbe754-8b92-4fe8-9c6c-b93861937a47 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-38fbe754-8b92-4fe8-9c6c-b93861937a47');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-486e65d8-0567-4fc0-89ec-bb4817c4b777\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-486e65d8-0567-4fc0-89ec-bb4817c4b777')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-486e65d8-0567-4fc0-89ec-bb4817c4b777 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 63357,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63357,\n        \"samples\": [\n          \"2307.06084\",\n          \"2306.00011\",\n          \"2307.07378\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63348,\n        \"samples\": [\n          \"Approximation-free control for unknown systems with performance and\\n  input constraints\",\n          \"A complex-scaled boundary integral equation for time-harmonic water\\n  waves\",\n          \"Zephyr : Stitching Heterogeneous Training Data with Normalizing Flows\\n  for Photometric Redshift Inference\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstract\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63355,\n        \"samples\": [\n          \"In this study, we investigate a cosmological model involving a negative\\ncosmological constant (AdS vacua in the dark energy sector). We consider a\\nquintessence field on top of a negative cosmological constant and study its\\nimpact on cosmological evolution and structure formation. We use the power\\nspectrum of the redshifted HI 21 cm brightness temperature maps from the\\npost-reionization epoch as a cosmological probe. The signature of baryon\\nacoustic oscillations (BAO) on the multipoles of the power spectrum is used to\\nextract measurements of the angular diameter distance $D_A(z)$ and the Hubble\\nparameter $H(z)$. The projected errors on these are then subsequently employed\\nto forecast the constraints on the model parameters ($\\\\Omega_\\\\Lambda, w_0,\\nw_a$) using Markov Chain Monte Carlo techniques. We find that a negative\\ncosmological constant with a phantom dark energy equation of state (EoS) and a\\nhigher value of $H_0$ is viable from BAO distance measurements data derived\\nfrom galaxy samples. We also find that BAO imprints on the 21cm power spectrum\\nobtained from a futuristic SKA-mid like experiment yield a $1-\\\\sigma$ error on\\na negative cosmological constant and the quintessence dark energy EoS\\nparameters to be $\\\\Omega_\\\\Lambda=-1.030^{0.589}_{-1.712}$ and\\n$w_0=-1.023^{0.043}_{-0.060}$, $w_a=-0.141^{0.478}_{-0.409}$ respectively.\",\n          \"Estimating the number of clusters and cluster structures in unlabeled,\\ncomplex, and high-dimensional datasets (like images) is challenging for\\ntraditional clustering algorithms. In recent years, a matrix reordering-based\\nalgorithm called Visual Assessment of Tendency (VAT), and its variants have\\nattracted many researchers from various domains to estimate the number of\\nclusters and inherent cluster structure present in the data. However, these\\nalgorithms face significant challenges when dealing with image data as they\\nfail to effectively capture the crucial features inherent in images. To\\novercome these limitations, we propose a deep-learning-based framework that\\nenables the assessment of cluster structure in complex image datasets. Our\\napproach utilizes a self-supervised deep neural network to generate\\nrepresentative embeddings for the data. These embeddings are then reduced to\\n2-dimension using t-distributed Stochastic Neighbour Embedding (t-SNE) and\\ninputted into VAT based algorithms to estimate the underlying cluster\\nstructure. Importantly, our framework does not rely on any prior knowledge of\\nthe number of clusters. Our proposed approach demonstrates superior performance\\ncompared to state-of-the-art VAT family algorithms and two other deep\\nclustering algorithms on four benchmark image datasets, namely MNIST, FMNIST,\\nCIFAR-10, and INTEL.\",\n          \"The development of computer vision and in-situ monitoring using visual\\nsensors allows the collection of large datasets from the additive manufacturing\\n(AM) process. Such datasets could be used with machine learning techniques to\\nimprove the quality of AM. This paper examines two scenarios: first, using\\nconvolutional neural networks (CNNs) to accurately classify defects in an image\\ndataset from AM and second, applying active learning techniques to the\\ndeveloped classification model. This allows the construction of a\\nhuman-in-the-loop mechanism to reduce the size of the data required to train\\nand generate training data.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"authors\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 60349,\n        \"samples\": [\n          \"Ken Trotti\",\n          \"Andrei O. Barvinsky, Nikita Kolganov\",\n          \"Shuai Jiang, Sayaka Kamei, Chen Li, Shengzhe Hou, Yasuhiko Morimoto\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"published_date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 62864,\n        \"samples\": [\n          \"2023-05-29T03:51:18Z\",\n          \"2023-10-24T18:55:32Z\",\n          \"2023-04-06T21:22:27Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63357,\n        \"samples\": [\n          \"http://arxiv.org/abs/2307.06084v1\",\n          \"http://arxiv.org/abs/2306.00011v2\",\n          \"http://arxiv.org/abs/2307.07378v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"markdown\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63357,\n        \"samples\": [\n          \"# Neuromorphic analog circuits for robust on-chip always-on learning in spiking neural networks\\n\\n###### Abstract\\n\\nMixed-signal neuromorphic systems represent a promising solution for solving extreme-edge computing tasks without relying on external computing resources. Their spiking neural network circuits are optimized for processing sensory data on-line in continuous-time. However, their low precision and high variability can severely limit their performance. To address this issue and improve their robustness to inhomogeneities and noise in both their internal state variables and external input signals, we designed on-chip learning circuits with short-term analog dynamics and long-term tristate discretization mechanisms. An additional hysteretic stop-learning mechanism is included to improve stability and automatically disable weight updates when necessary, to enable continuous always-on learning. We designed a spiking neural network with these learning circuits in a prototype chip using a \\\\(180\\\\,\\\\mathrm{nm}\\\\) CMOS technology. Simulation and silicon measurement results from the prototype chip are presented. These circuits enable the construction of large-scale spiking neural networks with online learning capabilities for real-world edge computing tasks.\\n\\n always-on learning, edge-computing, on-chip learning online, SNN, hysteresis, tristability.\\n\\n## I Introduction\\n\\nThe requirements of artificial intelligence (AI) systems operating at the edge are similar to those that living organisms face to function in daily life. They need to measure sensory signals in real-time, perform closed-loop interactions with their surroundings, be energy-efficient, and continuously adapt to changes in the environment and in their own internal state. These requisites are well supported by neuromorphic systems and emerging memory technologies that implement brain-inspired mixed-signal spiking neural network (SNN) architectures [1, 2, 3, 4, 5]. These types of SNNs operate in a data-driven manner, with an event-based representation that is typically sparse in both space and time. Since they compute only when data is present, they are very power efficient. Similar to the biological neural systems they model, these SNNs are particularly well-suited to processing real-world signals. They can be designed to operate at the same data-rate of the input streams in real-time by matching the time constants of neural computation with those of the incoming signal dynamics. However, similar to their biological counterparts, these systems are affected by a high degree of variability and sensitivity to noise. One of the most effective strategies that biology uses to cope with noise and variability is to utilize adaptation and plasticity. This strategy has also been adopted by the neuromorphic community: several on-chip implementations of spike-based learning circuits have been proposed in the past [6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]. However, few have addressed the problem of being able to operate robustly and autonomously in continuous time, with the ability to switch automatically and reliably between learning and inference modes. Following the original neuromorphic engineering approach [18], we propose a set of analog circuits that faithfully emulate synaptic plasticity mechanisms observed in pyramidal cells of cortical circuits and implement complex spike-based learning and state-dependent mechanisms that support this functionality. In addition, we extend the concept of long-term bi-stability of synaptic weights, proposed to increase robustness to noise and variability in the input signals [14, 19], to a tristate stability and weight discretization circuit that increases the resolution of the (stable and crystallized) synaptic weights. The synaptic plasticity circuits update an internal state variable of the synapse on every pre-synaptic input spike. The change in this state variable is computed in continuous time by the soma block of the neuron. In parallel, depending on its value, the internal variable is driven to one of three possible stable states and converted to a discrete three-state synaptic weight current value. The post-synaptic learning circuits comprise an additional mechanism that gates\\n\\nFig. 1: Micrograph of the prototype chip comprising of the learning circuits in a network of 4 neurons with 64 synapses each (see highlighted area). The chip, comprising of additional test structures, measures \\\\(3\\\\times 5\\\\,\\\\mathrm{mm}^{2}\\\\).\\nthe weight changes, to stop the learning process when the neuron's mean firing rate is outside a defined learning window. The circuits were fabricated on a prototype SNN chip designed in a 180 nm 6M1P CMOS technology and tested within a network of 4 neurons with 64 synapses each (see Fig. 1). In the following sections we describe the main building blocks used at both the synapse and neuron level, demonstrate their expected behavior with circuit simulations, and provide experimental results measured from the chip.\\n\\n## II Network architecture\\n\\nThe block diagram of each neuron in the network is shown in Fig. 2. Input digital events (\\\\(\\\\mathsf{x_{0-N}}\\\\)) arrive at the individual synapses via asynchronous logic [2] and trigger local weight update circuits to induce a change in the voltage stored on a local capacitor by an amount determined by the post-synaptic learning circuits. In parallel, a tristate stability circuit drives this internal voltage to one of three possible stable states. This local internal voltage is then discretized and converted to a low, intermediate or high current value. All currents produced by all synapses are summed spatially and conveyed to a differential pair integrator (DPI), which integrates the weighted sum over time [20]. A parallel and analogous pathway receives input events representing a desired target signal (\\\\(\\\\mathsf{x_{t}}\\\\)), and produces a corresponding current from its dedicated DPI circuit. The target and input currents are both summed to drive the neuron's postsynaptic Integrate & Fire (I&F) circuit [21], and subtracted to drive the soma's Delta rule circuit [22]. The Delta rule circuit produces either positive or negative weight update signals proportional to the difference between the target input and the weighted synaptic input. These signals are broadcast to all the neuron's input synapses in continuous time if learning is enabled. Learning is enabled (or disabled) by means of two hysteretic Winner-Take-All (hWTA) circuits [23] that compare the neuron's mean output firing rate to a low and a high threshold (see Section III-B for details).\\n\\n## III Circuits\\n\\nAs the details of the Delta rule and I&F circuits have already been presented [11, 21, 22], we describe the synapse learning circuits and the soma hWTA circuit.\\n\\n### _Plastic synapse circuit_\\n\\nFigure 3 presents all of the learning circuits used at the synaptic level. With every pre-synaptic spike, the weight update circuit (Fig. 2(a)) increases or decreases the internal analog weight variable \\\\(\\\\mathsf{V_{w}}\\\\) by an amount determined by the voltages \\\\(\\\\mathsf{V_{UP}}\\\\) and \\\\(\\\\mathsf{V_{DN}}\\\\), produced by the post-synaptic Delta rule circuits. The tri-stability supply voltage circuit (Fig. 2(b)), produces the biases that power either of the positive feedback amplifiers of Fig. 2(c), depending on the state of \\\\(\\\\mathsf{V_{w}}\\\\) with respect to \\\\(\\\\mathsf{V_{dd}}/2\\\\). The tri-stability circuit (Fig. 2(c)) consists of two slew-rate limited positive feedback amplifiers which slowly drive \\\\(\\\\mathsf{V_{w}}\\\\) towards ground, \\\\(\\\\mathsf{V_{dd}}/2\\\\), or \\\\(\\\\mathsf{V_{dd}}\\\\) depending on the value of \\\\(\\\\mathsf{V_{w}}\\\\) relative\\n\\nFig. 3: Synapse learning circuits. (a) The weight update circuit increases or decreases the internal analog weight variable \\\\(\\\\mathsf{V_{w}}\\\\) with every input spike \\\\(\\\\mathsf{V_{PRE}}\\\\); (b) The tri-stability supply voltage circuit determines which of the two amplifiers in (c) to power depending on the value of \\\\(\\\\mathsf{V_{w}}\\\\) with respect to \\\\(\\\\mathsf{V_{dd}}/2\\\\) by activating either \\\\(\\\\mathsf{V_{DH}}\\\\) or \\\\(\\\\mathsf{V_{DL}}\\\\). (c) The tristability circuit drives the \\\\(\\\\mathsf{V_{w}}\\\\) voltage towards ground, \\\\(\\\\mathsf{V_{dd}}/2\\\\) or \\\\(\\\\mathsf{V_{dd}}\\\\) depending on its value relative to \\\\(\\\\mathsf{V_{THH}}\\\\) and \\\\(\\\\mathsf{V_{THL}}\\\\). (d) The current discretization circuit converts \\\\(\\\\mathsf{V_{w}}\\\\) into a low (the leakage current \\\\(\\\\mathsf{I_{0}}\\\\)), intermediate, or high current.\\n\\nFig. 2: Block diagram of a single neuron row. The plastic synapses (in red) consist of input logic, a weight update, tristate stability, and a current ADC block. Input spikes arriving at a synapse update the internal weight variable \\\\(\\\\mathsf{V_{w}}\\\\), and change it by an amount that is determined by the post-synaptic learning circuits at the soma (in green). The weight voltage is slowly driven to one of three possible stable states, and converted into a synaptic current by thresholding circuits. A parallel pathway provides a target current (in blue). Both input and target currents are integrated over time by differential pair integrator (DPI) circuits. The soma (in green), comprises of an Integrate & Fire (I&F) block which integrates the sum of target and input currents, a Delta rule block that calculates the difference of the two DPI currents to determine the amplitude of the weight change, and a hysteretic Winner-Take-All (hWTA) block used to determine if and when to \\u201cstop-learning\\u201d.\\nto \\\\(\\\\mathsf{V_{THH}}\\\\) and \\\\(\\\\mathsf{V_{THL}}\\\\). The weight discretization circuit (Fig. (d)d) sets the value of the effective synaptic current \\\\(\\\\mathsf{l_{w}}\\\\) to \\\\(\\\\mathsf{l_{0}}\\\\), \\\\(\\\\mathsf{l_{wb}}\\\\), or \\\\(2\\\\mathsf{l_{wb}}\\\\) depending on the state of \\\\(\\\\mathsf{V_{w}}\\\\) with respect to \\\\(\\\\mathsf{V_{THL}}\\\\) and \\\\(\\\\mathsf{V_{THH}}\\\\).\\n\\n### _Hysteretic WTA for \\\"stop-learning\\\"_\\n\\nFigure 4 shows an instance of a hWTA circuit: it consists of two identical cells, (\\\\(M_{2}\\\\)-\\\\(M_{6}\\\\)) and (\\\\(M_{7}\\\\)-\\\\(M_{11}\\\\)) that compete with each other. As soon as one cell wins (e.g., the left one), the bias current \\\\(\\\\mathsf{l_{bn}}\\\\) is copied and added to the input current of the winning branch (e.g., \\\\(\\\\mathsf{l_{L}}\\\\)). This creates a hysteresis window, such that for the winning (left) cell to lose the competition, its input current has to decrease below the input current of the opposite branch by an additional factor equal to the bias current (\\\\(\\\\mathsf{l_{L}}<\\\\mathsf{l_{R}}-\\\\mathsf{l_{bn}}\\\\)). The output voltage of this circuit \\\\(\\\\mathsf{V_{OUT}}\\\\) switches to \\\"high\\\" when the left cell wins, and to \\\"low\\\" when the right cell becomes the winner.\\n\\nTo implement the \\\"stop-learning\\\" mechanism [14], we produce a current \\\\(\\\\mathsf{l_{Ca}}\\\\) (a surrogate of the neuron's calcium concentration) by integrating the post-synaptic neuron spikes with a DPI circuit [20]. We then compare this current to two thresholds with the two hWTA circuits. The digital output nodes of the two hWTA circuits were connected to logic gates to produce an active high \\\\(\\\\mathsf{Learn}\\\\) signal when the \\\\(\\\\mathsf{l_{Ca}}\\\\) current is within the set bounds (i.e., within the learning region) and a low when it is outside this region. This \\\\(\\\\mathsf{Learn}\\\\) signal is then used as a \\\"third factor\\\" to enable or disable the Delta rule weight circuit, and switch on or off the weight updates. The hysteresis windows of the hWTA circuits are used to distinguish between cases in which the target input is present (to enable learning) or absent (to disable learning and automatically switch to an \\\"inference\\\" mode). The effect of this window is described in Section IV-A.\\n\\n## IV Results\\n\\nWe validate the learning circuits with both circuit simulations and with experimental results measured from the fabricated chip.\\n\\n### _Circuit simulation results_\\n\\nHere, we show simulations of a single neuron and 40 plastic synapses during a learning task and show how the hWTA enables automatic switching from learning to inference.\\n\\nAfter initializing all synaptic weights to zero, we started a training phase by stimulating each plastic synapse with a \\\\(25\\\\,\\\\mathrm{Hz}\\\\) input spike train, and by sending a spike train with a \\\\(1\\\\,\\\\mathrm{kHz}\\\\) frequency to the target synapse. As expected, during this training phase, the weights of the synapses potentiated and the total weighted synaptic input current increased (see the red trace of Fig. 5). During the inference phase, we removed the target input spike train while keeping on stimulating the input synapses. As expected, without this extra input, the average\\n\\nFig. 4: hysteresis WTA circuit used to determine the \\u201cstop-learning\\u201d signals. The digital output voltage \\\\(\\\\mathsf{V_{OUT}}\\\\) switches from low to high only if the left input current \\\\(\\\\mathsf{l_{L}}\\\\) increases above \\\\(\\\\mathsf{l_{R}}\\\\) by an amount at least equal to \\\\(\\\\mathsf{l_{bh}}\\\\).\\n\\nFig. 5: Row simulation results. In the top plots of both sub-figures, the DPI synapse current (in red) follows the DPI target current (in blue) when the target input is high. The neuron\\u2019s membrane activity (in grey) is scaled for visibility. In the lower plots of both sub-figures the calcium current (in black) enables the \\\\(\\\\mathsf{Learn}\\\\) signal when it lies between the learning region\\u2019s low (green line) and high (red line) thresholds. (a) Small hysteresis bias (\\\\(\\\\mathsf{l_{bh}}=100\\\\,\\\\mathrm{pA}\\\\)): after the target current is removed the calcium current drops back into the learning region, the weights are decreased, and the neuron forgets its tuning (b) Large hysteresis bias (\\\\(\\\\mathsf{l_{bh}}=800\\\\,\\\\mathrm{pA}\\\\)): the large hysteresis region around the highest threshold (shaded pink) keeps the learning disabled, despite the fact that the calcium current fell below the high threshold. The weights of the plastic synapses do not change and the neuron maintains its proper tuning to the trained pattern.\\nmean firing rate of the neuron decreased, and the calcium concentration current fell below the upper bound of the learning region. Figure 5 shows this task performed with two values for \\\\(\\\\mathsf{b_{th}}\\\\), which governs the width of the hysteresis window. Without a proper hysteresis window (Fig. 4(a)), when the neuron falls back into a learning region it \\\"forgets\\\" its training (i.e., the learning circuits decrease the weights). On the other hand, by properly tuning the hysteresis window (Fig. 4(b)), the network remains in a \\\"stop-learning\\\" mode, and the neuron retains a high output firing rate response to the trained pattern, even in absence of a target signal. In the larger hysteresis window case, the total estimated power consumption is 1.07 uW, and a maximum (mean) energy of 740 pJ (680 pJ) is required to update the weights.\\n\\n### _Chip measurement results_\\n\\n#### Iv-B1 Tristability\\n\\nThe results from the measurements of the plastic synapse circuits are shown in Fig. 6. Initially, the neuron is presented with a high target activity, triggering large positive weight updates and causing a rapid increase in the synapse weight internal variable. Upon removal of the target, the weight is decreased. By increasing the power to the tristate stability amplifiers (Fig. 4(c)), i.e., by increasing \\\\(\\\\mathsf{b_{bs}}\\\\) of Fig. 4(b), the circuit opposes the weight changes more strongly and drives \\\\(\\\\mathsf{V_{w}}\\\\) to one of the three stable states more quickly. Stability at \\\\(\\\\mathsf{V_{dd}}\\\\) and ground is shown in Fig. 5(a) and at \\\\(\\\\mathsf{V_{dd}}\\\\)/2 in Fig. 5(b). Once the stimulation ends, the tristability circuit crystalizes the weight to one of the three stable states depending on the value of \\\\(\\\\mathsf{b_{bs}}\\\\).\\n\\n#### Iv-B2 Hysteresis for \\\"stop-learning\\\"\\n\\nFigure 7 shows the results of the characterization of the hysteretic calcium-based stop-learning mechanism. Similarly to the previous experiment, the neuron is initially stimulated with a high target activity, bringing it to the learning region. The plastic synapse weight rapidly increases, pushing the neuron into the \\\"stop-learning\\\" region. Once the target activity is removed, the neuron returns to the learning region, and, for small hysteresis window settings (top blue plot in Fig. 7), the plastic synapse decreases its weight as it is stimulated. For higher values of \\\\(\\\\mathsf{b_{th}}\\\\) the hysteresis window increases (orange plot in Fig. 7) and when the target is removed, the neuron's return to the learning mode is delayed. As this delay increases, even though the plastic synapse keeps on being stimulated, the neuron remains in the \\\"stop-learning\\\" region and the weight remains unchanged (purple plot in Fig. 7).\\n\\n## V Conclusions\\n\\nWe presented a set of analog circuits that enable learning in mixed-signal neuromorphic SNNs, with tristate stability and weight discretization circuits. By comparing the neuron's calcium concentration to lower and upper bounds, and by using hysteresis, we demonstrate effective always-on learning features, that automatically switch from learning mode to inference mode, without having to manually disable or enable learning. Comparisons to previous efforts are provided in Table I.\\n\\n## Acknowledgment\\n\\nThe authors thank Shyam Narayanan, Charlotte Frenkel, and Junren Chen for fruitful discussions and contributions.\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l l l l l l} \\\\hline \\\\hline  & [24] & [25] & [17] & [11] & [This work] \\\\\\\\ \\\\hline \\\\begin{tabular}{l} **Technology** \\\\\\\\ **Design** \\\\\\\\ **Learning** \\\\\\\\ **Stop** \\\\\\\\ **learning** \\\\\\\\ **Weight** \\\\\\\\ **resolution** \\\\\\\\ **Energy/SOP** \\\\\\\\ **Power** \\\\\\\\ **supply** \\\\\\\\ \\\\end{tabular} & \\\\begin{tabular}{l} 28 nm \\\\\\\\ digital \\\\\\\\ semi super- \\\\\\\\ vised \\\\\\\\ yes \\\\\\\\ yes \\\\\\\\ **Weight** \\\\\\\\ **22.7 pJ** \\\\\\\\ 0.55 V \\\\\\\\ \\\\end{tabular} & \\\\begin{tabular}{l} 14 nm \\\\\\\\ digital \\\\\\\\ program- \\\\\\\\ mobile \\\\\\\\ no \\\\\\\\ 120.75 V \\\\\\\\ \\\\end{tabular} & \\\\begin{tabular}{l} 180 nm \\\\\\\\ mixed- \\\\\\\\ signal super- \\\\\\\\ error based \\\\\\\\ yes \\\\\\\\ no \\\\\\\\ 120.75 V \\\\\\\\ \\\\end{tabular} & \\n\\\\begin{tabular}{l} 180 nm \\\\\\\\ mixed- \\\\\\\\ signal \\\\\\\\ error based \\\\\\\\ yes \\\\\\\\ yes \\\\\\\\ \\\\end{tabular} \\\\\\\\ \\\\hline \\\\hline \\\\end{tabular}\\n\\\\end{table} TABLE I: Comparison to the state-of-the-art\\n\\nFig. 6: Tristability chip measurements. (a) Stability at \\\\(\\\\mathsf{V_{dd}}\\\\) and ground: When the target is presented, the plastic synapse weight is increased by the post-synaptic learning circuits (\\\\(\\\\overline{\\\\mathsf{V_{up}}}\\\\) and \\\\(\\\\mathsf{V_{dn}}\\\\) scaled for visibility). As the tristability bias increases, the circuit opposes the weight update more strongly. When the target is removed, the tristability maintains the weight value around \\\\(\\\\mathsf{V_{dd}}\\\\) for larger values of \\\\(\\\\mathsf{b_{bs}}\\\\) (in orange and purple). (b) Stability at \\\\(\\\\mathsf{V_{dd}}\\\\)/2: as \\\\(\\\\mathsf{b_{bs}}\\\\) increases the tristability opposes the learning with more strength.\\n\\nFig. 7: Hysteresis chip measurements. The hysteresis window is shown for three different values of \\\\(\\\\mathsf{b_{th}}\\\\). Increases in \\\\(\\\\mathsf{b_{th}}\\\\) produce larger hysteresis windows which are useful for tuning the \\u201cstop-learning\\u201d properties of the network.\",\n          \"# DeepVAT: A Self-Supervised Technique for Cluster Assessment in Image Datasets\\n\\n###### Abstract\\n\\nEstimating the number of clusters and cluster structures in unlabeled, complex, and high-dimensional datasets (like images) is challenging for traditional clustering algorithms. In recent years, a matrix reordering-based algorithm called Visual Assessment of Tendency (VAT), and its variants have attracted many researchers from various domains to estimate the number of clusters and inherent cluster structure present in the data. However, these algorithms face significant challenges when dealing with image data as they fail to effectively capture the crucial features inherent in images. To overcome these limitations, we propose a deep-learning-based framework that enables the assessment of cluster structure in complex image datasets. Our approach utilizes a self-supervised deep neural network to generate representative embeddings for the data. These embeddings are then reduced to 2-dimension using t-distributed Stochastic Neighbour Embedding (t-SNE) and inputted into VAT based algorithms to estimate the underlying cluster structure. Importantly, our framework does not rely on any prior knowledge of the number of clusters. Our proposed approach demonstrates superior performance compared to state-of-the-art VAT family algorithms and two other deep clustering algorithms on four benchmark image datasets, namely MNIST, FMNIST, CIFAR-10, and INTEL.\\n\\n## 1 Introduction\\n\\nData clustering is a widely used unsupervised learning technique that involves dividing a collection of unlabeled objects into \\\\(k\\\\) groups of similar objects. Various clustering algorithms are available in the literature, such as hierarchical clustering, centroid-based approaches, density-based algorithms, and distribution-based clustering. Most clustering algorithms require \\\\(k\\\\), the number of clusters to seek, as an input, which is the clustering tendency assessment problem. One common method to determine the number of clusters and their underlying structure is to visualize the data points using a 2D or 3D plot. However, this approach is only feasible for two- or three-dimensional datasets. For high-dimensional datasets such as images, time-series, visualizing and interpreting cluster structures using 2D or 3D visualization is not practical. Although various dimensionality reduction techniques, such as principal component analysis (PCA) and linear discriminant analysis (LDA), exist in the literature, these techniques often result in a low-dimensional representation of complex, high-dimensional datasets that may not fully reflect the inherent cluster structure due to information loss.\\n\\nThere are various formal (based on statistics) and informal (other approaches) techniques [1, 2] available in the literature for cluster structure assessment, but they are not completely effective. In contrast, visual approaches [3] have been in use for many years and serve as the foundation for many visual data analysis methods. The _Visual Assessment of Clustering Tendency_ (VAT) [4], a matrix reordering-based visual-analytical method, is one of such algorithm which provides a visual way to assess the clustering tendency of various datasets. There are several variants of VAT available for different types of data, which are collectively known as the VAT family of algorithms. The VAT family of algorithms has become an acceptable and widely used tool in several domains like biomedical applications, speech processing, image segmentation, transportation applications, and _etc_ for exploratory data analysis.\\n\\nVAT algorithm employs a variant of Prim's minimum spanning tree algorithm [5] to perform matrix reordering of the pairwise dissimilarity matrix to generate a reordered dissimilarity matrix. The reordered dissimilarity matrix can be viewed as a monochrome image called a _Reordered Dissimilarity Image_ (RDI) or cluster heat map. The RDI displays\\na possible cluster structure of the data set by showing dark blocks (data points of low dissimilarity values) along the diagonal. One method to obtain an accurate estimate of the number of clusters (\\\\(k\\\\)) from the RDI in the data is to count the number of dark blocks along the diagonal of the RDI. That means VAT not only can be used for cluster tendency assessment but also can be used for subsequent clustering of the input datasets, without needing the number of clusters.\\n\\nThis method is particularly effective for datasets with well-separated, compact clusters since the dark blocks along the diagonal are easily identifiable. However, for complex datasets (e.g., images, time series) having overlapping cluster structures (which is the case for most real-life datasets), existing VAT approaches perform poorly as the RDI quality degrades and the contrast between dark blocks along the diagonal and the rest of the image decrease. This makes it difficult to count the dark blocks along the diagonal.\\n\\nThere have been some efforts [6, 7, 8] to improve the quality of VAT generated RDI to accurately estimate the number of clusters for various complex geometry datasets. The VAT family algorithms, commonly used for analyzing cluster structures, exhibit poor performance when applied to image datasets, especially those with overlapping clusters. In the typical workflow, images are flattened before employing the VAT algorithms, resulting in the loss of their crucial spatial features. Consequently, the pixel-wise Euclidean distance becomes less effective in accurately capturing similarities or dissimilarities between images due to the feature loss incurred during flattening and the curse of dimensionality. Figure 1 shows an _improved Visual Assessment of Tendency_ (iVAT) [6] RDI for a synthetic, high-dimensional dataset (number of samples = 1000, dimensions= \\\\(100\\\\)) having three well-separated Gaussian mixtures (so \\\\(k\\\\)=3) in View (a), and RDI for a sample of popular MNIST dataset (number of samples = 1000 dimensions= \\\\(784\\\\), \\\\(k=10\\\\) classes) in View (b). It is evident from the figure that iVAT performs well when the data has inherently well separated clusters as we can clearly see three dark blocks along the diagonal in its RDI representing three clusters. However, when it comes to image datasets like MNIST, it struggles to provide meaningful results, as the resulting RDI does not exhibit clear dark blocks along the diagonal. This limitation highlights the need for a VAT variant that can effectively preserve the essential features of images, enabling more accurate assessments of cluster structures in image datasets.\\n\\nAs unsupervised deep learning methods (like autoencoders [9] and contrastive learning [10]) excel at extracting robust features from complex images, it makes them well-suited for developing a dedicated VAT algorithm for image datasets.\\n\\nTo address the above concerns, we propose a novel visual-analytical framework called DeepVAT. DeepVAT utilizes deep learning techniques to extract meaningful deep features from images, enabling more effective assessment of cluster structures. Unlike traditional VAT approaches, DeepVAT can uncover hidden cluster structures within image data, even in situations where ground truth labels or information about the number of classes are unavailable. Our major contributions are as follows:\\n\\n1. We proposed a deep, self-supervised learning framework, DeepVAT, that can provide visual evidence of the number of clusters present in complex image datasets.\\n2. In our method, we did not incorporate any prior knowledge about the ground truth number of clusters of data.\\n3. We performed experiments on four real-world, publicly available, large image datasets to show the superiority of DeepVAT over other state-of-the-art VAT family algorithms (proposed for high-dimensional data) in terms of quality of RDI, clustering accuracy, and normalized mutual information (NMI) score.\\n\\nTo the best of our knowledge, our work represents the first investigation in the literature exploring the utilization of deep features from images in the context of VAT methods. This contribution highlights the importance of incorporating deep learning techniques in the development of VAT models for accurate and insightful analysis of image datasets.\\n\\nHere is an outline of the rest of this article. Section 2 presents the preliminaries for the VAT/iVAT algorithm and reviews related work. The proposed algorithm, DeepVAT, is discussed in Section 3. Section 4 discusses the experiments and results, followed by conclusions in Section 5.\\n\\n## 2 Preliminaries and Related work\\n\\n### VAT and iVAT\\n\\nConsider we have a set of \\\\(N\\\\) objects, denoted as \\\\(O=o_{1},o_{2},\\\\ldots,o_{N}\\\\), where each object in \\\\(O\\\\) is described by a \\\\(p\\\\)-dimensional feature vector (\\\\(\\\\in\\\\mathbb{R}^{p}\\\\)). Alternatively, the data can be represented as a dissimilarity matrix, denoted\\n\\nFigure 1: (a) iVAT image of 100-dimensional Compact and Separated (CS) Gaussian mixture data (3 Gaussians); (b) iVAT image of flattened MNIST data (784 dimensional)\\nas \\\\(D_{N}=[d_{ij}]\\\\), where \\\\(d_{ij}\\\\) indicates the dissimilarity between object \\\\(o_{i}\\\\) and object \\\\(o_{j}\\\\) computed using a suitable distance measure. The VAT algorithm considers the dissimilarity matrix, \\\\(D_{N}\\\\) as input and reorders (by shuffling the rows and columns) using a modified Prim's algorithm. The image \\\\(I(D_{N})\\\\) of the reordered distance matrix \\\\(D_{N}\\\\) displays each pixel's intensity to indicate the dissimilarity between the corresponding row and column objects. When dark blocks appear along the diagonal, they might represent distinct clusters, ideally \\\\(k\\\\) (the original number of clusters in data) clusters. As single-linkage clusters are always diagonally aligned in VAT ordered images [11], \\\\(k_{p}\\\\) aligned clusters can be obtained by cutting the largest \\\\((k_{p}-1)\\\\) edges (given by the MST cut magnitude order \\\\(d\\\\)) from the MST. Here, \\\\(k_{p}\\\\) is the estimated number of clusters from VAT/iVAT RDI.\\n\\nThe improved-VAT (iVAT) [6] enhances the quality of VAT [4] RDI by using path-based distance transformation. The iVAT transformed matrix \\\\(D_{N}^{{}^{\\\\prime}}=[d_{ij}^{{}^{\\\\prime}}]\\\\) is generated using a path-based minimax distance [5]:\\n\\n\\\\[d_{ij}^{{}^{\\\\prime}}=\\\\min_{p\\\\in P_{ij}}\\\\max_{1<h<|p|}\\\\textbf{D}_{p[h]p[h+1]} \\\\tag{1}\\\\]\\n\\nwhere \\\\(p\\\\in P_{ij}\\\\) is an acyclic path in the set of all acyclic paths between objects \\\\((o_{i})\\\\) and \\\\((o_{j})\\\\) (vertices \\\\(i\\\\) and \\\\(j\\\\)) in \\\\(O\\\\).\\n\\n### VAT Variants for Large Volumes of High-Dimensional Data\\n\\nAlthough the VAT tool, discussed above, finds its usefulness in many applications, it can be computationally expensive as the size of the data set grows due to its \\\\(\\\\mathcal{O}(N^{2})\\\\) complexity. To understand the clustering structure for large volume datasets, a scalable version of VAT called _scalable VAT_ (sVAT) was developed by Hathaway _et al._[12], which utilizes a smart sampling based approach. To begin, sVAT extracts a smart sample of size \\\\(n\\\\) (where \\\\(n<<N\\\\)) from the large data set \\\\(X\\\\) using _Maximin Random Sampling_ (MMRS) [13]. The extracted sample is then used to compute the distance matrix \\\\(D_{n}\\\\), which is input into VAT.\\n\\nTo handle large volumes of high-dimensional datasets, Rathore _et. al_ in [7] proposed FensiVAT, an ensemble-based, hybrid clustering framework that combines fast data-space reduction using random projection with an intelligent sampling strategy to assess the clustering tendency of high-dimensional data. Recently, Zhang _et al._[8] proposed another method that leverages a kernel-based dissimilarity matrix to refine the RDI further, called kernel-based iVAT (KernelVAT). They use a Gaussian kernel and Isolation kernel (data-dependent) to transform the RDI.\\n\\nThe SpecVAT [14] algorithm is another approach that improves the quality of the RDI produced by VAT. It utilizes spectral graph theory to transform the raw distance matrix into a graph embedding space using graph Laplacian. It then creates an alternative feature representation of the data by selecting the \\\\(r\\\\) most significant eigenvectors that correspond to the highest eigenvalues. VAT is then applied to this transformed representation, resulting in a much-improved RDI.\\n\\nTo our knowledge, none of the existing VAT family of algorithms, including those reviewed in this section, have been investigated thoroughly on image datasets. Moreover, they have been shown to perform poorly on image datasets in their numerical experiments. Below, we discuss our proposed framework, DeepVAT.\\n\\n## 3 Proposed Framework: DeepVAT\\n\\nIn this paper, we propose a deep learning-based framework, DeepVAT, to advance the VAT family of algorithms for cluster structure assessment in complex image datasets.\\n\\nFigure 2: The proposed architecture of DeepVAT\\nFigure 2 presents each step of our proposed framework. Below, we briefly explain each step of DeepVAT keyed to the blocks shown in figure 2.\\n\\n### Generating Image Embeddings\\n\\nThe first step in our framework is representation learning by employing deep learning architectures. The objective of this step is to attain a _cluster-friendly_ representation of images, which involves bringing similar data points closer to each other and pushing dissimilar points further away. While deep learning architectures like autoencoders can be explored for this purpose, they may lack the inherent capability to produce a truly _cluster-friendly_ representation.\\n\\nRecently, a wide range of self-supervised approaches such as contrastive learning based models has been proposed that can provide _cluster-friendly_ representations for images using deep neural networks, without the need for ground truth information. These models include _Simple Contrastive Learning of Representations_ (SimCLR) [10], Barlow Twins [15], _Decoupled Contrastive Learning_ (DCL) [16], SimSiam [17], _Bootstrap Your Own Latent_ (BYOL) [18], and many others.\\n\\nWe observed that incorporating SimCLR as the feature extractor in the DeepVAT pipeline led to significantly superior iVAT images compared to when an autoencoder was used as the feature extractor. The significant difference observed can be attributed to the inherent capabilities of SimCLR compared to basic autoencoders. SimCLR has the ability to effectively group similar points together and push dissimilar points apart, thanks to the InfoNCE loss it minimizes [19]. In contrast, basic autoencoders lack this inherent capability. Additionally, a recent study [20] suggests that the InfoNCE loss aids in learning cluster-preserving representations of images, further highlighting the suitability of SimCLR for DeepVAT. Hence, we chose SimCLR as our primary model for creating embeddings in our proposed framework.\\n\\nIn SimCLR, the first stage includes performing auxiliary tasks or a given batch of images, such as corrupting the data, adding noise, and creating augmented views of the same data. These transformations generate fresh views of the same images, effectively enlarging the training set. Gray-scale images cannot undergo certain transformations such as color jitters. Instead, an affine stretch is utilized along with rotation, resizing, and blurring. Through these tasks, the models can acquire a rich and beneficial representation of the data.\\n\\nSimCLR consists of an encoder network and a non-linear projection head. The augmented images are fed into the encoder to extract high-level features. The encoder consists of several convolutional and fully connected layers and is trained using a contrastive loss function. The SimCLR framework utilizes an InfoNCE loss function [19] to measure the similarity between different views of an image. The model aims to maximize the similarity between the two views of the same image and minimize the similarity between views of different images. By doing so, SimCLR learns to extract valuable features robust to variations in the input data, which is helpful for generalization in real-world scenarios. The encoder projects the images into (say) \\\\(d\\\\)-dimensional space.\\n\\nThen, the projection head, a small neural network, further maps the encoded features (\\\\(d\\\\)-dimensional) to a (lower) \\\\(m\\\\)-dimensional set of embeddings, and then back to a lower-manifold of \\\\(d\\\\)-dimensional space, resulting in a rank-deficient weight matrix. This projection head is trained alongside the encoder during training. After training successfully, the projection head is discarded, and the data is passed through the trained encoder to generate embeddings. The projection head serves as an additional non-linear transformation that helps to increase the quality of the learned features.\\n\\n### Dimensional Reduction using t-SNE\\n\\nDespite the fact that SimCLR embeddings (shown with a pink bar in figure 2) can be used to compute the dissimilarity matrix for VAT/iVAT, the high dimensionality of the SimCLR embeddings can lead to the curse of dimensionality problem, which can affect the quality of the resulting visualization. In our experiments, as discussed in Section 4, we observed that using SimCLR embeddings to compute the dissimilarity matrix did not result in a significant improvement in the quality of the resulting RDI for complex image datasets (CIFAR-10 [21] and INTEL [22]).\\n\\nOne way to tackle this issue is to apply t-SNE on a data representation obtained from SimCLR. Compared to the original flattened image data, t-SNE works better on SimCLR embeddings because SimCLR is a deep-layer architecture that can more efficiently represent the highly varying data manifold in multiple nonlinear layers [10, 23]. The projections generated by SimCLR's projection head can identify highly varying manifolds better than a local method like t-SNE, resulting in a higher quality visualization compared to using t-SNE on the original high-dimensional data [23]. However, it is important to acknowledge that representing the complete structure of intrinsically high-dimensional data in just two or three dimensions is fundamentally impossible, highlighting a fundamental limitation.\\n\\n### Smart Sampling: Maximin Random Sampling (MMRS)\\n\\nComputing and analyzing VAT RDI using t-SNE embeddings (shown with a pink bar in figure 2), generated in the last step, may be infeasible for image datasets with large samples \\\\((N)\\\\) due to \\\\(\\\\mathcal{O}(N^{2})\\\\) complexity of VAT. To deal with large image datasets, we exploit a smart sampling ap\\nproach called _Maximin and Random Sampling_ (MMRS).\\n\\nLet \\\\(\\\\textbf{X}=\\\\{x_{i}\\\\}_{i=1}^{N}\\\\) represent the set of t-SNE reduced embeddings obtained from the trained encoder, where \\\\(x_{i}\\\\in\\\\mathbb{R}^{2}\\\\). The MMRS technique is an intelligent way to obtain samples in large batch data sets by combining MaxiMin (MM) and Random Sampling (RS). The MM sampling process starts by identifying a set of \\\\(k^{{}^{\\\\prime}}\\\\) (an overestimate of \\\\(k\\\\)) distinguished objects, which are the farthest from each other in the input data **X**. Then each point in the set **X** is grouped with its nearest distinguished object using the nearest prototype rule (NPR) (mentioned in [7]), which divides the entire dataset into \\\\(k^{\\\\prime}\\\\) groups \\\\(\\\\{G_{i}\\\\}_{i=1}^{k^{{}^{\\\\prime}}}\\\\) where \\\\(G_{i}\\\\subseteq\\\\textbf{X}\\\\), \\\\(\\\\forall i\\\\in\\\\{1,2,\\\\ldots,k^{{}^{\\\\prime}}\\\\}\\\\) by associating \\\\(|G_{i}|\\\\) points to \\\\(i^{th}\\\\)_MM sample_, which represents each of the \\\\(k^{{}^{\\\\prime}}\\\\) group. Finally, the sample \\\\(\\\\mathcal{S}\\\\) of size \\\\(n<<N\\\\) is formed by selecting random data-points from each of the \\\\(k^{{}^{\\\\prime}}\\\\) groups \\\\(\\\\{G_{i}\\\\}_{i=1}^{k^{{}^{\\\\prime}}}\\\\). The number of points \\\\(n_{j}\\\\) extracted from group \\\\(G_{j}\\\\) is proportional to the cardinality of \\\\(G_{j}\\\\), i.e \\\\(n_{j}\\\\propto|G_{j}|\\\\). To be precise, \\\\(n_{j}=\\\\lceil n\\\\times|G_{j}|/N\\\\rceil\\\\), where \\\\(\\\\lceil\\\\cdot\\\\rceil\\\\) is the ceiling function. This step gives us a smart sample of size \\\\(n<<N\\\\) in lower dimensional space. Rather than feeding a large number of embeddings directly into iVAT for visualization, we feed a _smart sample_ of size \\\\(n\\\\), obtained using MMRS.\\n\\n### Dissimilarity Matrix Computation for VAT/iVAT\\n\\nThe reduced-dimension, smart samples are used to compute dissimilarity matrix \\\\(D_{n}\\\\) which is fed to the VAT/iVAT algorithm to obtain reordered dissimilarity matrix \\\\(D_{n}^{{}^{\\\\prime}}\\\\). The visualization of \\\\(I(D_{n}^{{}^{\\\\prime}})\\\\) suggests the number of clusters \\\\(k\\\\) present in the dataset.\\n\\n## 4 Experiments\\n\\nWe performed experiments on four publicly available, real, image datasets. We evaluated the ability of DeepVAT to suggest the number of clusters in image datasets and compared its performance with other VAT family methods that are claimed to work better with high-dimensional data. We also compare DeepVAT with two well known deep-clustering based methods. The experiments were conducted on a regular PC with the following configuration: OS: Ubuntu \\\\(22.04.2\\\\) LTS (64 bit); processor: Intel(R) Xeon(R) Gold \\\\(5220\\\\)R CPU @ \\\\(2.20\\\\)GHz; RAM: \\\\(62\\\\) GB; GPU: Nvidia Quadro RTX \\\\(6000\\\\), \\\\(24\\\\) GB.\\n\\n### Datasets\\n\\nWe performed our experiments on the following datasets:\\n\\n1. **MNIST**[24]: It has a total of \\\\(60,000\\\\) grayscale training images of digits with a dimension of \\\\(28*28\\\\) ranging from 0 to 9, i.e., total 10 classes, with each class having 6,000 images. The full training set is used in all experiments (60,000 images).\\n2. **FMNIST**[25]: It has a total of 60,000 grayscale training images of fashion apparel with a dimension of \\\\(28*28\\\\), i.e., it has a total of \\\\(10\\\\) classes, with each class having 6,000 images. The full training set is used in all experiments (60,000 images).\\n3. **CIFAR10**[21]: It has a total of \\\\(50,000\\\\) natural RGB training images with a dimension of \\\\(32*32*3\\\\). It has a total of \\\\(10\\\\) classes, with each class having \\\\(5,000\\\\) images. The full training set is used in all experiments (50,000 images).\\n4. **Intel Image Dataset**[22]: It has \\\\(14,034\\\\) natural RGB training images and 3,000 testing images with \\\\(6\\\\) classes. We clubbed both sets and used the final count of \\\\(17,000\\\\) images to perform various experiments. Each image has a dimension of \\\\(32*32*3\\\\).\\n\\n### Evaluation Criteria\\n\\nWe show all (best) iVAT images with an estimated number of clusters (\\\\(k_{p}\\\\)) for all the compared algorithms in Table 1. To estimate \\\\(k_{p}\\\\), we used the algorithm presented in [26]. As mentioned in section 2.1, \\\\(k_{p}\\\\) clusters can be obtained by cutting (\\\\(k_{p}\\\\)-_1_) edges in MST provided by VAT/iVAT algorithm. We used the predicted labels and ground truth information of each dataset to compute the partition accuracy (PA) for the estimated value of \\\\(k\\\\) (from iVAT image) and normalized mutual information (NMI). The PA of a clustering algorithm is the percentage (%) ratio of the number of samples with matching ground truth and algorithmic labels to the total number of samples in the dataset. To ensure consistent label mapping between the predicted and true labels, the Kuhn-Munkres algorithm [27] is employed to find the best mapping between the predicted and ground truth labels. A higher value of PA and NMI implies a better match to the ground truth partition.\\n\\n### Comparison of DeepVAT with other Models\\n\\nIn this section, we make a qualitative and quantitative comparison of DeepVAT with existing state-of-the-art VAT family methods that claim to work with high-dimensional and complex data (images when flattened can be seen as high-dimensional data). Specifically, we compare DeepVAT with the following methods:\\n\\n1. **VAT family methods** 1. **FensiVAT**: FensiiVAT [7] is applied on a small MMRS subset of the embeddings extracted from the trained encoder of SimCLR.\\n2. **KernelVAT**: KernelVAT [8]. is applied on a small MMRS subset of the embeddings extracted from the trained encoder of SimCLR. 3. **SpecVAT**: SpecVAT [14] is applied on a small MMRS subset of the embeddings extracted from the trained encoder of SimCLR.\\n2. **Deep-Clustering methods** 1. **DEC**[28]: iVAT is applied to the t-SNE reduced embeddings, extracted from the trained encoder of DEC. Specifically, iVAT is applied to a smaller MMRS subset. 2. **LSD-C**[29]: The t-SNE reduced embeddings, extracted from the trained encoder of DEC, are utilized for applying iVAT. More specifically, iVAT is applied to a smaller MMRS subset. 3. **Autoencoder + iVAT**: We trained a vanilla autoencoder and obtained embeddings from the trained encoder network. Subsequently, t-SNE is applied to these embeddings, and iVAT is then applied specifically to a smaller MMRS subset of the reduced embeddings.\\n\\n#### 4.3.1 Parameter Settings\\n\\nIn DeepVAT, the SimCLR model was trained using the LARS optimizer [30] for each dataset, with \\\\(1,000\\\\) epochs. The output dimension of the encoder network was set to \\\\(d=2,048\\\\), and the projection head network was chosen to have \\\\(m=128\\\\). We performed each experiment five times on each dataset and reported the average results. We use a batch size of \\\\(700\\\\) for MNIST and FMNIST and \\\\(256\\\\) for CIFAR10 and Intel Image Dataset. The parameters for MMRS sampling are \\\\(k^{\\\\prime}\\\\) = 15 for MNIST, FMNIST, and CIFAR10, and 10 for INTEL, number of samples, \\\\(n\\\\): 4,000 for all datasets.\\n\\nEuclidean distance is utilized as the metric to generate the RDI for the t-SNE reduced embeddings of the MNIST dataset. Likewise, in the ablation study discussed in Section 4.4, Euclidean distance is employed to generate the RDI for the t-SNE reduced embeddings of the raw-flattened MNIST data. For all other experiments, cosine dissimilarity is utilized as the dissimilarity measure to generate the RDI.\\n\\nThe input to all three VAT based methods is 2048-dimensional SimCLR embeddings as these methods transform the original data into a suitable embedding space/low dimensional space by virtue of their design. In KernelVAT, radial basis function (RBF) kernel is used, with the precision parameter (\\\\(\\\\gamma\\\\)) set to \\\\(0.05\\\\). In FensiVAT, the down-space (reduced) dimension for random projection is chosen \\\\(100\\\\) when FensiVAT is applied to a \\\\(2048\\\\)-dimensional SimCLR embedding. In SpecVAT, we performed iterations over the parameter _number of eigen-values_\\\\((r)\\\\) ranging from 1 to 10 and noted the best result.\\n\\nDEC [28] and LSD-C [29] heavily rely on prior information about the number of clusters in a dataset, while DeepVAT do not require this specific information. As stated in Section 4.3.1, we deliberately choose an overestimate for the number of clusters in all our experiments involving VAT algorithms. Consequently, for a fair comparison, we adopt the same overestimate (\\\\(k^{{}^{\\\\prime}}\\\\) = 15 for MNIST, FMNIST, and CIFAR-10, and \\\\(k^{{}^{\\\\prime}}\\\\) = 10 for INTEL) for DEC (which requires the value of \\\\(k\\\\) for performing \\\\(k\\\\)-means) and LSD-C (where the linear layer after the encoder has the same number of neurons as the number of classes).\\n\\nTo ensure fairness in the assessment, just like DeepVAT utilized t-SNE reduced embeddings from the SimCLR encoder, we also apply t-SNE to reduce the embeddings generated from the encoders of DEC and LSD-C to 2 dimensions before generating the RDI.\\n\\nWe keep all the parameter settings the same unless stated otherwise.\\n\\n### Ablation Study\\n\\n#### 4.4.1 Results and Discussions\\n\\nTable 1 shows the comparison of all six models based on the RDI quality and their ability to estimate the underlying clusters (\\\\(k_{p}\\\\)) accurately. Table 2 shows the comparison of DeepVAT with all the six methods mentioned above based on the PA and NMI.\\n\\nWe can see that the DeepVAT method generates much clearer and sharper dark blocks compared to the SpecVAT, KernelVAT, and FensiVAT models. Consequently, the number of dark blocks generated by DeepVAT (\\\\(k_{p}\\\\)) is close to the original number of classes (\\\\(k\\\\)) in the dataset, making it the most accurate in estimating the potential number of clusters compared to other algorithms. When applying FensiVAT and KernelVAT directly to the high-dimensional embedding, we observed that they produced blurry RDI (the cluster count is good but the quality of RDI is poor) and only achieved moderate quantitative results in terms of PA and NMI (refer Table 2) for simple datasets such as MNIST and FMNIST. However, when dealing with complex datasets like CIFAR-10 and INTEL, both algorithms failed to generate high-quality RDI and quantitative results (refer Table 2). Note that clustering algorithms face significant challenges when dealing with these datasets, as the ground truth labels may not accurately reflect distinct clusters within the feature vector representation of the data points. These results suggest that our approach produces more visually appealing and informative representations of the data.\\n\\nBased on the results presented in Table 2, DeepVAT demonstrates a significant performance advantage over state-of-the-art VAT family methods in terms of both PA and\\nNMI metrics. DeepVAT demonstrates its superiority over deep-clustering algorithms by achieving a 35% improvement in PA and 30% improvement in NMI. Furthermore, it outperforms simple autoencoders by an impressive 95% on PA and 203% on NMI metrics, clearly highlighting its remarkable performance. As a result, DeepVAT surpasses all six competitive models in both PA and NMI measures.\\n\\nThe success of DeepVAT can be attributed to the use of SimCLR and t-SNE. SimCLR is effective at generating a robust representation of the dataset by leveraging non-linear functions, such as deep CNN encoders and projection heads, to approximate its intrinsic dimensionality. By applying the proposed model to the best-performing model, DeepVAT achieves a better performance than the other models.\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{|c|c|c|c|c|c|c|c|} \\\\hline\\n**Dataset** & _FensiVAT_ & _KernelVAT_ & _SpecVAT_ & _DEC_ & _LSD-C_ & _Autoencoder_ & **Ours** \\\\\\\\ \\\\hline \\\\multirow{3}{*}{_MNIST_} & \\\\multirow{3}{*}{\\\\(k=10\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=10\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=8\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=3\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=15\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=7\\\\)} & \\\\multirow{3}{*}{\\\\(k_{p}=10\\\\)} \\\\\\\\  & & & & & & & \\\\\\\\ \\\\cline{1-1} \\\\cline{5-8} \\\\cline{8\\nplying t-SNE on the representation produced by SimCLR, we obtain a better low-dimensional embedding, as SimCLR is better equipped to detect highly varying manifolds than t-SNE alone.\\n\\nTo examine the impact of various components in our model, we perform a three-part ablation study on all four datasets. We systematically eliminate one component at a time from the DeepVAT pipeline (Fig. 2) to assess its reliance within the complete pipeline. Our model is summarised as **DeepVAT = SimCLR + t-SNE + MMRS + iVAT**.\\n\\n1. **DeepVAT _minus_ SimCLR**: We flatten each image in the dataset and apply t-SNE on top of them. Then we sample using MMRS and compute the final iVAT image for the samples. This will show that our model not only benefits from the t-SNE block.\\n2. **DeepVAT _minus_ t-SNE**: Images are passed through a trained SimCLR encoder, and we sample the learned high-dimensional embeddings using MMRS. The final iVAT image is computed on the sampled embeddings.\\n3. **DeepVAT _minus_ MMRS: iVAT image is computed on full set of embeddings. However, as iVAT/VAT family algorithms require computation of dissimilarity matrix, which has a time complexity of order \\\\(\\\\mathcal{O}(N^{2})\\\\), it will take hours to get the results. Hence, due to such large time complexity and resource constraint, we are not reporting the results of this ablation.\\n4. **DeepVAT _minus_ tSNE _minus_ SimCLR**: We apply iVAT directly on the MMRS sub-set of raw flattened images.\\n\\nThe findings of the ablation study (1) (Table 3) suggest that the generation of RDI by DeepVAT is not solely reliant on t-SNE. Although t-SNE applied directly to raw flattened images produces reasonably good results, it is not as accurate as DeepVAT. However, when dealing with complex datasets like CIFAR-10, utilizing t-SNE on raw flattened images fails to provide meaningful information about the cluster structure. Additionally, the role of the SimCLR module in DeepVAT is investigated in the study (2). The results in Table 3 indicate that SimCLR alone does not yield satisfactory outcomes, although it still demonstrates limited interpretability for simple datasets like MNIST and FM-NIST. Nevertheless, when iVAT is applied to SimCLR embeddings for complex datasets, it fails to convey meaningful results. This limitation may be attributed to the high dimensionality of the SimCLR embeddings (2048), which hinders the accurate inference of cluster presence by iVAT.\\n\\n## 5 Conclusions and Future Work\\n\\nThis article proposes a deep, self-supervised learning based VAT framework, DeepVAT, for cluster structure assessment in image data. The self-supervised learning method SimCLR significantly improved the performance of iVAT both qualitatively and quantitatively. Our experimental results suggest that when t-SNE is used as dimensionality reduction on top of SimCLR embeddings, the iVAT yields a much sharper RDI, thus a more accurate estimate of the number of clusters. This is because SimCLR can capture the intrinsic dimensionality of image datasets which helped t-SNE in generating a good low dimensional representation. Based on our numerical experiments on four image datasets, we have also shown that DeepVAT significantly outperformed other VAT family methods (FensiVAT, KernelVAT and SpecVAT) and two deep clustering methods (DEC and LSD-C) based on clustering partition accuracy (PA) and NMI. We believe that deploying more deep learning based models like deep metric learning and semi-supervised, which have partial access to labels can further improve the iVAT image for complex datasets.\\n\\nAt present, the training time for major self-supervised contrastive learning models is quite extensive. As part of our future work, we aim to focus on reducing the training time required for such models. Our objective is to develop methods that can generate high-quality iVAT images using self-supervised contrastive learning models in significantly less time.\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{|l|c|c|c|c|c|c|c|c|} \\\\hline \\\\multirow{2}{*}{\\n\\\\begin{tabular}{} \\\\end{tabular} } & \\\\multicolumn{2}{c|}{_MNIST_} & \\\\multicolumn{2}{c|}{_FMNIST_} & \\\\multicolumn{2}{c|}{_CIFAR-10_} & \\\\multicolumn{2}{c|}{_INTEL_} \\\\\\\\ \\\\cline{2-9}  & PA (\\\\%) & NMI & PA (\\\\%) & NMI & PA (\\\\%) & NMI & PA (\\\\%) & NMI \\\\\\\\ \\\\hline \\\\hline _Full DeepVAT_ & **82.02** & **0.89** & **43.76** & **0.61** & **51.26** & **0.47** & **56.84** & **0.46** \\\\\\\\ \\\\hline _DeepVAT_ minus _SimCLR_ & 37.27 & 0.51 & 29.87 & 0.51 & 18.25 & 0.07 & 31.27 & 0.15 \\\\\\\\ \\\\hline _DeepVAT_ minus _t-SNE_ & 40.73 & 0.60 & 30.61 & 0.52 & 10.14 & 0.01 & 17.52 & 0.007 \\\\\\\\ \\\\hline _DeepVAT_ minus _MMRS_ & \\u2013 & \\u2013 & \\u2013 & \\u2013 & \\u2013 & \\u2013 & \\u2013 & \\u2013 \\\\\\\\ \\\\hline _DeepVAT_ minus _SimCLR_ minus _t-SNE_ & 11.27 & 0.009 & 10.01 & 0.007 & 10.12 & 0.06 & 15.12 & 0.005 \\\\\\\\ \\\\hline \\\\end{tabular}\\n\\\\end{table}\\nTable 3: **Ablation study.** We analyze the effects of removing different blocks from the DeepVAT pipeline on PA and NMI.\",\n          \"# Defect Classification in Additive Manufacturing Using CNN-Based Vision Processing\\n\\n###### Abstract\\n\\nThe development of computer vision and in-situ monitoring using visual sensors allows the collection of large datasets from the additive manufacturing (AM) process. Such datasets could be used with machine learning techniques to improve the quality of AM. This paper examines two scenarios: first, using convolutional neural networks (CNNs) to accurately classify defects in an image dataset from AM and second, applying active learning techniques to the developed classification model. This allows the construction of a human-in-the-loop mechanism to reduce the size of the data required to train and generate training data.\\n\\n**Keywords:** Convolutional neural networks, additive manufacturing, defect classification, active learning\\n\\n## 1 Introduction\\n\\nLarge and openly available datasets of annotated images containing up to millions of training examples such as Pascal VOC [1] are available to machine learning researchers for many applications. This has enabled huge improvements in machine learning over recent years. By contrast, such openly available datasets are not available in the domain of Additive Manufacturing (AM) or 3D printing because labelled samples are difficult, expensive, and time-consuming to obtain as shown in [13] and [14]. As a result of poor data availability, researches in AM often have to use only a limited amount of labelled samples for training tasks before then leveraging a large number of unlabelled image data. Some researchers have called this the \\\"small data challenge in the big data era\\\" [15].\\n\\nTo overcome this challenge, we present a method that applies transfer learning and fine-tuning on a CNN-based neural network model to achieve accurate classification of manufacturing defects. This uses a dataset of images of the melt pool, created from the interaction between a laser and the materials used in manufacturing, taken during the AM process. Structural defects in the resulting output can sometimes be detected during manufacture from observations of the melt pool. Our technique involves using active learning algorithms to reduce the number of labelled samples required in the training process. We perform automatic labelling using the model to generate larger datasets of labelled images from unlabelled samples, for use in training.\\n\\n## 2 Methods\\n\\n_Transfer learning_ is a method that performs training a neural network model using data from a source domain then later applying the trained model to a target domain that is different from the source. This allows rapid progress in re-training and significantly reduces the required number of training samples in the target domain. It is commonly used in computer vision tasks such as classification to support improved performance in domains which are data-poor. In recent years, transfer learning has proved to be effective in the task of defect classification in AM, such as the work presented in [10] and [21] where transfer learning and fine-tuning were applied to the training of CNN based neural network architectures.\\n_Active learning_[Settles, 2009] is a technique for labelling data that selects and prioritises the most informative data points to submit to an annotator for labelling. Such prioritised data points have the highest potential impact on the supervised training of a machine learning model, thus accelerating the training process. The combination of transfer learning and active learning allows leveraging small amounts of labelled data to improve the performance of the training process of a deep learning model.\\n\\n## 3 Classification Experiments in Additive Manufacturing\\n\\nTo investigate the potential for transfer learning and active learning in the task of defect detection in AM, a case study was carried out using the open image dataset from [Westphal and Seitz, 2021]. This contains 4,000 images, manually divided into 2 different defect detection classes in AM. The images in this dataset are clearly separated into 3 balanced subsets for training (2,000), testing (1,000) and validation (1,000).\\n\\nTo conduct experiments, we employed a VGG16 based classifier from previous work which proved to be accurate in the task of defect classification on images generated from emission monitoring during additive manufacturing [Liu et al., 2022]. This classifier relies on transfer learning in which 13 convolutional layers from a pre-trained VGG16 model are used for feature extraction and the weights in these layers had been trained using ImageNet data. After the convolutional layers, 2 dense layers with ReLU activation function are added followed by 1 dense layer as the output layer using Sigmoid as the activation function, since the targeted dataset are divided into 2 classes for binary classification. In the original paper [Westphal and Seitz, 2021], the best classification performance is generated using a VGG16 based CNN model which is the reason we do not use a more recent model such as ResNet. We consider that as a baseline for further investigation in this study.\\n\\nThe tuning of hyperparameters involves adjusting the optimiser, learning rate, batch size and training epochs. There are 3 optimisers in the test we use which are Adam, SGD and RMSprop in combination with learning rate in a range from \\\\(10^{-2}\\\\) to \\\\(10^{-5}\\\\). We have also conducted training using different batch sizes (4, 32, 64) and training epochs (30, 60, 120). The cost function used in all tests is binary cross entropy. To reduce overfitting, weight regularisers are added to the 2 dense layers with the ReLU activation function mentioned above. The weight decay regulariser, also known as L2 regulariser which calculates the sum of the squared weights, is applied when initialising the keras model. The tuning of this hyperparameter is in a range from \\\\(10^{-1}\\\\) to \\\\(10^{-4}\\\\) and tested for multiple times until no obvious overfitting issue appears in the training and validation.\\n\\nAfter tuning on hyperparameters for multiple combinations, the best preforming combinations regarding the 3 types of optimisers are shown in Table 1 together with classification results on the validation dataset in comparison with the baseline from [Westphal and Seitz, 2021]. These initial tests were performed to check how adaptive our approach is on this dataset. The results show that all 3 optimisers can reach a value around 98% of the validation accuracy and our classification model is well-adapted to this dataset. The results also show that for this dataset a smaller batch size used in the training process such as 4, gives better performance and this can be explained as smaller batch sizes require more frequent weight updates during training. In turn this can help the model adjust its parameters more quickly and respond to changes in the data distribution which increases the model's ability to adapt to a new dataset. Finally, although not shown here, accuracy is stable thoughout the training showing no overfitting.\\n\\n## 4 Active Learning Experiments in Additive Manufacturing\\n\\nHaving developed a classifier which uses domain transfer across AM image datasets, we extended training to include active learning applied to further investigate classification performance during the progression of AL iterations. The second experiment was performed in a series of steps of (1) active sample section, (2) query for label, (3) train with queried sample, and (4) validate for current query iteration. The cycle iterates until a human supervisor decides to complete the training phase when validation accuracy achieves a target level.\\n\\nHere we apply a pool-based sampling scenario and an uncertainty sampling query strategy [Settles, 2009]. This is the most commonly used query strategy to start generalised sampling on this particular AM dataset.\\nThe implementation of active learning uses Python 3 and Google Colab. During the experiment, a classifier model is initialised and the optimser chosen is SGD as we found this gives more stabilised performance in the validation test and has minimal overfitting even when training is continued long after convergence. While Adam and RMSprop converge faster, there are larger fluctuations in the validation and minor overfitting after training reaches convergence. In addition, though SGD yields a result lower than the other 2 optimisers, it has slightly better potential that can be improved by applying active learning. During this experiment, 2,000 training samples were fed to the classifier with a total of 40 queries and for each query 50 samples were actively selected by the uncertainty sampling query strategy.\\n\\nThe selected and queried samples were assigned a label by an annotator after which the newly labelled samples were used to fine-tune the classifier to improve performance. This was evaluated using classification accuracy on the validation dataset at the end of each query iteration and later we show results on the test set.\\n\\nFollowing the inclusion of active learning, validation accuracy in each query iteration is shown in Figure 1 where results show that with the aid of active learning, the model reaches convergence after the 13th query and the value of validation accuracy is around 98%. More specifically, the calculated mean value from the 13th to 40th queries is 0.981 with a standard deviation of 0.0246 and a peak of 0.990. This is slightly higher than the result of the SGD optimiser based model shown in Table 1 and 1% higher than the baseline. Overall performance after convergence is also relatively stable. Results also show that the model only needs the first 650 most informative samples to achieve the best performance which is only 37.5% of the total 2,000 labelled training data.\\n\\nThis trained model was used to classify the labels on the testing dataset mentioned in Section 3, which is a balanced dataset consisting of 1,000 samples and the results are shown in Table 2.\\n\\n\\\\begin{table}\\n\\\\begin{tabular}{l c c|c|c c c c c} \\\\hline \\\\hline Experiment: & \\\\multirow{2}{*}{Batch} & \\\\multirow{2}{*}{Epochs} & \\\\multicolumn{2}{c}{Confusion} & \\\\multirow{2}{*}{Accuracy} & \\\\multirow{2}{*}{Precision} & \\\\multirow{2}{*}{Recall} & \\\\multirow{2}{*}{F1-Score} & \\\\multirow{2}{*}{AUC} \\\\\\\\ Optimiser, learning rate & & & & matrix & & & & \\\\\\\\ \\\\hline Baseline & 64 & 30 & 496 & 4* & 0.977* & 0.992* & 0.963* & 0.977* & 0.993 \\\\\\\\ \\\\cline{3-10}  & & & 19 & 481 & & & & \\\\\\\\ \\\\hline SGD, lr=0.01 & 4 & 60 & 483 & 17 & 0.979 & 0.967 & 0.992 & 0.979 & 0.998 \\\\\\\\ \\\\cline{3-10}  & & & 4 & 496 & & & & \\\\\\\\ \\\\hline Adam, lr =0.00001 & 4 & 120 & 490 & 10 & 0.988 & 0.980 & 0.996 & 0.988 & 0.998 \\\\\\\\ \\\\cline{3-10}  & & & 2 & 498 & & & & \\\\\\\\ \\\\hline RMSprop lr =0.00001 & 4 & 60 & 485 & 15 & 0.982 & 0.971 & 0.994 & 0.982 & 0.997 \\\\\\\\ \\\\cline{3-10}  & & & 3 & 497 & & & & \\\\\\\\ \\\\hline \\\\hline \\\\end{tabular}\\n\\\\end{table}\\nTable 1: Best performing hyperparameters for each optimiser, performance results on the validation set. Results marked \\u2018*\\u2019 are updates provided directly to us by the authors of [21] in response to us pointing out errors in the original paper. An author correction to the copy of record is now underway.\\n\\nFigure 1: classification accuracy on the validation dataset at the end of each query iteration\\n## 5 Conclusions\\n\\nThis paper presents an investigation into performance of a computer vision based classification task on a dataset from the additive manufacturing process. We use a CNN based classifier in combination with transfer learning and active learning strategies. We improved the overall validation accuracy to about 98%. We also conducted experiments to investigate the approximate minimum number of labelled samples needed to reach convergence in training. In future work we plan to further investigate the sampling strategies for active learning especially regarding class imbalance problems. We will involve approaches from semi-supervised learning to reinforce the labelling and self training as an extension to the current active learning mechanism.\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_abstracts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 63352,\n        \"samples\": [\n          \"attribute graph ubiquitous multimedia application graph representation learning grl successful analyzing attribute graph data however incomplete graph data missing node attribute negative impact medium knowledge discovery existing method handling attribute missing graph limited assumption fail capture complex attribute graph dependency address challenge propose attribute missing graph contrastive learning amgcl framework handling missing node attribute attribute graph data amgcl leverage dirichlet energy minimization based feature precoding encode missing attribute self supervised graph augmentation contrastive learning structure gacls learn latent variable encoded data specifically amgcl utilizies feature reconstruction based structure attribute energy minimization maximizes lower bound evidence latent representation mutual information experimental result multiple real world datasets demonstrate amgcl outperforms state art method feature imputation node classification task indicating effectiveness proposed method real world attribute graph analysis task\",\n          \"estimating number cluster cluster structure unlabeled complex high dimensional datasets like image challenging traditional clustering algorithm recent year matrix reordering based algorithm called visual assessment tendency vat variant attracted many researcher various domain estimate number cluster inherent cluster structure present data however algorithm face significant challenge dealing image data fail effectively capture crucial feature inherent image overcome limitation propose deep learning based framework enables assessment cluster structure complex image datasets approach utilizes self supervised deep neural network generate representative embeddings data embeddings reduced dimension using distributed stochastic neighbour embedding sne inputted vat based algorithm estimate underlying cluster structure importantly framework rely prior knowledge number cluster proposed approach demonstrates superior performance compared state art vat family algorithm two deep clustering algorithm four benchmark image datasets namely mnist fmnist cifar intel\",\n          \"development computer vision situ monitoring using visual sensor allows collection large datasets additive manufacturing process datasets could used machine learning technique improve quality paper examines two scenario first using convolutional neural network cnns accurately classify defect image dataset second applying active learning technique developed classification model allows construction human loop mechanism reduce size data required train generate training data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df['processed_abstracts']=processed_abstracts\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GC7GEhXSRIiN"
      },
      "source": [
        "## Apply BERTopic for Topic Modeling\n",
        "\n",
        "With our preprocessed abstracts, weâll apply BERTopic to identify topics. BERTopic uses BERT embeddings combined with clustering techniques to find patterns in text, making it ideal for identifying scientific themes in research abstracts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "q-ej2EcSRBkl"
      },
      "outputs": [],
      "source": [
        "from umap import UMAP\n",
        "from hdbscan import HDBSCAN\n",
        "from bertopic import BERTopic\n",
        "\n",
        "topic_model = BERTopic(\n",
        "    embedding_model=\"all-MiniLM-L6-v2\",   # Efficient embedding model for quick computation\n",
        "    umap_model=UMAP(\n",
        "        n_neighbors=10,                  # Lower neighbors for tighter clusters\n",
        "        n_components=5,                  # Dimensionality reduction\n",
        "        min_dist=0.1,                    # Slight separation between clusters\n",
        "        metric='cosine'                  # Cosine similarity for text data\n",
        "    ),\n",
        "    hdbscan_model=HDBSCAN(\n",
        "        min_cluster_size=60,             # Increase to reduce topic count\n",
        "        min_samples=15,                   # Fewer samples to prevent fragmentation\n",
        "        metric='euclidean',              # Works well with UMAP output\n",
        "        cluster_selection_method='eom'   # Keeps distinct clusters\n",
        "    ),                       # Target topic count, reduces smaller ones\n",
        "    top_n_words=10                       # Top words per topic\n",
        ")\n",
        "\n",
        "# Fit the model on the preprocessed abstracts\n",
        "topics,probs= topic_model.fit_transform(processed_abstracts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Save the BERTopic model\n",
        "with open(\"bertopic_model.pkl\", \"wb\") as f:\n",
        "    pickle.dump(topic_model, f)\n",
        "\n",
        "# Save the list of topics\n",
        "with open(\"topics_list.pkl\", \"wb\") as f:\n",
        "    pickle.dump(topics, f)\n"
      ],
      "metadata": {
        "id": "FTWx7mibNy2Z"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "DUzP3gviUlL_",
        "outputId": "abcd599c-e97a-4c9e-b9a5-c9c757a791af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               id                                              title  \\\n",
              "1      2307.16362  High Sensitivity Beamformed Observations of th...   \n",
              "3      2309.09088  Enhancing GAN-Based Vocoders with Contrastive ...   \n",
              "4      2307.16404      Nonvolatile Magneto-Thermal Switching in MgB2   \n",
              "6      2304.00044                   On The Theory of Ring Afterglows   \n",
              "8      2309.07927  Kid-Whisper: Towards Bridging the Performance ...   \n",
              "...           ...                                                ...   \n",
              "63350  2305.10173  Quantum theory without the Axiom of choice, an...   \n",
              "63351  2307.11414                     The Derived Deligne Conjecture   \n",
              "63352  2306.06241                      Almost paratopological groups   \n",
              "63354  2303.04288  Polynomial Time and Private Learning of Unboun...   \n",
              "63356  2310.02919  Attention-based Multi-task Learning for Base E...   \n",
              "\n",
              "                                                abstract  \\\n",
              "1      We analyzed four epochs of beamformed EVN data...   \n",
              "3      Vocoder models have recently achieved substant...   \n",
              "4      Ongoing research explores thermal switching ma...   \n",
              "6      Synchrotron and inverse Compton emission succe...   \n",
              "8      Recent advancements in Automatic Speech Recogn...   \n",
              "...                                                  ...   \n",
              "63350  In this conceptual paper, we discuss quantum f...   \n",
              "63351  Derived $A_\\infty$-algebras have a wealth of t...   \n",
              "63352  A class of almost paratopological groups is in...   \n",
              "63354  We study the problem of privately estimating t...   \n",
              "63356  Human genetic diseases often arise from point ...   \n",
              "\n",
              "                                                 authors  \\\n",
              "1                    Rebecca Lin, Marten H. van Kerkwijk   \n",
              "3      Haoming Guo, Seth Z. Zhao, Jiachen Lian, Gopal...   \n",
              "4                      Hiroto Arima, Yoshikazu Mizuguchi   \n",
              "6            Marcus DuPont, Andrew MacFadyen, Re'em Sari   \n",
              "8      Ahmed Adel Attia, Jing Liu, Wei Ai, Dorottya D...   \n",
              "...                                                  ...   \n",
              "63350                                          Koen Thas   \n",
              "63351         Javier Aguilar MartÃ­n, Constanze Roitzheim   \n",
              "63352                                Evgenii Reznichenko   \n",
              "63354     Jamil Arbas, Hassan Ashtiani, Christopher Liaw   \n",
              "63356   Amina Mollaysa, Ahmed Allam, Michael Krauthammer   \n",
              "\n",
              "             published_date                               link  \\\n",
              "1      2023-07-31T01:36:55Z  http://arxiv.org/abs/2307.16362v2   \n",
              "3      2023-09-16T20:04:16Z  http://arxiv.org/abs/2309.09088v2   \n",
              "4      2023-07-31T04:59:19Z  http://arxiv.org/abs/2307.16404v1   \n",
              "6      2023-03-31T18:02:12Z  http://arxiv.org/abs/2304.00044v1   \n",
              "8      2023-09-12T06:58:18Z  http://arxiv.org/abs/2309.07927v3   \n",
              "...                     ...                                ...   \n",
              "63350  2023-05-17T12:57:19Z  http://arxiv.org/abs/2305.10173v1   \n",
              "63351  2023-07-21T08:16:23Z  http://arxiv.org/abs/2307.11414v3   \n",
              "63352  2023-06-09T20:27:33Z  http://arxiv.org/abs/2306.06241v2   \n",
              "63354  2023-03-07T23:24:27Z  http://arxiv.org/abs/2303.04288v2   \n",
              "63356  2023-10-04T16:01:06Z  http://arxiv.org/abs/2310.02919v2   \n",
              "\n",
              "                                                markdown  \\\n",
              "1      # High Sensitivity Beamformed Observations of ...   \n",
              "3      # Enhancing Gan-Based Vocoders with Contrastiv...   \n",
              "4      # Nonvolatile Magneto-Thermal Switching in MgB...   \n",
              "6      # On The Theory of Ring Afterglows\\n\\n###### A...   \n",
              "8      Kid-Whisper: Towards Bridging the Performance ...   \n",
              "...                                                  ...   \n",
              "63350  # Quantum theory without the axiom of choice, ...   \n",
              "63351  # The derived Deligne conjecture\\n\\n###### Abs...   \n",
              "63352  # Almost paratopological groups\\n\\n###### Abst...   \n",
              "63354  # Polynomial Time and Private Learning of Unbo...   \n",
              "63356  # Attention-based Multi-task Learning for Base...   \n",
              "\n",
              "                                     processed_abstracts  topic  \n",
              "1      analyzed four epoch beamformed evn data crab p...      0  \n",
              "3      vocoder model recently achieved substantial pr...      5  \n",
              "4      ongoing research explores thermal switching ma...      1  \n",
              "6      synchrotron inverse compton emission successfu...      0  \n",
              "8      recent advancement automatic speech recognitio...      5  \n",
              "...                                                  ...    ...  \n",
              "63350  conceptual paper discus quantum formalism use ...      1  \n",
              "63351  derived a_ infty algebra wealth theoretical ad...      2  \n",
              "63352  class almost paratopological group introduced ...      2  \n",
              "63354  study problem privately estimating parameter d...     62  \n",
              "63356  human genetic disease often arise point mutati...     49  \n",
              "\n",
              "[42636 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b8086161-d24c-4b53-961e-2739869f232b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>authors</th>\n",
              "      <th>published_date</th>\n",
              "      <th>link</th>\n",
              "      <th>markdown</th>\n",
              "      <th>processed_abstracts</th>\n",
              "      <th>topic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2307.16362</td>\n",
              "      <td>High Sensitivity Beamformed Observations of th...</td>\n",
              "      <td>We analyzed four epochs of beamformed EVN data...</td>\n",
              "      <td>Rebecca Lin, Marten H. van Kerkwijk</td>\n",
              "      <td>2023-07-31T01:36:55Z</td>\n",
              "      <td>http://arxiv.org/abs/2307.16362v2</td>\n",
              "      <td># High Sensitivity Beamformed Observations of ...</td>\n",
              "      <td>analyzed four epoch beamformed evn data crab p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2309.09088</td>\n",
              "      <td>Enhancing GAN-Based Vocoders with Contrastive ...</td>\n",
              "      <td>Vocoder models have recently achieved substant...</td>\n",
              "      <td>Haoming Guo, Seth Z. Zhao, Jiachen Lian, Gopal...</td>\n",
              "      <td>2023-09-16T20:04:16Z</td>\n",
              "      <td>http://arxiv.org/abs/2309.09088v2</td>\n",
              "      <td># Enhancing Gan-Based Vocoders with Contrastiv...</td>\n",
              "      <td>vocoder model recently achieved substantial pr...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2307.16404</td>\n",
              "      <td>Nonvolatile Magneto-Thermal Switching in MgB2</td>\n",
              "      <td>Ongoing research explores thermal switching ma...</td>\n",
              "      <td>Hiroto Arima, Yoshikazu Mizuguchi</td>\n",
              "      <td>2023-07-31T04:59:19Z</td>\n",
              "      <td>http://arxiv.org/abs/2307.16404v1</td>\n",
              "      <td># Nonvolatile Magneto-Thermal Switching in MgB...</td>\n",
              "      <td>ongoing research explores thermal switching ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2304.00044</td>\n",
              "      <td>On The Theory of Ring Afterglows</td>\n",
              "      <td>Synchrotron and inverse Compton emission succe...</td>\n",
              "      <td>Marcus DuPont, Andrew MacFadyen, Re'em Sari</td>\n",
              "      <td>2023-03-31T18:02:12Z</td>\n",
              "      <td>http://arxiv.org/abs/2304.00044v1</td>\n",
              "      <td># On The Theory of Ring Afterglows\\n\\n###### A...</td>\n",
              "      <td>synchrotron inverse compton emission successfu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2309.07927</td>\n",
              "      <td>Kid-Whisper: Towards Bridging the Performance ...</td>\n",
              "      <td>Recent advancements in Automatic Speech Recogn...</td>\n",
              "      <td>Ahmed Adel Attia, Jing Liu, Wei Ai, Dorottya D...</td>\n",
              "      <td>2023-09-12T06:58:18Z</td>\n",
              "      <td>http://arxiv.org/abs/2309.07927v3</td>\n",
              "      <td>Kid-Whisper: Towards Bridging the Performance ...</td>\n",
              "      <td>recent advancement automatic speech recognitio...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63350</th>\n",
              "      <td>2305.10173</td>\n",
              "      <td>Quantum theory without the Axiom of choice, an...</td>\n",
              "      <td>In this conceptual paper, we discuss quantum f...</td>\n",
              "      <td>Koen Thas</td>\n",
              "      <td>2023-05-17T12:57:19Z</td>\n",
              "      <td>http://arxiv.org/abs/2305.10173v1</td>\n",
              "      <td># Quantum theory without the axiom of choice, ...</td>\n",
              "      <td>conceptual paper discus quantum formalism use ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63351</th>\n",
              "      <td>2307.11414</td>\n",
              "      <td>The Derived Deligne Conjecture</td>\n",
              "      <td>Derived $A_\\infty$-algebras have a wealth of t...</td>\n",
              "      <td>Javier Aguilar MartÃ­n, Constanze Roitzheim</td>\n",
              "      <td>2023-07-21T08:16:23Z</td>\n",
              "      <td>http://arxiv.org/abs/2307.11414v3</td>\n",
              "      <td># The derived Deligne conjecture\\n\\n###### Abs...</td>\n",
              "      <td>derived a_ infty algebra wealth theoretical ad...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63352</th>\n",
              "      <td>2306.06241</td>\n",
              "      <td>Almost paratopological groups</td>\n",
              "      <td>A class of almost paratopological groups is in...</td>\n",
              "      <td>Evgenii Reznichenko</td>\n",
              "      <td>2023-06-09T20:27:33Z</td>\n",
              "      <td>http://arxiv.org/abs/2306.06241v2</td>\n",
              "      <td># Almost paratopological groups\\n\\n###### Abst...</td>\n",
              "      <td>class almost paratopological group introduced ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63354</th>\n",
              "      <td>2303.04288</td>\n",
              "      <td>Polynomial Time and Private Learning of Unboun...</td>\n",
              "      <td>We study the problem of privately estimating t...</td>\n",
              "      <td>Jamil Arbas, Hassan Ashtiani, Christopher Liaw</td>\n",
              "      <td>2023-03-07T23:24:27Z</td>\n",
              "      <td>http://arxiv.org/abs/2303.04288v2</td>\n",
              "      <td># Polynomial Time and Private Learning of Unbo...</td>\n",
              "      <td>study problem privately estimating parameter d...</td>\n",
              "      <td>62</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63356</th>\n",
              "      <td>2310.02919</td>\n",
              "      <td>Attention-based Multi-task Learning for Base E...</td>\n",
              "      <td>Human genetic diseases often arise from point ...</td>\n",
              "      <td>Amina Mollaysa, Ahmed Allam, Michael Krauthammer</td>\n",
              "      <td>2023-10-04T16:01:06Z</td>\n",
              "      <td>http://arxiv.org/abs/2310.02919v2</td>\n",
              "      <td># Attention-based Multi-task Learning for Base...</td>\n",
              "      <td>human genetic disease often arise point mutati...</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42636 rows Ã 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8086161-d24c-4b53-961e-2739869f232b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b8086161-d24c-4b53-961e-2739869f232b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b8086161-d24c-4b53-961e-2739869f232b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bbc3580a-c59c-42e0-b8bf-7130b9b8d226\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bbc3580a-c59c-42e0-b8bf-7130b9b8d226')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bbc3580a-c59c-42e0-b8bf-7130b9b8d226 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_b2899a34-00e2-42b6-9200-8000ae4cc690\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_filtered')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_b2899a34-00e2-42b6-9200-8000ae4cc690 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_filtered');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_filtered",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "df['topic'] = topics\n",
        "df_filtered = df[df['topic'] != -1]\n",
        "df_filtered"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "wCP5SYFqUZ2-",
        "outputId": "18a52d72-de3a-4155-8ef2-0eb4f753ae76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Topic  Count                                               Name  \\\n",
              "0      -1  20721                          -1_model_data_method_task   \n",
              "1       0   9571                          0_mass_star_galaxy_energy   \n",
              "2       1   7030                         1_quantum_state_spin_phase   \n",
              "3       2   3053                    2_group_algebra_mathbb_category   \n",
              "4       3   1418               3_image_segmentation_medical_imaging   \n",
              "..    ...    ...                                                ...   \n",
              "92     91     63      91_summarization_summary_document_abstractive   \n",
              "93     92     63              92_sentence_embeddings_word_embedding   \n",
              "94     93     62  93_entropy_thermodynamics_thermodynamic_equili...   \n",
              "95     94     60           94_distributed_consensus_agent_algorithm   \n",
              "96     95     60                95_aerial_flight_control_trajectory   \n",
              "\n",
              "                                       Representation  \\\n",
              "0   [model, data, method, task, learning, based, a...   \n",
              "1   [mass, star, galaxy, energy, hole, field, blac...   \n",
              "2   [quantum, state, spin, phase, magnetic, system...   \n",
              "3   [group, algebra, mathbb, category, prove, mani...   \n",
              "4   [image, segmentation, medical, imaging, mri, m...   \n",
              "..                                                ...   \n",
              "92  [summarization, summary, document, abstractive...   \n",
              "93  [sentence, embeddings, word, embedding, simila...   \n",
              "94  [entropy, thermodynamics, thermodynamic, equil...   \n",
              "95  [distributed, consensus, agent, algorithm, con...   \n",
              "96  [aerial, flight, control, trajectory, quadroto...   \n",
              "\n",
              "                                  Representative_Docs  \n",
              "0   [vision system see reason compositional nature...  \n",
              "1   [perform new general relativistic viscous radi...  \n",
              "2   [electronic state calculation using quantum co...  \n",
              "3   [mapping class group x smooth manifold x group...  \n",
              "4   [accurate medical image segmentation utmost im...  \n",
              "..                                                ...  \n",
              "92  [natural language processing booming applicati...  \n",
              "93  [sentence embeddings enable u capture semantic...  \n",
              "94  [paper investigates generalized thermodynamic ...  \n",
              "95  [paper develops novel approach consensus probl...  \n",
              "96  [paper study motion planning problem pick plac...  \n",
              "\n",
              "[97 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21b130b6-bcf8-496f-944e-22cbece62246\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "      <th>Representation</th>\n",
              "      <th>Representative_Docs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>20721</td>\n",
              "      <td>-1_model_data_method_task</td>\n",
              "      <td>[model, data, method, task, learning, based, a...</td>\n",
              "      <td>[vision system see reason compositional nature...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>9571</td>\n",
              "      <td>0_mass_star_galaxy_energy</td>\n",
              "      <td>[mass, star, galaxy, energy, hole, field, blac...</td>\n",
              "      <td>[perform new general relativistic viscous radi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>7030</td>\n",
              "      <td>1_quantum_state_spin_phase</td>\n",
              "      <td>[quantum, state, spin, phase, magnetic, system...</td>\n",
              "      <td>[electronic state calculation using quantum co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>3053</td>\n",
              "      <td>2_group_algebra_mathbb_category</td>\n",
              "      <td>[group, algebra, mathbb, category, prove, mani...</td>\n",
              "      <td>[mapping class group x smooth manifold x group...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>1418</td>\n",
              "      <td>3_image_segmentation_medical_imaging</td>\n",
              "      <td>[image, segmentation, medical, imaging, mri, m...</td>\n",
              "      <td>[accurate medical image segmentation utmost im...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>91</td>\n",
              "      <td>63</td>\n",
              "      <td>91_summarization_summary_document_abstractive</td>\n",
              "      <td>[summarization, summary, document, abstractive...</td>\n",
              "      <td>[natural language processing booming applicati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>92</td>\n",
              "      <td>63</td>\n",
              "      <td>92_sentence_embeddings_word_embedding</td>\n",
              "      <td>[sentence, embeddings, word, embedding, simila...</td>\n",
              "      <td>[sentence embeddings enable u capture semantic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>93</td>\n",
              "      <td>62</td>\n",
              "      <td>93_entropy_thermodynamics_thermodynamic_equili...</td>\n",
              "      <td>[entropy, thermodynamics, thermodynamic, equil...</td>\n",
              "      <td>[paper investigates generalized thermodynamic ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>94</td>\n",
              "      <td>60</td>\n",
              "      <td>94_distributed_consensus_agent_algorithm</td>\n",
              "      <td>[distributed, consensus, agent, algorithm, con...</td>\n",
              "      <td>[paper develops novel approach consensus probl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>95</td>\n",
              "      <td>60</td>\n",
              "      <td>95_aerial_flight_control_trajectory</td>\n",
              "      <td>[aerial, flight, control, trajectory, quadroto...</td>\n",
              "      <td>[paper study motion planning problem pick plac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>97 rows Ã 5 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21b130b6-bcf8-496f-944e-22cbece62246')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-21b130b6-bcf8-496f-944e-22cbece62246 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-21b130b6-bcf8-496f-944e-22cbece62246');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f734a03b-a646-43a8-a49d-6493b037eb39\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f734a03b-a646-43a8-a49d-6493b037eb39')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f734a03b-a646-43a8-a49d-6493b037eb39 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_d84f0091-775d-4ccd-9be5-354eb004ef1b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('info')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_d84f0091-775d-4ccd-9be5-354eb004ef1b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('info');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "info",
              "summary": "{\n  \"name\": \"info\",\n  \"rows\": 97,\n  \"fields\": [\n    {\n      \"column\": \"Topic\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 28,\n        \"min\": -1,\n        \"max\": 95,\n        \"num_unique_values\": 97,\n        \"samples\": [\n          61,\n          39,\n          92\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2393,\n        \"min\": 60,\n        \"max\": 20721,\n        \"num_unique_values\": 80,\n        \"samples\": [\n          252,\n          20721,\n          312\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"61_bandit_regret_arm_algorithm\",\n          \"39_control_controller_disturbance_system\",\n          \"92_sentence_embeddings_word_embedding\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representation\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Representative_Docs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "info = pd.DataFrame(topic_model.get_topic_info() )\n",
        "info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "rX3DXDifYcIr"
      },
      "outputs": [],
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "topic_abstracts = defaultdict(list)\n",
        "\n",
        "# For each topic, collect 10 abstracts\n",
        "for topic_num in info['Topic'].values:\n",
        "    if topic_num == -1:\n",
        "        continue\n",
        "    sample_abstracts = df[df['topic'] == topic_num]['processed_abstracts'].sample(\n",
        "        n=min(10, df[df['topic'] == topic_num].shape[0]),\n",
        "        random_state=42\n",
        "    ).tolist()\n",
        "    topic_abstracts[topic_num] = sample_abstracts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek3UDYVEZNsG",
        "outputId": "fe194e7c-193a-4f68-cd97-238b6f25914b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topic 0 - Sample Abstracts:\n",
            "1. v izzo et al nucl fusion state art modeling thermal current quench cq mhd coupled self consistent evolution runaway electron generation transport showed non axisymmetric n vessel coil could passively ...\n",
            "2. report analysis result globular cluster gc ngc millisecond pulsar msp j recently reported found gc data used large area telescope onboard fermi gamma ray space telescope fermi detect gamma ray pulsati...\n",
            "3. present left right symmetric model provides explanation mass hierarchy charged fermion within framework standard model explanation achieved utilization tree level radiative seesaw mechanism model tiny...\n",
            "4. present study long term variability jupiter mid infrared auroral ch emission micron image jupiter recorded earth based telescope last three decade collated order quantify magnitude timescales northern...\n",
            "5. demonstrate prototype kinetic inductance detector kid readout system us less mw per pixel ccat prime rfsoc based readout capable reading four independent detector network kid power dissipation measure...\n",
            "6. haystack telescope antenna diameter elevation dependent surface accuracy le mu rm capable millimeter wave observation radome enclosed instrument serf radar sensor space situational awareness one third...\n",
            "7. phase resolved analysis x ray spectrum ultra luminous x ray pulsar ulxp ngc ulx performed data taken xmm newton nustar december th addition classical phase restricting analysis method developed active...\n",
            "8. extragalactic radio continuum survey play increasingly important role galaxy evolution cosmology study radio galaxy radio quasar dominate bright end star forming galaxy sfgs radio quiet active galacti...\n",
            "9. third generation g gravitational wave detector particular einstein telescope et cosmic explorer ce explore unprecedented cosmic volume search compact binary merger providing u ten thousand detection p...\n",
            "10. work consider gravitational wave interacting quantum harmonic oscillator transverse traceless gauge take gravitational wave carrying signature plus cross polarization first try obtain suitable form le...\n",
            "\n",
            "Topic 1 - Sample Abstracts:\n",
            "1. revisit problem two dimensional trion external magnetic field demonstrate approximation used previously finding energy spectrum system break experimentally accessible range magnetic field shown neglec...\n",
            "2. circuit description language class quantum programming language program classical produce description quantum computation form quantum circuit since program leverage expressive power high level classi...\n",
            "3. eta pairing type cooper pairing state phase superconducting order parameter aligned staggered manner contrast usual bcs superconductors spatially uniform phase study search characteristic eta pairing ...\n",
            "4. quantum measurement generally introduce perturbation subsequent evolution measured system furthermore projective measurement cannot decrease uncertainty system outcome ignored von neumann entropy cann...\n",
            "5. high harmonic generation hhg powerful probe electron dynamic attosecond femtosecond timescales successfully used detect electronic structural change novel solid state quantum material including transi...\n",
            "6. circuit cutting decomposition quantum circuit independent partition become promising avenue towards experiment larger quantum circuit noisy intermediate scale quantum nisq era previous work focused cu...\n",
            "7. study recently proposed modified schr dinger equation added nonlinear term give rise disentanglement process quantum measurement explored case pair coupled spin find deterministic time evolution gener...\n",
            "8. low frequency classical f noise quantum noise low temperature phonon mode ubiquitous across various experimental platform usually considered hindrance quantum technological application show simultaneo...\n",
            "9. variational quantum eigensolver one promising algorithm near term quantum computer potential solve quantum chemistry problem involving strongly correlated electron otherwise difficult solve classical ...\n",
            "10. quadratic programming orthogonal matrix encompasses broad class hard optimization problem efficient quantum representation problem instance little noncommutative grothendieck problem lncg generalizati...\n"
          ]
        }
      ],
      "source": [
        "for topic_num in list(topic_abstracts.keys())[:2]:  # first 2 topics\n",
        "    print(f\"\\nTopic {topic_num} - Sample Abstracts:\")\n",
        "    for i, abs_text in enumerate(topic_abstracts[topic_num]):\n",
        "        print(f\"{i+1}. {abs_text[:200]}...\")  #first 200 chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCgLClRmaRIa",
        "outputId": "a7929302-9e31-4782-96d7-c345ae975255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"topic_num\": 0,\n",
            "  \"topic_keywords\": [\n",
            "    \"mass\",\n",
            "    \"star\",\n",
            "    \"galaxy\",\n",
            "    \"energy\",\n",
            "    \"hole\",\n",
            "    \"field\",\n",
            "    \"black\",\n",
            "    \"rm\",\n",
            "    \"stellar\",\n",
            "    \"matter\"\n",
            "  ],\n",
            "  \"sample_abstracts\": [\n",
            "    \"v izzo et al nucl fusion state art modeling thermal current quench cq mhd coupled self consistent evolution runaway electron generation transport showed non axisymmetric n vessel coil could passively prevent beam formation disruption sparc compact high field tokamak projected achieve fusion gain q dt plasma however suppression requires finite transport re within magnetic island healed flux surface conservatively assuming zero transport region lead upper bound current compared pre disruption plasma current investigation find core localized electron within r kinetic energy mev contribute plateau formation yet relatively small amount transport e diffusion coefficient mathrm needed core fully mitigate re properly accounting cq electric field effect transport island ii contribution significant current disruption mhd may help achieve\",\n",
            "    \"report analysis result globular cluster gc ngc millisecond pulsar msp j recently reported found gc data used large area telescope onboard fermi gamma ray space telescope fermi detect gamma ray pulsation msp sigma confidence level corresponding weighted h test value sim msp fourth gamma ray pulsar found gc significant pulse emission gamma ray luminosity efficiency time erg respectively order clear view property known gc gamma ray msps analyze fermi lat data three one four msps share property either high dot e sim erg gc contain limited number known msps addition find psrs j b ngc ngc respectively detectable pulse gamma ray emission psr j b ngc using obtained pulse spectrum spectral upper limit constrain number msps four gc result consistent number radio pulsar reported least ngc ngc contribution msps observed gamma ray emission ignored study indicates presence bright msp could dominant factor whether gc detectable gamma ray\",\n",
            "    \"present left right symmetric model provides explanation mass hierarchy charged fermion within framework standard model explanation achieved utilization tree level radiative seesaw mechanism model tiny mass light active neutrino generated via three loop radiative inverse seesaw mechanism dirac majorana submatrices arising one loop level best knowledge first example inverse seesaw mechanism implemented submatrices generated one loop level model contains global u _ x symmetry spontaneous breaking allows stabilization dark matter dm candidate show electroweak precision observables electron muon anomalous magnetic moment well charged lepton flavor violating decay mu rightarrow e gamma consistent current experimental limit addition analyze implication model gev diphoton excess recently reported cm collaboration demonstrate anomaly could easily accommodated finally discus qualitative aspect dm considered model\",\n",
            "    \"present study long term variability jupiter mid infrared auroral ch emission micron image jupiter recorded earth based telescope last three decade collated order quantify magnitude timescales northern auroral hotspot ch emission varies find ratio radiance poleward northern auroral emission lower latitude zonal mean henceforth relative poleward radiance rpr exhibit variability range timescales searched pattern variability order test whether seasonally varying solar insolation year solar cycle short term solar wind variability jupiter magnetopause could explain observed evolution variability rpr exhibit weak r correlation solar insolation received jupiter high northern latitude rule hypothesis suggested previous work e g sinclair et al shortwave solar heating aurorally produced haze particle dominant heating mechanism lower stratosphere also find variability exhibit negligible r correlation monthly mean sunspot number rule variability associated solar cycle shorter timescales find moderate correlation rpr solar wind condition jupiter preceding day image recorded example find correlation r r rpr mean standard deviation solar wind dynamical pressure preceding day moderate correlation suggests either subset solar wind compression lead brighter poleward ch emission subset ch emission brightening event driven internal magnetospheric independent solar wind\",\n",
            "    \"demonstrate prototype kinetic inductance detector kid readout system us less mw per pixel ccat prime rfsoc based readout capable reading four independent detector network kid power dissipation measured less w running multi tone comb four channel simultaneously system also used first time perform sweep resonator identification prototype ghz array\",\n",
            "    \"haystack telescope antenna diameter elevation dependent surface accuracy le mu rm capable millimeter wave observation radome enclosed instrument serf radar sensor space situational awareness one third time available research mit haystack observatory ongoing testing k band ghz w band receiver currently ghz preparing inclusion telescope event horizon telescope eht array use single dish research telescope given geographic location addition haystack telescope current future version eht array would substantially improve image quality\",\n",
            "    \"phase resolved analysis x ray spectrum ultra luminous x ray pulsar ulxp ngc ulx performed data taken xmm newton nustar december th addition classical phase restricting analysis method developed active galactic nucleus study newly employed ulxp revealed pulsation cycle source divided two interval term x ray variability suggests rotating flow consists least two representative emission region furthermore new method successfully decomposed spectrum independent pair interval one unchanging component spectrum reproduced standard disk model _ km inner radius pm kev peak temperature spectrum component coincides pulsation explained comptonization _ kev blackbody exhibited harder photon index brighter phase interval two result consistent picture pulsating emission originates funnel like flow formed within magnetosphere inner flow exhibiting harder continuum observed exclusively opening cone point observer\",\n",
            "    \"extragalactic radio continuum survey play increasingly important role galaxy evolution cosmology study radio galaxy radio quasar dominate bright end star forming galaxy sfgs radio quiet active galactic nucleus agns common fainter flux density aim develop machine learning classifier efficiently reliably separate agns sfgs radio continuum survey perform supervised classification sfgs v agns using light gradient boosting machine lgbm three lofar deep field lockman hole bootes elais n benefit wide range high quality multi wavelength data classification label derived extensive spectral energy distribution sed analysis trained model precision recall sfgs agns model slightly worse performance precision recall result demonstrate trained model successfully reproduce classification label derived detailed sed analysis model performance decrease towards higher redshift mainly due smaller training sample size make classifier adaptable radio galaxy survey also investigate classifier performs poorer multi wavelength sampling sed particular find far infrared fir radio band great importance also find higher n photometric band lead significant boost model performance addition using mhz radio data model also used ghz radio data converting ghz mhz radio data reduces performance precision recall final trained model publicly available http github com jesper karsten mbasc\",\n",
            "    \"third generation g gravitational wave detector particular einstein telescope et cosmic explorer ce explore unprecedented cosmic volume search compact binary merger providing u ten thousand detection per year study simulate employ binary black hole detected g interferometer dark siren extract infer cosmological parameter cross matching gravitational wave data electromagnetic information retrieved simulated galaxy catalog considering standard lambda cdm model apply suitable bayesian framework obtain joint posterior distribution hubble constant h_ matter energy density parameter omega_m different scenario assuming galaxy catalog complete z dark siren detected network signal noise ratio greater show network made et two ce constrain h_ omega_m promising confidence interval within one year continuous observation additionally find information h_ contained local single host dark siren dark siren z substantially improve estimate result imply sub percent measure h_ confidently attained network g detector highlighting need characterising systematic effect higher accuracy\",\n",
            "    \"work consider gravitational wave interacting quantum harmonic oscillator transverse traceless gauge take gravitational wave carrying signature plus cross polarization first try obtain suitable form lewis invariant using general form possible considering quadratic order contribution position momentum variable order progress drop cross term obtaining separable hamiltonian term first second spatial coordinate obtain two lewis invariant corresponding separable part entire hamiltonian system using lewis invariant one obtain two ermakov pinney equation finally obtain corresponding lewis phase eventually berry phase entire system finally obtain explicit expression berry phase plane polarized gravitational wave different choice harmonic oscillator frequency\"\n",
            "  ]\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "llm_input = []\n",
        "\n",
        "for topic_num, abstracts in topic_abstracts.items():\n",
        "    # Get topic keywords from BERTopic\n",
        "    topic_keywords = topic_model.get_topic(topic_num)\n",
        "    keywords = [word for word, _ in topic_keywords[:10]]  # top 10 keywords\n",
        "\n",
        "    llm_input.append({\n",
        "        \"topic_num\": int(topic_num),\n",
        "        \"topic_keywords\": keywords,\n",
        "        \"sample_abstracts\": abstracts\n",
        "    })\n",
        "\n",
        "# Preview one sample\n",
        "import json\n",
        "print(json.dumps(llm_input[0], indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('openai_key')\n",
        "client = OpenAI(api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "Vihikh7R4g1O"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_topic_name(topic_keywords, sample_abstracts):\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful assistant for naming topics from research paper abstracts.\n",
        "Given the following keywords generated using BERTopic and sample abstracts, generate a short and meaningful topic name.\n",
        "\n",
        "The topic name should be very short,maximum of 3 to 4 words â not a sentence or description.\n",
        "\n",
        "Keywords: {', '.join(topic_keywords)}\n",
        "\n",
        "Abstracts:\n",
        "{chr(10).join(f\"- {abs}\" for abs in sample_abstracts)}\n",
        "\n",
        "Give a concise 3â4 word topic name:\"\"\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        temperature=0.7,\n",
        "        max_tokens=30\n",
        "    )\n",
        "    return response.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "HSK6-XVs5Neh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "renamed_topics = {}\n",
        "'''\n",
        "for entry in llm_input:\n",
        "    name = generate_topic_name(entry[\"topic_keywords\"], entry[\"sample_abstracts\"][:5])\n",
        "    renamed_topics[entry[\"topic_num\"]] = name\n",
        "    print(f\"Topic {entry['topic_num']}: {name}\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qKEPFMx5gPP",
        "outputId": "55df5f4e-f99c-4785-c8cb-53e8603a884c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Topic 0: Stellar Energy Variability\n",
            "Topic 1: Quantum Material Properties\n",
            "Topic 2: Algebraic Curve Construction\n",
            "Topic 3: Medical Image Segmentation\n",
            "Topic 4: Discrete Wave Equations\n",
            "Topic 5: Audio Manipulation Techniques\n",
            "Topic 6: Magic Distance Graphs\n",
            "Topic 7: Wireless Channel Communication\n",
            "Topic 8: Logical Composition Theory\n",
            "Topic 9: Generative Image Editing\n",
            "Topic 10: Bayesian Estimation Methods\n",
            "Topic 11: Stochastic Distribution Analysis\n",
            "Topic 12: Renewable Energy Optimization\n",
            "Topic 13: Multilingual Language Models\n",
            "Topic 14: Multimodal Image Understanding\n",
            "Topic 15: Automated Program Repair\n",
            "Topic 16: Video Compression Techniques\n",
            "Topic 17: Secure Computation Acceleration\n",
            "Topic 18: Geometric Graph Learning\n",
            "Topic 19: Climate Forecasting Model\n",
            "Topic 20: Blockchain Security Analysis\n",
            "Topic 21: Crop Change Detection\n",
            "Topic 22: Misinformation Detection Methods\n",
            "Topic 23: Adversarial Attack Detection\n",
            "Topic 24: Financial Risk Assessment\n",
            "Topic 25: Memory-Augmented RL Agent\n",
            "Topic 26: Causal Inference Estimation\n",
            "Topic 27: \"Graph-based Recommendation Models\"\n",
            "Topic 28: Physics-Informed Neural Networks\n",
            "Topic 29: Robot Manipulation Learning\n",
            "Topic 30: Cooperative Game Optimization\n",
            "Topic 31: Sparse Neural Pruning\n",
            "Topic 32: Stochastic Optimization Algorithms\n",
            "Topic 33: Numerical Mesh Scheme\n",
            "Topic 34: Privacy-Preserving Federated Learning\n",
            "Topic 35: Brain Connectivity Analysis\n",
            "Topic 36: Semantic Segmentation Methods\n",
            "Topic 37: Vortex Dynamics Study\n",
            "Topic 38: Autonomous Driving Behavior\n",
            "Topic 39: Adaptive Control Synthesis\n",
            "Topic 40: Dynamic Scene Reconstruction\n",
            "Topic 41: Biomedical Drug Discovery\n",
            "Topic 42: AI in Education\n",
            "Topic 43: Clinical Language Models\n",
            "Topic 44: Granular Dynamics Study\n",
            "Topic 45: Dialog Knowledge Integration\n",
            "Topic 46: Trophic Dynamics Model\n",
            "Topic 47: Epidemic Dynamics Modeling\n",
            "Topic 48: Dynamic Object Localization\n",
            "Topic 49: Genetic Data Analysis\n",
            "Topic 50: Deep Anomaly Detection\n",
            "Topic 51: Dynamic Continual Learning\n",
            "Topic 52: Ethical AI Implementation\n",
            "Topic 53: Deepfake Detection Framework\n",
            "Topic 54: Cell Membrane Fusion\n",
            "Topic 55: Context-Aware Transformers\n",
            "Topic 56: Algorithmic Fairness Analysis\n",
            "Topic 57: Aerial Communication Networks\n",
            "Topic 58: Efficient DNN Implementation\n",
            "Topic 59: Material Fracture Behavior\n",
            "Topic 60: Imbalanced Data Augmentation\n",
            "Topic 61: Contextual Bandit Algorithms\n",
            "Topic 62: Private Data Mechanisms\n",
            "Topic 63: Vibratory Terrain Locomotion\n",
            "Topic 64: Biophysics in Africa\n",
            "Topic 65: Active Noise Labeling\n",
            "Topic 66: Cardiac Signal Analysis\n",
            "Topic 67: Shapley Value Explanation\n",
            "Topic 68: Matroid Theory Extensions\n",
            "Topic 69: Network Growth Patterns\n",
            "Topic 70: Urban Mobility Analysis\n",
            "Topic 71: Micro Expression Recognition\n",
            "Topic 72: Privacy Control Usability\n",
            "Topic 73: Immersive VR Experience\n",
            "Topic 74: Neuromorphic Spiking Networks\n",
            "Topic 75: Knowledge Base QA Framework\n",
            "Topic 76: Retrieval Language Models\n",
            "Topic 77: Multi-Step Reasoning Enhancement\n",
            "Topic 78: Dynamic Path Planning\n",
            "Topic 79: Spectral Clustering Method\n",
            "Topic 80: Linear Code Construction\n",
            "Topic 81: Atomic Structure Modeling\n",
            "Topic 82: Clinical Risk Prediction\n",
            "Topic 83: IoT Security Challenges\n",
            "Topic 84: Contrastive Representation Learning\n",
            "Topic 85: Social Bias Evaluation\n",
            "Topic 86: Neural Plasticity Dynamics\n",
            "Topic 87: Edge Computing Optimization\n",
            "Topic 88: Regularization Methods for Inverse\n",
            "Topic 89: Image Restoration Techniques\n",
            "Topic 90: Ground-Aware Motion Reconstruction\n",
            "Topic 91: Cross-Lingual Summarization Evaluation\n",
            "Topic 92: Compact Embedding Structures\n",
            "Topic 93: Anisotropic Entropy Production\n",
            "Topic 94: Distributed Optimization Algorithm\n",
            "Topic 95: Modular Aerial Vehicles\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered[\"Topic Name\"] = df[\"topic\"].map(renamed_topics)"
      ],
      "metadata": {
        "id": "7s5sqokaFAxj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 770
        },
        "id": "ne1S6DdwHdjy",
        "outputId": "1a9a609e-253b-403f-8e36-521506e6e559"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               id                                              title  \\\n",
              "1      2307.16362  High Sensitivity Beamformed Observations of th...   \n",
              "3      2309.09088  Enhancing GAN-Based Vocoders with Contrastive ...   \n",
              "4      2307.16404      Nonvolatile Magneto-Thermal Switching in MgB2   \n",
              "6      2304.00044                   On The Theory of Ring Afterglows   \n",
              "8      2309.07927  Kid-Whisper: Towards Bridging the Performance ...   \n",
              "...           ...                                                ...   \n",
              "63350  2305.10173  Quantum theory without the Axiom of choice, an...   \n",
              "63351  2307.11414                     The Derived Deligne Conjecture   \n",
              "63352  2306.06241                      Almost paratopological groups   \n",
              "63354  2303.04288  Polynomial Time and Private Learning of Unboun...   \n",
              "63356  2310.02919  Attention-based Multi-task Learning for Base E...   \n",
              "\n",
              "                                                abstract  \\\n",
              "1      We analyzed four epochs of beamformed EVN data...   \n",
              "3      Vocoder models have recently achieved substant...   \n",
              "4      Ongoing research explores thermal switching ma...   \n",
              "6      Synchrotron and inverse Compton emission succe...   \n",
              "8      Recent advancements in Automatic Speech Recogn...   \n",
              "...                                                  ...   \n",
              "63350  In this conceptual paper, we discuss quantum f...   \n",
              "63351  Derived $A_\\infty$-algebras have a wealth of t...   \n",
              "63352  A class of almost paratopological groups is in...   \n",
              "63354  We study the problem of privately estimating t...   \n",
              "63356  Human genetic diseases often arise from point ...   \n",
              "\n",
              "                                                 authors  \\\n",
              "1                    Rebecca Lin, Marten H. van Kerkwijk   \n",
              "3      Haoming Guo, Seth Z. Zhao, Jiachen Lian, Gopal...   \n",
              "4                      Hiroto Arima, Yoshikazu Mizuguchi   \n",
              "6            Marcus DuPont, Andrew MacFadyen, Re'em Sari   \n",
              "8      Ahmed Adel Attia, Jing Liu, Wei Ai, Dorottya D...   \n",
              "...                                                  ...   \n",
              "63350                                          Koen Thas   \n",
              "63351         Javier Aguilar MartÃ­n, Constanze Roitzheim   \n",
              "63352                                Evgenii Reznichenko   \n",
              "63354     Jamil Arbas, Hassan Ashtiani, Christopher Liaw   \n",
              "63356   Amina Mollaysa, Ahmed Allam, Michael Krauthammer   \n",
              "\n",
              "             published_date                               link  \\\n",
              "1      2023-07-31T01:36:55Z  http://arxiv.org/abs/2307.16362v2   \n",
              "3      2023-09-16T20:04:16Z  http://arxiv.org/abs/2309.09088v2   \n",
              "4      2023-07-31T04:59:19Z  http://arxiv.org/abs/2307.16404v1   \n",
              "6      2023-03-31T18:02:12Z  http://arxiv.org/abs/2304.00044v1   \n",
              "8      2023-09-12T06:58:18Z  http://arxiv.org/abs/2309.07927v3   \n",
              "...                     ...                                ...   \n",
              "63350  2023-05-17T12:57:19Z  http://arxiv.org/abs/2305.10173v1   \n",
              "63351  2023-07-21T08:16:23Z  http://arxiv.org/abs/2307.11414v3   \n",
              "63352  2023-06-09T20:27:33Z  http://arxiv.org/abs/2306.06241v2   \n",
              "63354  2023-03-07T23:24:27Z  http://arxiv.org/abs/2303.04288v2   \n",
              "63356  2023-10-04T16:01:06Z  http://arxiv.org/abs/2310.02919v2   \n",
              "\n",
              "                                                markdown  \\\n",
              "1      # High Sensitivity Beamformed Observations of ...   \n",
              "3      # Enhancing Gan-Based Vocoders with Contrastiv...   \n",
              "4      # Nonvolatile Magneto-Thermal Switching in MgB...   \n",
              "6      # On The Theory of Ring Afterglows\\n\\n###### A...   \n",
              "8      Kid-Whisper: Towards Bridging the Performance ...   \n",
              "...                                                  ...   \n",
              "63350  # Quantum theory without the axiom of choice, ...   \n",
              "63351  # The derived Deligne conjecture\\n\\n###### Abs...   \n",
              "63352  # Almost paratopological groups\\n\\n###### Abst...   \n",
              "63354  # Polynomial Time and Private Learning of Unbo...   \n",
              "63356  # Attention-based Multi-task Learning for Base...   \n",
              "\n",
              "                                     processed_abstracts  topic  \\\n",
              "1      analyzed four epoch beamformed evn data crab p...      0   \n",
              "3      vocoder model recently achieved substantial pr...      5   \n",
              "4      ongoing research explores thermal switching ma...      1   \n",
              "6      synchrotron inverse compton emission successfu...      0   \n",
              "8      recent advancement automatic speech recognitio...      5   \n",
              "...                                                  ...    ...   \n",
              "63350  conceptual paper discus quantum formalism use ...      1   \n",
              "63351  derived a_ infty algebra wealth theoretical ad...      2   \n",
              "63352  class almost paratopological group introduced ...      2   \n",
              "63354  study problem privately estimating parameter d...     62   \n",
              "63356  human genetic disease often arise point mutati...     49   \n",
              "\n",
              "                          Topic Name  \n",
              "1         Stellar Energy Variability  \n",
              "3      Audio Manipulation Techniques  \n",
              "4        Quantum Material Properties  \n",
              "6         Stellar Energy Variability  \n",
              "8      Audio Manipulation Techniques  \n",
              "...                              ...  \n",
              "63350    Quantum Material Properties  \n",
              "63351   Algebraic Curve Construction  \n",
              "63352   Algebraic Curve Construction  \n",
              "63354        Private Data Mechanisms  \n",
              "63356          Genetic Data Analysis  \n",
              "\n",
              "[42636 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15fca533-ec1f-4a9e-972e-70d0b0b0e3be\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>abstract</th>\n",
              "      <th>authors</th>\n",
              "      <th>published_date</th>\n",
              "      <th>link</th>\n",
              "      <th>markdown</th>\n",
              "      <th>processed_abstracts</th>\n",
              "      <th>topic</th>\n",
              "      <th>Topic Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2307.16362</td>\n",
              "      <td>High Sensitivity Beamformed Observations of th...</td>\n",
              "      <td>We analyzed four epochs of beamformed EVN data...</td>\n",
              "      <td>Rebecca Lin, Marten H. van Kerkwijk</td>\n",
              "      <td>2023-07-31T01:36:55Z</td>\n",
              "      <td>http://arxiv.org/abs/2307.16362v2</td>\n",
              "      <td># High Sensitivity Beamformed Observations of ...</td>\n",
              "      <td>analyzed four epoch beamformed evn data crab p...</td>\n",
              "      <td>0</td>\n",
              "      <td>Stellar Energy Variability</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2309.09088</td>\n",
              "      <td>Enhancing GAN-Based Vocoders with Contrastive ...</td>\n",
              "      <td>Vocoder models have recently achieved substant...</td>\n",
              "      <td>Haoming Guo, Seth Z. Zhao, Jiachen Lian, Gopal...</td>\n",
              "      <td>2023-09-16T20:04:16Z</td>\n",
              "      <td>http://arxiv.org/abs/2309.09088v2</td>\n",
              "      <td># Enhancing Gan-Based Vocoders with Contrastiv...</td>\n",
              "      <td>vocoder model recently achieved substantial pr...</td>\n",
              "      <td>5</td>\n",
              "      <td>Audio Manipulation Techniques</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2307.16404</td>\n",
              "      <td>Nonvolatile Magneto-Thermal Switching in MgB2</td>\n",
              "      <td>Ongoing research explores thermal switching ma...</td>\n",
              "      <td>Hiroto Arima, Yoshikazu Mizuguchi</td>\n",
              "      <td>2023-07-31T04:59:19Z</td>\n",
              "      <td>http://arxiv.org/abs/2307.16404v1</td>\n",
              "      <td># Nonvolatile Magneto-Thermal Switching in MgB...</td>\n",
              "      <td>ongoing research explores thermal switching ma...</td>\n",
              "      <td>1</td>\n",
              "      <td>Quantum Material Properties</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2304.00044</td>\n",
              "      <td>On The Theory of Ring Afterglows</td>\n",
              "      <td>Synchrotron and inverse Compton emission succe...</td>\n",
              "      <td>Marcus DuPont, Andrew MacFadyen, Re'em Sari</td>\n",
              "      <td>2023-03-31T18:02:12Z</td>\n",
              "      <td>http://arxiv.org/abs/2304.00044v1</td>\n",
              "      <td># On The Theory of Ring Afterglows\\n\\n###### A...</td>\n",
              "      <td>synchrotron inverse compton emission successfu...</td>\n",
              "      <td>0</td>\n",
              "      <td>Stellar Energy Variability</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2309.07927</td>\n",
              "      <td>Kid-Whisper: Towards Bridging the Performance ...</td>\n",
              "      <td>Recent advancements in Automatic Speech Recogn...</td>\n",
              "      <td>Ahmed Adel Attia, Jing Liu, Wei Ai, Dorottya D...</td>\n",
              "      <td>2023-09-12T06:58:18Z</td>\n",
              "      <td>http://arxiv.org/abs/2309.07927v3</td>\n",
              "      <td>Kid-Whisper: Towards Bridging the Performance ...</td>\n",
              "      <td>recent advancement automatic speech recognitio...</td>\n",
              "      <td>5</td>\n",
              "      <td>Audio Manipulation Techniques</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63350</th>\n",
              "      <td>2305.10173</td>\n",
              "      <td>Quantum theory without the Axiom of choice, an...</td>\n",
              "      <td>In this conceptual paper, we discuss quantum f...</td>\n",
              "      <td>Koen Thas</td>\n",
              "      <td>2023-05-17T12:57:19Z</td>\n",
              "      <td>http://arxiv.org/abs/2305.10173v1</td>\n",
              "      <td># Quantum theory without the axiom of choice, ...</td>\n",
              "      <td>conceptual paper discus quantum formalism use ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Quantum Material Properties</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63351</th>\n",
              "      <td>2307.11414</td>\n",
              "      <td>The Derived Deligne Conjecture</td>\n",
              "      <td>Derived $A_\\infty$-algebras have a wealth of t...</td>\n",
              "      <td>Javier Aguilar MartÃ­n, Constanze Roitzheim</td>\n",
              "      <td>2023-07-21T08:16:23Z</td>\n",
              "      <td>http://arxiv.org/abs/2307.11414v3</td>\n",
              "      <td># The derived Deligne conjecture\\n\\n###### Abs...</td>\n",
              "      <td>derived a_ infty algebra wealth theoretical ad...</td>\n",
              "      <td>2</td>\n",
              "      <td>Algebraic Curve Construction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63352</th>\n",
              "      <td>2306.06241</td>\n",
              "      <td>Almost paratopological groups</td>\n",
              "      <td>A class of almost paratopological groups is in...</td>\n",
              "      <td>Evgenii Reznichenko</td>\n",
              "      <td>2023-06-09T20:27:33Z</td>\n",
              "      <td>http://arxiv.org/abs/2306.06241v2</td>\n",
              "      <td># Almost paratopological groups\\n\\n###### Abst...</td>\n",
              "      <td>class almost paratopological group introduced ...</td>\n",
              "      <td>2</td>\n",
              "      <td>Algebraic Curve Construction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63354</th>\n",
              "      <td>2303.04288</td>\n",
              "      <td>Polynomial Time and Private Learning of Unboun...</td>\n",
              "      <td>We study the problem of privately estimating t...</td>\n",
              "      <td>Jamil Arbas, Hassan Ashtiani, Christopher Liaw</td>\n",
              "      <td>2023-03-07T23:24:27Z</td>\n",
              "      <td>http://arxiv.org/abs/2303.04288v2</td>\n",
              "      <td># Polynomial Time and Private Learning of Unbo...</td>\n",
              "      <td>study problem privately estimating parameter d...</td>\n",
              "      <td>62</td>\n",
              "      <td>Private Data Mechanisms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63356</th>\n",
              "      <td>2310.02919</td>\n",
              "      <td>Attention-based Multi-task Learning for Base E...</td>\n",
              "      <td>Human genetic diseases often arise from point ...</td>\n",
              "      <td>Amina Mollaysa, Ahmed Allam, Michael Krauthammer</td>\n",
              "      <td>2023-10-04T16:01:06Z</td>\n",
              "      <td>http://arxiv.org/abs/2310.02919v2</td>\n",
              "      <td># Attention-based Multi-task Learning for Base...</td>\n",
              "      <td>human genetic disease often arise point mutati...</td>\n",
              "      <td>49</td>\n",
              "      <td>Genetic Data Analysis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42636 rows Ã 10 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15fca533-ec1f-4a9e-972e-70d0b0b0e3be')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-15fca533-ec1f-4a9e-972e-70d0b0b0e3be button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-15fca533-ec1f-4a9e-972e-70d0b0b0e3be');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0585ce56-f819-4549-a66b-79acad4b6a46\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0585ce56-f819-4549-a66b-79acad4b6a46')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0585ce56-f819-4549-a66b-79acad4b6a46 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_122edd73-b00b-4637-87c5-25b1aca40098\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_filtered')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_122edd73-b00b-4637-87c5-25b1aca40098 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_filtered');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_filtered",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.to_csv(\"BERTopic_output.csv\", index=False)"
      ],
      "metadata": {
        "id": "RrKVEt2GFkFx"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtUvCghySbsn"
      },
      "source": [
        "## Visualize Topics\n",
        "\n",
        "Visualizing the discovered topics helps in understanding the distribution and relationships between different topics. BERTopic provides several visualization tools to aid in this analysis:\n",
        "1. **Intertopic Distance Map**: Shows how topics are related to each other.\n",
        "2. **Topic Hierarchy**: Displays the hierarchical structure of topics.\n",
        "3. **Top Words per Topic**: Lists the most representative words for each topic.\n",
        "\n",
        "Let's generate these visualizations to gain insights into the topic structure.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LuHNdyAPhJc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "outputId": "817d0949-c934-4d66-ea5f-1c3f0c34cf15"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"1372f23c-0944-4dbc-b1cb-58b41806314e\" class=\"plotly-graph-div\" style=\"height:800px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1372f23c-0944-4dbc-b1cb-58b41806314e\")) {                    Plotly.newPlot(                        \"1372f23c-0944-4dbc-b1cb-58b41806314e\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"0_mass_star_galaxy\",\"1_quantum_state_spin\",\"2_group_algebra_mathbb\",\"3_image_segmentation_medical\",\"4_equation_mathbb_solution\",\"5_speech_audio_speaker\",\"6_graph_vertex_edge\",\"7_channel_communication_wir...\",\"8_logic_proof_automaton\",\"9_image_diffusion_text\",\"10_estimator_distribution_p...\",\"11_random_stochastic_equation\",\"12_power_grid_energy\",\"13_language_translation_llm\",\"14_image_visual_text\",\"15_code_software_bug\",\"16_video_frame_action\",\"17_memory_hardware_cache\",\"18_graph_node_gnns\",\"19_climate_forecast_forecas...\",\"20_blockchain_transaction_c...\",\"21_crop_image_remote\",\"22_news_social_medium\",\"23_attack_adversarial_backd...\",\"24_market_price_financial\",\"25_rl_policy_reward\",\"26_causal_treatment_effect\",\"27_recommendation_item_user\",\"28_neural_equation_pdes\",\"29_robot_tactile_grasp\",\"30_agent_game_nash\",\"31_network_pruning_neural\",\"32_optimization_convergence...\",\"33_element_numerical_equation\",\"34_fl_client_federated\",\"35_brain_eeg_fmri\",\"36_segmentation_transformer...\",\"37_flow_turbulent_vortex\",\"38_driving_vehicle_autonomous\",\"39_control_controller_distu...\",\"40_scene_nerf_view\",\"41_protein_drug_molecule\",\"42_student_education_course\",\"43_clinical_medical_biomedi...\",\"44_droplet_flow_shear\",\"45_dialogue_conversational_...\",\"46_oscillator_bifurcation_s...\",\"47_epidemic_infection_covid\",\"48_lidar_sensor_slam\",\"49_gene_cell_genome\",\"50_anomaly_detection_log\",\"51_continual_forgetting_lea...\",\"52_ai_human_decision\",\"53_face_recognition_deepfake\",\"54_polymer_cell_active\",\"55_transformer_attention_la...\",\"56_fairness_bias_fair\",\"57_uav_uavs_aerial\",\"58_dnn_quantization_bit\",\"59_fracture_dislocation_str...\",\"60_calibration_class_ensemble\",\"61_bandit_regret_arm\",\"62_privacy_private_dp\",\"63_robot_locomotion_control...\",\"64_citation_publication_sci...\",\"65_label_learning_noisy\",\"66_ecg_heart_cardiac\",\"67_explanation_feature_shap...\",\"68_matroid_matroids_lattice\",\"69_network_community_node\",\"70_traffic_travel_mobility\",\"71_emotion_affective_emotio...\",\"72_privacy_cybersecurity_cy...\",\"73_metaverse_vr_virtual\",\"74_spiking_snns_snn\",\"75_question_answer_qa\",\"76_retrieval_query_document\",\"77_reasoning_cot_llm\",\"78_robot_planning_path\",\"79_clustering_cluster_algor...\",\"80_code_cyclic_mathbb\",\"81_crystal_structure_atom\",\"82_patient_survival_risk\",\"83_iot_device_attack\",\"84_ssl_supervised_contrastive\",\"85_bias_gender_stereotype\",\"86_neuron_neural_brain\",\"87_edge_network_service\",\"88_inverse_problem_regulari...\",\"89_image_restoration_degrad...\",\"90_pose_human_motion\",\"91_summarization_summary_do...\",\"92_sentence_embeddings_word\",\"93_entropy_thermodynamics_t...\",\"94_distributed_consensus_ag...\",\"95_aerial_flight_control\"],\"y\":[\"0_mass_star_galaxy\",\"1_quantum_state_spin\",\"2_group_algebra_mathbb\",\"3_image_segmentation_medical\",\"4_equation_mathbb_solution\",\"5_speech_audio_speaker\",\"6_graph_vertex_edge\",\"7_channel_communication_wir...\",\"8_logic_proof_automaton\",\"9_image_diffusion_text\",\"10_estimator_distribution_p...\",\"11_random_stochastic_equation\",\"12_power_grid_energy\",\"13_language_translation_llm\",\"14_image_visual_text\",\"15_code_software_bug\",\"16_video_frame_action\",\"17_memory_hardware_cache\",\"18_graph_node_gnns\",\"19_climate_forecast_forecas...\",\"20_blockchain_transaction_c...\",\"21_crop_image_remote\",\"22_news_social_medium\",\"23_attack_adversarial_backd...\",\"24_market_price_financial\",\"25_rl_policy_reward\",\"26_causal_treatment_effect\",\"27_recommendation_item_user\",\"28_neural_equation_pdes\",\"29_robot_tactile_grasp\",\"30_agent_game_nash\",\"31_network_pruning_neural\",\"32_optimization_convergence...\",\"33_element_numerical_equation\",\"34_fl_client_federated\",\"35_brain_eeg_fmri\",\"36_segmentation_transformer...\",\"37_flow_turbulent_vortex\",\"38_driving_vehicle_autonomous\",\"39_control_controller_distu...\",\"40_scene_nerf_view\",\"41_protein_drug_molecule\",\"42_student_education_course\",\"43_clinical_medical_biomedi...\",\"44_droplet_flow_shear\",\"45_dialogue_conversational_...\",\"46_oscillator_bifurcation_s...\",\"47_epidemic_infection_covid\",\"48_lidar_sensor_slam\",\"49_gene_cell_genome\",\"50_anomaly_detection_log\",\"51_continual_forgetting_lea...\",\"52_ai_human_decision\",\"53_face_recognition_deepfake\",\"54_polymer_cell_active\",\"55_transformer_attention_la...\",\"56_fairness_bias_fair\",\"57_uav_uavs_aerial\",\"58_dnn_quantization_bit\",\"59_fracture_dislocation_str...\",\"60_calibration_class_ensemble\",\"61_bandit_regret_arm\",\"62_privacy_private_dp\",\"63_robot_locomotion_control...\",\"64_citation_publication_sci...\",\"65_label_learning_noisy\",\"66_ecg_heart_cardiac\",\"67_explanation_feature_shap...\",\"68_matroid_matroids_lattice\",\"69_network_community_node\",\"70_traffic_travel_mobility\",\"71_emotion_affective_emotio...\",\"72_privacy_cybersecurity_cy...\",\"73_metaverse_vr_virtual\",\"74_spiking_snns_snn\",\"75_question_answer_qa\",\"76_retrieval_query_document\",\"77_reasoning_cot_llm\",\"78_robot_planning_path\",\"79_clustering_cluster_algor...\",\"80_code_cyclic_mathbb\",\"81_crystal_structure_atom\",\"82_patient_survival_risk\",\"83_iot_device_attack\",\"84_ssl_supervised_contrastive\",\"85_bias_gender_stereotype\",\"86_neuron_neural_brain\",\"87_edge_network_service\",\"88_inverse_problem_regulari...\",\"89_image_restoration_degrad...\",\"90_pose_human_motion\",\"91_summarization_summary_do...\",\"92_sentence_embeddings_word\",\"93_entropy_thermodynamics_t...\",\"94_distributed_consensus_ag...\",\"95_aerial_flight_control\"],\"z\":[[1.0000005,0.5307536,0.45039576,0.3501917,0.36132354,0.29681832,0.27553877,0.34848344,0.39090055,0.33033487,0.5214957,0.43939748,0.35458377,0.3187717,0.32172087,0.3805872,0.3174493,0.46621892,0.3176589,0.5471746,0.35631245,0.4109345,0.2992959,0.30051273,0.39364985,0.28178066,0.41467583,0.30178288,0.42968562,0.25766024,0.23647916,0.35460767,0.37674937,0.36244726,0.2654518,0.36338168,0.32180005,0.4706342,0.3078246,0.2353861,0.36195162,0.37349513,0.30105802,0.31688377,0.39983383,0.27619186,0.39478433,0.34257734,0.32483774,0.39387062,0.4400377,0.2735248,0.23986447,0.3011032,0.2605277,0.34689113,0.26000893,0.2834873,0.3238087,0.40665787,0.40123934,0.21899001,0.2546946,0.19209027,0.3875131,0.31638253,0.3846921,0.44527373,0.2920559,0.3664806,0.296446,0.3094754,0.26395547,0.29642248,0.30138215,0.29770422,0.30625352,0.34187427,0.27095836,0.38181913,0.3454162,0.4889896,0.3344352,0.32480812,0.29765087,0.21612006,0.30625007,0.24857004,0.30201593,0.3120381,0.2797305,0.27758387,0.24049482,0.40628156,0.18124987,0.26829326],[0.5307536,1.0000004,0.28272298,0.2032101,0.31485954,0.21791798,0.25894317,0.3711862,0.35423446,0.19754057,0.34598315,0.3972232,0.25844684,0.17867608,0.17293198,0.21104857,0.17667198,0.377156,0.28383943,0.27436996,0.31955636,0.18084246,0.14625736,0.16282311,0.2928264,0.28780317,0.24328329,0.22961266,0.36650142,0.22794831,0.26928982,0.30921397,0.3555524,0.3116924,0.2236846,0.33931682,0.188062,0.3282211,0.20976152,0.23425853,0.17831159,0.34888843,0.20758368,0.19547938,0.27873662,0.18559125,0.4461919,0.19237988,0.1674099,0.2583205,0.2294232,0.21604937,0.19193071,0.1926503,0.3254829,0.24666849,0.16150625,0.21813202,0.35039663,0.39104962,0.22330208,0.22721675,0.21211274,0.22339952,0.20188248,0.1536964,0.31376758,0.2617613,0.27856648,0.33221406,0.22220111,0.20468219,0.16590789,0.20887423,0.3912979,0.24751824,0.20650448,0.24185483,0.19913332,0.27265853,0.3627936,0.552999,0.20539655,0.261234,0.27075595,0.092289,0.38252616,0.26927722,0.2509724,0.20074174,0.15257517,0.12289717,0.15563399,0.43952543,0.2452975,0.18465798],[0.45039576,0.28272298,1.0,0.14587289,0.61286575,0.15747355,0.5518912,0.21444987,0.51479316,0.19458799,0.29101884,0.4088106,0.18261464,0.20257373,0.22489533,0.2380966,0.18421935,0.29513374,0.20147716,0.19054088,0.29624856,0.1866153,0.13865417,0.14330223,0.251267,0.14391163,0.19768988,0.18461359,0.23903222,0.21144484,0.27204567,0.21524791,0.26849073,0.30299821,0.16131549,0.191319,0.20556855,0.23902449,0.17372626,0.16625904,0.2107614,0.1689085,0.26781243,0.1830944,0.24168682,0.18255806,0.2246764,0.15469296,0.15259238,0.18026507,0.17913988,0.15549952,0.14916997,0.18790579,0.21109197,0.25937414,0.16093889,0.15255867,0.17089818,0.20729339,0.1739858,0.14360876,0.23937637,0.19691467,0.14159186,0.17742047,0.16692324,0.2693244,0.710863,0.27130324,0.22962157,0.19608632,0.18847111,0.16413164,0.1456974,0.23382078,0.20732722,0.2451968,0.19203353,0.30542222,0.5770073,0.2127431,0.14421493,0.14976071,0.19434471,0.11794286,0.18679127,0.17279916,0.2175141,0.16314052,0.15609217,0.1584253,0.16027819,0.26910776,0.14177655,0.18411946],[0.3501917,0.2032101,0.14587289,1.0000002,0.12971196,0.5114631,0.16192631,0.32641283,0.24903186,0.70701563,0.48896906,0.1552083,0.25359687,0.43554816,0.6945897,0.38745442,0.63465726,0.3972517,0.47872794,0.4768371,0.24727306,0.728404,0.3245461,0.60590446,0.28992224,0.40901572,0.4086368,0.37185913,0.5422841,0.48109835,0.22221269,0.6460427,0.46625978,0.25112262,0.41921565,0.6979563,0.77866507,0.22167991,0.5052284,0.18468793,0.677714,0.55063957,0.33953145,0.6370297,0.23181376,0.367797,0.12461755,0.36512795,0.52818674,0.58595955,0.5789484,0.5516325,0.39786857,0.6748863,0.23693743,0.5412969,0.45991066,0.32282022,0.6122722,0.30537704,0.74615675,0.2664782,0.2383551,0.27975726,0.27259842,0.62118435,0.6633349,0.592821,0.13467363,0.30187097,0.3416126,0.49990332,0.27129862,0.4239113,0.4988342,0.38465902,0.40716505,0.40854344,0.3897396,0.40766916,0.20111467,0.46185404,0.69547206,0.4020947,0.643934,0.30113828,0.55083156,0.29069746,0.54518074,0.7471646,0.62018484,0.37703648,0.37445197,0.10172674,0.20179655,0.24959587],[0.36132354,0.31485954,0.61286575,0.12971196,0.9999998,0.18582545,0.3564513,0.2203153,0.36508426,0.16966791,0.3914389,0.6514873,0.25644,0.14556906,0.13876373,0.13947527,0.12490968,0.18066262,0.122439325,0.24779417,0.20042925,0.1282676,0.0939459,0.16633998,0.30281922,0.24276288,0.20503503,0.14714846,0.40048924,0.17457758,0.28929496,0.26215833,0.44500005,0.55840486,0.15948606,0.19967858,0.10508199,0.3542663,0.14621806,0.34553105,0.12191095,0.10220477,0.17163804,0.13690788,0.32643068,0.12906784,0.35039383,0.23782936,0.09926784,0.114696555,0.18792251,0.16646293,0.1238999,0.17959592,0.20587167,0.19810727,0.13551351,0.15762088,0.12010879,0.23625702,0.1547807,0.20159277,0.25411454,0.20246904,0.1094486,0.13966659,0.18441373,0.22951446,0.4173368,0.17802525,0.21380438,0.1537368,0.16500665,0.085787706,0.112931974,0.17374247,0.16610415,0.13996379,0.19883822,0.28874168,0.39660302,0.17431024,0.16309,0.17324777,0.18041043,0.050476544,0.19550623,0.17203917,0.47527263,0.15627858,0.123979926,0.13157414,0.1382691,0.42828658,0.28098157,0.18052539],[0.29681832,0.21791798,0.15747355,0.5114631,0.18582545,0.99999994,0.16419213,0.42404723,0.34106004,0.56843513,0.43499625,0.16175927,0.31584957,0.67823946,0.6381675,0.4732126,0.59947836,0.389847,0.47517323,0.46400028,0.2740901,0.50496644,0.4731832,0.5259487,0.32199308,0.40212545,0.33953705,0.48472625,0.4815998,0.4440583,0.26484358,0.5920781,0.40115374,0.19173566,0.40953338,0.5699785,0.55595565,0.24344973,0.44429222,0.24538076,0.4076011,0.4528404,0.43226427,0.573853,0.17631699,0.68762565,0.17744406,0.25426388,0.3328056,0.41962013,0.4711777,0.5513757,0.4331819,0.580409,0.11851524,0.6546565,0.45434943,0.29249552,0.5794237,0.22966652,0.6480483,0.30344063,0.30388162,0.24642117,0.30683303,0.6450416,0.52779686,0.5891433,0.07264097,0.279505,0.3854646,0.6252434,0.3470341,0.41129214,0.49769068,0.53071976,0.55790013,0.5672572,0.2548345,0.36254266,0.23033302,0.37500814,0.48826388,0.380623,0.5981284,0.54757404,0.47764426,0.3212074,0.3313468,0.5081713,0.4858676,0.5560128,0.6046986,0.17079143,0.22507243,0.19356972],[0.27553877,0.25894317,0.5518912,0.16192631,0.3564513,0.16419213,0.9999999,0.3052008,0.5453543,0.1933537,0.2793793,0.38908404,0.28407666,0.22649753,0.21824312,0.29476503,0.16847011,0.38229704,0.62899584,0.18088126,0.3813911,0.18558888,0.20089313,0.18129171,0.21672298,0.2224018,0.24762769,0.28444788,0.23190038,0.2010755,0.45120928,0.31249446,0.3978023,0.28178066,0.253819,0.16735254,0.20167495,0.1538443,0.23058343,0.18049729,0.12914073,0.28953648,0.21454884,0.22077222,0.1507656,0.20408241,0.27926785,0.23779787,0.1407373,0.29572967,0.21824932,0.18740748,0.19425115,0.17380728,0.15439989,0.2218161,0.24894002,0.23095307,0.27868348,0.19997258,0.20092788,0.35019058,0.31814215,0.19188972,0.23949574,0.2344689,0.1254779,0.2679437,0.7456014,0.6760312,0.40566313,0.16946746,0.18281032,0.11974779,0.21227956,0.25739217,0.22443895,0.30021173,0.3134956,0.46971047,0.5858151,0.2569736,0.16527373,0.19593495,0.21952872,0.12968662,0.23576199,0.42503622,0.22496581,0.17652224,0.14003363,0.17924322,0.18147123,0.2313151,0.3966019,0.1377304],[0.34848344,0.3711862,0.21444987,0.32641283,0.2203153,0.42404723,0.3052008,1.0000005,0.34869552,0.2828087,0.46270108,0.28502214,0.5253786,0.29948398,0.28349406,0.35051078,0.34233525,0.5054532,0.38875642,0.41885525,0.37723505,0.44691584,0.24455312,0.32963535,0.33494064,0.36186993,0.31278807,0.33966807,0.40431383,0.29507354,0.4037177,0.442615,0.51208025,0.34987965,0.42973107,0.3739766,0.34979856,0.2472974,0.40167436,0.41426808,0.28969684,0.26787472,0.26741922,0.28771836,0.12781249,0.33484048,0.30905035,0.31238344,0.3744117,0.35072803,0.37717712,0.33919856,0.2763628,0.37801212,0.07557358,0.37883607,0.34433782,0.7034927,0.5216981,0.21938471,0.38203344,0.37795967,0.35594127,0.26936057,0.16504502,0.31734726,0.4151705,0.37008548,0.2328397,0.41174996,0.50257,0.26814556,0.291242,0.37137225,0.37154764,0.2826034,0.28524208,0.29697984,0.3721453,0.4231982,0.4369725,0.30220237,0.31357297,0.5289716,0.34576127,0.19421473,0.3458002,0.67515254,0.3771303,0.3885734,0.28413314,0.22818303,0.1950783,0.1891615,0.52398515,0.37040025],[0.39090055,0.35423446,0.51479316,0.24903186,0.36508426,0.34106004,0.5453543,0.34869552,1.0000007,0.30054379,0.39804143,0.36085546,0.39672995,0.52671194,0.41340232,0.62162083,0.32012048,0.5609767,0.37105808,0.376849,0.5715129,0.29324162,0.37734604,0.34613717,0.4126225,0.44959062,0.48014733,0.37323573,0.42369086,0.44862416,0.5738108,0.34452036,0.43924788,0.3264296,0.41091222,0.30999398,0.2906291,0.2643344,0.42967075,0.36758548,0.2209614,0.35674122,0.511006,0.49551374,0.24917167,0.4599711,0.27073884,0.32896408,0.23083925,0.36209416,0.32552856,0.3808201,0.501121,0.2955186,0.22183122,0.42500523,0.43369323,0.33979917,0.36986417,0.31895164,0.34539852,0.3747532,0.43429378,0.33686975,0.33084258,0.34662232,0.2840319,0.5825341,0.5179312,0.40941364,0.4192247,0.34399176,0.45526803,0.34908286,0.2993337,0.5442455,0.39416203,0.67007416,0.40790042,0.3466931,0.60418826,0.3517432,0.37793663,0.3328591,0.3516556,0.36755553,0.3741152,0.3718344,0.22765505,0.2432512,0.22571015,0.39514938,0.3910871,0.39160615,0.37361145,0.33084425],[0.33033487,0.19754057,0.19458799,0.70701563,0.16966791,0.56843513,0.1933537,0.2828087,0.30054379,1.0,0.4823139,0.2564596,0.32126302,0.57627463,0.8116149,0.43557537,0.70804167,0.3902792,0.513725,0.44206747,0.2882002,0.6420472,0.424045,0.6368582,0.34402758,0.4812683,0.34674382,0.45659864,0.5295758,0.5327197,0.31521186,0.6200242,0.45014164,0.26995662,0.4093566,0.5363907,0.75492334,0.2542234,0.5059124,0.22326481,0.73787034,0.48136708,0.3948699,0.5000081,0.2615191,0.50623703,0.18668866,0.28132832,0.45168364,0.4196241,0.46307144,0.5739546,0.39226517,0.6763434,0.20089558,0.6213542,0.40235814,0.2673467,0.57130694,0.27316105,0.6804812,0.34120467,0.25148898,0.25088698,0.25008246,0.5855819,0.42784464,0.5647409,0.15274665,0.3034025,0.3718387,0.55261356,0.285351,0.47960502,0.46726462,0.45590216,0.48158726,0.52735335,0.38485783,0.31011423,0.1996789,0.40981713,0.44810495,0.33225152,0.64286447,0.41959614,0.5019964,0.32662708,0.5070575,0.7651188,0.6278695,0.48558918,0.5252383,0.18466419,0.22905914,0.2380009],[0.5214957,0.34598315,0.29101884,0.48896906,0.3914389,0.43499625,0.2793793,0.46270108,0.39804143,0.4823139,1.0000005,0.6593537,0.49710998,0.39476633,0.386106,0.38860315,0.41556805,0.43013725,0.41966563,0.63237184,0.30652648,0.4945426,0.3094322,0.43985727,0.61404485,0.543635,0.6868669,0.44526395,0.63022083,0.43616456,0.47390658,0.55774355,0.7178003,0.49772093,0.48158947,0.5377847,0.3863832,0.41926402,0.480001,0.47975814,0.39923036,0.47062287,0.3586959,0.4091572,0.40512183,0.34647486,0.414643,0.52929574,0.42113608,0.49833536,0.55286604,0.46729195,0.34819606,0.41291094,0.27879182,0.42508835,0.47311527,0.4176828,0.40891328,0.37404907,0.57178885,0.53382766,0.5026829,0.36005196,0.3166648,0.5237203,0.5101649,0.61404455,0.23802891,0.45435748,0.5133927,0.33709884,0.3145352,0.265562,0.3770316,0.3489399,0.3538325,0.42840797,0.4906694,0.59897274,0.32131413,0.48521316,0.5573956,0.36425647,0.48195335,0.30062655,0.47759908,0.3498422,0.605611,0.41674247,0.42681012,0.32632855,0.29774955,0.45825696,0.42217922,0.37631822],[0.43939748,0.3972232,0.4088106,0.1552083,0.6514873,0.16175927,0.38908404,0.28502214,0.36085546,0.2564596,0.6593537,0.99999976,0.3430909,0.15753707,0.109724365,0.17226239,0.13466011,0.27687016,0.24812616,0.37303692,0.28624436,0.15193677,0.11260573,0.1902244,0.49193758,0.3735138,0.38543004,0.19137532,0.45121858,0.23717609,0.44064856,0.33339018,0.5237145,0.48730126,0.26586658,0.26237038,0.09368725,0.41759214,0.2445331,0.40895915,0.10636083,0.21028756,0.18389912,0.14211474,0.45230374,0.13720708,0.5877738,0.4578726,0.15658993,0.2382392,0.28168553,0.25306967,0.1482215,0.11543371,0.35780758,0.1819325,0.19309232,0.24300644,0.1741559,0.33393276,0.21646567,0.4157722,0.38198534,0.27825108,0.17077081,0.16919437,0.20272112,0.28431246,0.3571705,0.39730385,0.33855847,0.08840631,0.18065691,0.05811386,0.257646,0.1399368,0.1380263,0.1891768,0.34877935,0.36426413,0.30699423,0.28814027,0.24376866,0.24091356,0.22391595,0.050390404,0.33820435,0.27569857,0.40764022,0.14529343,0.124423884,0.11647349,0.094601646,0.6640941,0.4274576,0.20183615],[0.35458377,0.25844684,0.18261464,0.25359687,0.25644,0.31584957,0.28407666,0.5253786,0.39672995,0.32126302,0.49710998,0.3430909,1.0,0.3375836,0.30853686,0.4231832,0.30446282,0.52734107,0.3893631,0.6185549,0.48202235,0.4360254,0.31210002,0.37158036,0.57672596,0.47937366,0.43620133,0.36117455,0.5536313,0.35178545,0.5105731,0.41405603,0.55012864,0.40999627,0.40515324,0.3760409,0.3035858,0.3862741,0.45269993,0.5808872,0.2477009,0.2772437,0.34670922,0.29771045,0.2517285,0.29590726,0.38079706,0.43327996,0.26871562,0.33983585,0.41466728,0.36441493,0.42523232,0.32743248,0.14712335,0.42655557,0.36921135,0.53011364,0.40488824,0.31867912,0.41686317,0.38433105,0.3704536,0.37980562,0.23469548,0.36710015,0.42217523,0.48906788,0.2166089,0.40794486,0.58059746,0.34800285,0.3851436,0.30061287,0.35592872,0.32121685,0.26859802,0.36144716,0.43811637,0.4136273,0.2870979,0.34693557,0.43662572,0.4626744,0.34197673,0.23675917,0.34428945,0.5704432,0.3024924,0.30488643,0.26019013,0.26764843,0.24598119,0.38789108,0.51177675,0.42234793],[0.3187717,0.17867608,0.20257373,0.43554816,0.14556906,0.67823946,0.22649753,0.29948398,0.52671194,0.57627463,0.39476633,0.15753707,0.3375836,1.0000002,0.77315867,0.68009543,0.5485089,0.44180906,0.4819774,0.44565764,0.3285019,0.46224427,0.658605,0.48383418,0.38319594,0.47725785,0.42333546,0.5394386,0.42837572,0.5199207,0.34543353,0.5253574,0.36916232,0.15610509,0.41812503,0.4825095,0.539177,0.19197068,0.44776893,0.20771569,0.35841024,0.4705491,0.6116255,0.7557585,0.1648131,0.768532,0.11303455,0.295439,0.3141057,0.44612145,0.41390622,0.5914539,0.50219756,0.4572008,0.11723679,0.7444901,0.473601,0.25642723,0.465677,0.27459618,0.602532,0.3857985,0.2635782,0.25144982,0.48494992,0.63173705,0.37468946,0.61000603,0.1285182,0.31041798,0.40554708,0.5988102,0.45434344,0.3956483,0.4037452,0.7692706,0.76351744,0.8368844,0.32125843,0.2943569,0.28743643,0.38001987,0.48409238,0.30907091,0.5827313,0.7572249,0.44368562,0.2776623,0.17371398,0.42053217,0.41543317,0.7793743,0.81740206,0.1702185,0.19781473,0.20844422],[0.32172087,0.17293198,0.22489533,0.6945897,0.13876373,0.6381675,0.21824312,0.28349406,0.41340232,0.8116149,0.386106,0.109724365,0.30853686,0.77315867,0.9999996,0.59320766,0.7957424,0.44918194,0.54484934,0.44727063,0.32192034,0.7116854,0.56043005,0.6357029,0.35543028,0.5015587,0.34931666,0.5390081,0.45286977,0.62934697,0.3387005,0.62158984,0.39429918,0.11196035,0.43339372,0.5699825,0.8366513,0.16250385,0.58627784,0.18954512,0.6971061,0.4990799,0.5635552,0.6847219,0.16499893,0.68015283,0.06411487,0.24513707,0.5156033,0.44628578,0.51488304,0.67462134,0.5125139,0.70504403,0.1249546,0.7160596,0.47199938,0.3067298,0.60060334,0.25893643,0.75153893,0.3742786,0.2359039,0.27991858,0.40857,0.7024803,0.45422363,0.6507911,0.15052293,0.30006614,0.39961004,0.65692425,0.3992284,0.5437985,0.49672577,0.6941695,0.7127267,0.70190716,0.39550522,0.32745877,0.27576545,0.4144107,0.5169435,0.3639151,0.7249426,0.57807225,0.50893193,0.314352,0.33427083,0.7115741,0.6603377,0.65048146,0.7194395,0.110457286,0.17631571,0.28004032],[0.3805872,0.21104857,0.2380966,0.38745442,0.13947527,0.4732126,0.29476503,0.35051078,0.62162083,0.43557537,0.38860315,0.17226239,0.4231832,0.68009543,0.59320766,1.0000002,0.4919414,0.66010135,0.43734962,0.48127759,0.5687743,0.4846886,0.57014096,0.5535333,0.44588894,0.45081866,0.51940864,0.50751066,0.4217846,0.48793143,0.4267614,0.4416125,0.4012935,0.17752783,0.45246416,0.44291392,0.4652115,0.22152466,0.49091184,0.233535,0.31826064,0.45168546,0.6720291,0.65103656,0.23119731,0.6160866,0.15135936,0.3791487,0.30103785,0.50659424,0.53805244,0.51368725,0.64657116,0.48247406,0.15130092,0.5360437,0.52107376,0.39293423,0.4558676,0.3367639,0.56713516,0.41634127,0.38333225,0.26681566,0.51602095,0.5270973,0.39965227,0.6820076,0.19960727,0.39359865,0.4204577,0.5225462,0.64729524,0.48059797,0.36075822,0.64667606,0.5509946,0.7345664,0.37478548,0.38612902,0.48347375,0.38191074,0.5259634,0.49943554,0.49705672,0.5524701,0.3896499,0.41140556,0.1417919,0.3802691,0.33047432,0.558054,0.49885234,0.1643046,0.24843726,0.29753673],[0.3174493,0.17667198,0.18421935,0.63465726,0.12490968,0.59947836,0.16847011,0.34233525,0.32012048,0.70804167,0.41556805,0.13466011,0.30446282,0.5485089,0.7957424,0.4919414,0.99999976,0.45483226,0.48155674,0.45465007,0.30638272,0.68982595,0.4425966,0.5503044,0.34096122,0.48962516,0.31472653,0.4940755,0.426077,0.5669578,0.31987232,0.5794432,0.38482067,0.1181595,0.40557247,0.5278741,0.80701584,0.20575738,0.60225165,0.22938514,0.7345808,0.40580428,0.43579513,0.5013225,0.17664039,0.5350689,0.079355136,0.23514734,0.5447062,0.39378217,0.5103815,0.5949707,0.3917747,0.6536677,0.102677785,0.6201468,0.4061196,0.3589146,0.6135447,0.20963033,0.6708908,0.33449322,0.23420858,0.2991955,0.2508082,0.5996381,0.48575065,0.56397367,0.123723924,0.2693909,0.42288917,0.5971544,0.32156122,0.55281264,0.4804805,0.49783525,0.5233745,0.4950427,0.4061423,0.34114578,0.2707312,0.3371814,0.47780597,0.3700114,0.6442675,0.37918904,0.4378048,0.39746204,0.33632222,0.7491331,0.74013054,0.47226757,0.51827383,0.114136375,0.20460257,0.31824064],[0.46621892,0.377156,0.29513374,0.3972517,0.18066262,0.389847,0.38229704,0.5054532,0.5609767,0.3902792,0.43013725,0.27687016,0.52734107,0.44180906,0.44918194,0.66010135,0.45483226,1.0000005,0.44056967,0.47493726,0.62988,0.45748743,0.3610661,0.46516037,0.42710933,0.40446758,0.38690615,0.41894498,0.4646772,0.3919371,0.40788174,0.4940439,0.5198539,0.3308332,0.49709502,0.4123496,0.46901956,0.33118162,0.46363056,0.31540087,0.38742405,0.43029568,0.40132445,0.45141226,0.29448956,0.39193693,0.26079297,0.34823605,0.38122526,0.4913768,0.46973997,0.43641296,0.43057397,0.46704242,0.23795162,0.5045047,0.44076145,0.46190706,0.6884283,0.36670172,0.48403367,0.35116512,0.45781067,0.28876498,0.34492362,0.38812116,0.43211186,0.523467,0.34132594,0.40761554,0.4504484,0.38434622,0.5138054,0.4771682,0.513849,0.42413837,0.40582052,0.49427408,0.3975615,0.43188328,0.4664708,0.43250027,0.44063967,0.5597189,0.42450193,0.3064086,0.41084802,0.6656056,0.23071799,0.39555228,0.3193177,0.3233033,0.30529058,0.3057715,0.3837017,0.35541463],[0.3176589,0.28383943,0.20147716,0.47872794,0.122439325,0.47517323,0.62899584,0.38875642,0.37105808,0.513725,0.41966563,0.24812616,0.3893631,0.4819774,0.54484934,0.43734962,0.48155674,0.44056967,1.0000005,0.42894107,0.36859223,0.49195623,0.44570163,0.5370411,0.32091448,0.4580092,0.33944783,0.5085265,0.55167,0.41934058,0.3758383,0.6984574,0.46151516,0.2058297,0.53820425,0.48807856,0.5341354,0.19924852,0.46334216,0.23654324,0.38922074,0.562787,0.36099076,0.45659027,0.1733604,0.45649576,0.27106842,0.29430026,0.360174,0.4685,0.5256384,0.5430036,0.37850976,0.4857764,0.14968286,0.5216396,0.42109886,0.32629475,0.6250081,0.24054413,0.62352484,0.41854104,0.31265268,0.24713525,0.33290672,0.576933,0.40925515,0.5536637,0.3041523,0.7414925,0.5200901,0.46905962,0.26528692,0.28635547,0.55926216,0.42866275,0.4538347,0.48592073,0.38008842,0.5097513,0.30305704,0.4710357,0.4409527,0.43838066,0.57868993,0.36633384,0.5558343,0.50952923,0.3074727,0.446491,0.4336546,0.38064328,0.4792259,0.1622333,0.42587483,0.19741495],[0.5471746,0.27436996,0.19054088,0.4768371,0.24779417,0.46400028,0.18088126,0.41885525,0.376849,0.44206747,0.63237184,0.37303692,0.6185549,0.44565764,0.44727063,0.48127759,0.45465007,0.47493726,0.42894107,0.99999964,0.37807643,0.6972605,0.43188307,0.47660962,0.57654035,0.5029511,0.52776027,0.4215002,0.6826072,0.40793392,0.38678148,0.52709293,0.5077979,0.39656004,0.45675257,0.4961765,0.44648433,0.53842396,0.5397342,0.41956836,0.45997488,0.4445102,0.38636193,0.44105807,0.39860478,0.3891547,0.41543108,0.5314881,0.50135016,0.49096608,0.5789308,0.48589292,0.43967035,0.41887647,0.20960654,0.49381405,0.42938566,0.44232717,0.4575624,0.399696,0.620313,0.35990638,0.33709538,0.32388768,0.3544322,0.48812634,0.5490825,0.636582,0.13401105,0.40387705,0.5511724,0.46700415,0.37026283,0.35057956,0.40434223,0.38969055,0.3620777,0.45743966,0.4542876,0.43241915,0.20071755,0.4905475,0.5999286,0.4892651,0.4721117,0.34891784,0.45152193,0.40597773,0.4007103,0.46351877,0.4362531,0.38480017,0.3508101,0.40795404,0.3270475,0.38109285],[0.35631245,0.31955636,0.29624856,0.24727306,0.20042925,0.2740901,0.3813911,0.37723505,0.5715129,0.2882002,0.30652648,0.28624436,0.48202235,0.3285019,0.32192034,0.5687743,0.30638272,0.62988,0.36859223,0.37807643,1.0000004,0.32302016,0.46424058,0.45607737,0.57034856,0.37034914,0.38685644,0.4390106,0.3290869,0.35515553,0.5860095,0.31271568,0.34195343,0.21896926,0.55562544,0.28976706,0.27342123,0.19567966,0.39865592,0.26130658,0.20737514,0.311218,0.4369923,0.39516115,0.24097338,0.35298577,0.2799838,0.3676647,0.2140378,0.3415856,0.42511946,0.32565027,0.5495481,0.40217692,0.21137957,0.28731748,0.44117704,0.38603657,0.365724,0.28952304,0.36411133,0.38255352,0.55816025,0.2294521,0.42839038,0.3347018,0.33430243,0.49317107,0.34548116,0.49377194,0.4538179,0.30613935,0.6934204,0.43477774,0.3119121,0.4033989,0.29412237,0.394656,0.29968384,0.3807522,0.39548174,0.27218187,0.3775952,0.6057554,0.36584553,0.2598091,0.2911407,0.5579389,0.12582205,0.24866527,0.23350264,0.2952909,0.21647565,0.29273564,0.49283522,0.23053043],[0.4109345,0.18084246,0.1866153,0.728404,0.1282676,0.50496644,0.18558888,0.44691584,0.29324162,0.6420472,0.4945426,0.15193677,0.4360254,0.46224427,0.7116854,0.4846886,0.68982595,0.45748743,0.49195623,0.6972605,0.32302016,1.0000001,0.401402,0.61601937,0.3733621,0.47244355,0.36486217,0.41820645,0.5250113,0.54001117,0.29317847,0.61791223,0.44795746,0.18066573,0.4708355,0.5440672,0.80553246,0.22465295,0.6111686,0.27714345,0.73072666,0.45165527,0.38178337,0.47446844,0.18633665,0.40597773,0.15936173,0.3524148,0.6801755,0.5014671,0.65360296,0.5673502,0.45882908,0.660425,0.08345511,0.5438619,0.45741287,0.5185554,0.62378913,0.24474986,0.74448156,0.32015824,0.29499555,0.31065574,0.28572747,0.6455535,0.5395684,0.63248366,0.13817677,0.34592733,0.4810403,0.4976862,0.35649574,0.46036908,0.4623626,0.40506935,0.4267755,0.43845525,0.48734093,0.45798337,0.23620096,0.43775773,0.54543304,0.545422,0.65660566,0.3332805,0.453614,0.41160074,0.43862638,0.7480541,0.62400705,0.38546553,0.37809667,0.090848505,0.2562196,0.40635696],[0.2992959,0.14625736,0.13865417,0.3245461,0.0939459,0.4731832,0.20089313,0.24455312,0.37734604,0.424045,0.3094322,0.11260573,0.31210002,0.658605,0.56043005,0.57014096,0.4425966,0.3610661,0.44570163,0.43188307,0.46424058,0.401402,0.9999998,0.46614906,0.43157035,0.34531724,0.46720865,0.61952835,0.28059435,0.3820839,0.4109564,0.35342544,0.23560059,0.05955002,0.4078556,0.4301778,0.37510586,0.17196794,0.4138877,0.08639239,0.22767343,0.34060112,0.5709204,0.63314265,0.14328371,0.64743525,0.14898956,0.40666714,0.20305929,0.37500703,0.4228377,0.42585233,0.62679887,0.46147242,0.08619309,0.49364027,0.55184734,0.2333766,0.30231354,0.18887658,0.5037709,0.3170106,0.38153395,0.11676224,0.6382583,0.5235938,0.34346858,0.5810405,0.13232453,0.46900094,0.43264848,0.6607026,0.6610368,0.4622819,0.32717097,0.6357913,0.5402722,0.5983483,0.18189697,0.3469493,0.13833036,0.24200298,0.4768975,0.42730796,0.4592659,0.7633778,0.3685344,0.29074508,0.06699439,0.28631467,0.3096426,0.6152681,0.5996537,0.0845628,0.22600746,0.11749526],[0.30051273,0.16282311,0.14330223,0.60590446,0.16633998,0.5259487,0.18129171,0.32963535,0.34613717,0.6368582,0.43985727,0.1902244,0.37158036,0.48383418,0.6357029,0.5535333,0.5503044,0.46516037,0.5370411,0.47660962,0.45607737,0.61601937,0.46614906,0.9999998,0.3964907,0.5037687,0.37602237,0.43277466,0.5681914,0.4699131,0.40334788,0.7302241,0.48310852,0.16383833,0.618345,0.48997086,0.65326947,0.21041971,0.5576043,0.30504164,0.53522027,0.47515112,0.39917526,0.45468405,0.16806433,0.42894986,0.15328753,0.37251815,0.43023086,0.4211598,0.6859291,0.59444976,0.5427934,0.75928867,0.08578969,0.5228132,0.6012224,0.37541187,0.63316965,0.22499906,0.81506336,0.4450993,0.48049676,0.22517051,0.22058222,0.66283697,0.4387606,0.6969983,0.1338427,0.32431296,0.39240435,0.4768679,0.5296874,0.39150146,0.5016229,0.42025807,0.4217788,0.4803243,0.32694927,0.34502763,0.26148683,0.3728557,0.5364319,0.6657814,0.68932503,0.4682839,0.5026516,0.35740313,0.39691246,0.56759596,0.50197196,0.34313235,0.43743315,0.16808401,0.3253662,0.2944083],[0.39364985,0.2928264,0.251267,0.28992224,0.30281922,0.32199308,0.21672298,0.33494064,0.4126225,0.34402758,0.61404485,0.49193758,0.57672596,0.38319594,0.35543028,0.44588894,0.34096122,0.42710933,0.32091448,0.57654035,0.57034856,0.3733621,0.43157035,0.3964907,1.0000001,0.5483361,0.5501758,0.4866456,0.5149707,0.37608454,0.64247084,0.4187438,0.53717995,0.30743644,0.41357875,0.40381524,0.27107504,0.3260574,0.46001396,0.4037614,0.21998043,0.34095028,0.4410946,0.38927305,0.31484842,0.3629888,0.34322566,0.47893158,0.19654353,0.3456292,0.4094549,0.43710706,0.4929458,0.29844525,0.20074408,0.35662818,0.43889025,0.35091245,0.29962632,0.37117723,0.4731619,0.57619333,0.4151382,0.29796854,0.39786702,0.42318654,0.39553058,0.59194595,0.18940659,0.36792812,0.54788023,0.37030798,0.45819584,0.31412536,0.28260887,0.38238743,0.35885575,0.42332506,0.3601865,0.37659037,0.2566242,0.37195757,0.51472294,0.36258855,0.40080678,0.30440155,0.38666657,0.36648512,0.2837989,0.2622971,0.22472426,0.37614405,0.30327556,0.43679273,0.36211452,0.31403452],[0.28178066,0.28780317,0.14391163,0.40901572,0.24276288,0.40212545,0.2224018,0.36186993,0.44959062,0.4812683,0.543635,0.3735138,0.47937366,0.47725785,0.5015587,0.45081866,0.48962516,0.40446758,0.4580092,0.5029511,0.37034914,0.47244355,0.34531724,0.5037687,0.5483361,1.0000002,0.49579707,0.49631277,0.658352,0.70804626,0.7049404,0.59987676,0.63110393,0.29803833,0.5513099,0.44703838,0.4167772,0.22579166,0.6434258,0.5971489,0.4120238,0.4764771,0.513586,0.44949928,0.19005674,0.516087,0.33861235,0.362426,0.3977067,0.34366196,0.41757783,0.6949564,0.52487314,0.37086806,0.206826,0.4448349,0.4826739,0.47668317,0.4623206,0.2598704,0.56269467,0.7617599,0.32931364,0.5806466,0.27046287,0.5473621,0.40188733,0.6165603,0.15625255,0.30589366,0.4973523,0.43128538,0.30649033,0.4017525,0.44404438,0.49145988,0.42459494,0.5959143,0.6780564,0.3073117,0.21555391,0.4577351,0.50559556,0.35581806,0.524456,0.3365229,0.5710772,0.41887847,0.36814138,0.3760325,0.4295512,0.36784792,0.36184093,0.34864247,0.52506727,0.534594],[0.41467583,0.24328329,0.19768988,0.4086368,0.20503503,0.33953705,0.24762769,0.31278807,0.48014733,0.34674382,0.6868669,0.38543004,0.43620133,0.42333546,0.34931666,0.51940864,0.31472653,0.38690615,0.33944783,0.52776027,0.38685644,0.36486217,0.46720865,0.37602237,0.5501758,0.49579707,1.0,0.44680557,0.43606997,0.40341696,0.4822842,0.3261208,0.4503224,0.32014388,0.42912492,0.52796125,0.2298011,0.30039677,0.44262385,0.38365376,0.2125559,0.42629194,0.5037654,0.5781257,0.29375938,0.40012258,0.33974165,0.650967,0.20563222,0.54832923,0.42018807,0.4088853,0.5211595,0.3413044,0.21981978,0.2975866,0.6061014,0.32639807,0.2390785,0.3223583,0.46162194,0.4229706,0.42789227,0.29501238,0.4953514,0.45340306,0.5084239,0.62942237,0.19778232,0.44117525,0.44800174,0.41642728,0.48684272,0.37041605,0.2532341,0.42311388,0.30221745,0.5096958,0.36359158,0.37735876,0.24098642,0.33832192,0.6746871,0.31211945,0.3830961,0.46942452,0.4109745,0.2874272,0.311291,0.28877872,0.31360933,0.36424768,0.27523658,0.31820247,0.2931735,0.29845867],[0.30178288,0.22961266,0.18461359,0.37185913,0.14714846,0.48472625,0.28444788,0.33966807,0.37323573,0.45659864,0.44526395,0.19137532,0.36117455,0.5394386,0.5390081,0.50751066,0.4940755,0.41894498,0.5085265,0.4215002,0.4390106,0.41820645,0.61952835,0.43277466,0.4866456,0.49631277,0.44680557,1.0000004,0.38944158,0.44219363,0.51456404,0.46298787,0.42523965,0.14327891,0.51024395,0.43299899,0.4124316,0.1476146,0.45938534,0.21194299,0.31147483,0.41487595,0.53740704,0.56013596,0.13906813,0.6092868,0.15484256,0.3403484,0.30040073,0.36960024,0.4450523,0.5332887,0.5120577,0.43073767,0.09613394,0.46918833,0.5151883,0.32413882,0.3809248,0.20100066,0.5307325,0.5661148,0.4227835,0.21014152,0.501175,0.55921555,0.3724469,0.6387714,0.16078283,0.4611638,0.5171009,0.5187045,0.48334998,0.4583353,0.3267843,0.57177067,0.6600526,0.54489696,0.3075712,0.44301206,0.21478316,0.33800367,0.5116604,0.39434385,0.49598154,0.4936793,0.38452855,0.41915175,0.21816713,0.37803224,0.36212295,0.5194078,0.54014796,0.1516126,0.30523595,0.19952103],[0.42968562,0.36650142,0.23903222,0.5422841,0.40048924,0.4815998,0.23190038,0.40431383,0.42369086,0.5295758,0.63022083,0.45121858,0.5536313,0.42837572,0.45286977,0.4217846,0.426077,0.4646772,0.55167,0.6826072,0.3290869,0.5250113,0.28059435,0.5681914,0.5149707,0.658352,0.43606997,0.38944158,0.99999994,0.534897,0.4428189,0.7765784,0.70738685,0.64023536,0.53916097,0.5711239,0.45175785,0.5829665,0.5582693,0.5974858,0.4659164,0.57802576,0.40382063,0.44007558,0.502155,0.38142508,0.48313403,0.41755944,0.42379487,0.47515705,0.52225894,0.60823375,0.42869115,0.4568589,0.38969973,0.55705476,0.4109639,0.42585495,0.6302091,0.45891362,0.65395164,0.4403107,0.33610398,0.49815524,0.21834287,0.5298476,0.55560005,0.6652342,0.1944803,0.39771494,0.49828497,0.44169953,0.23915884,0.32356817,0.58419126,0.38055748,0.36364043,0.49621627,0.5351057,0.41817975,0.27727345,0.62372583,0.58071136,0.44486535,0.5449076,0.25947356,0.6803295,0.400351,0.59301245,0.45729277,0.44512063,0.3324961,0.36197668,0.4670067,0.46800026,0.49140948],[0.25766024,0.22794831,0.21144484,0.48109835,0.17457758,0.4440583,0.2010755,0.29507354,0.44862416,0.5327197,0.43616456,0.23717609,0.35178545,0.5199207,0.62934697,0.48793143,0.5669578,0.3919371,0.41934058,0.40793392,0.35515553,0.54001117,0.3820839,0.4699131,0.37608454,0.70804626,0.40341696,0.44219363,0.534897,0.9999997,0.516646,0.4728728,0.46574357,0.21670519,0.39335933,0.5181648,0.539862,0.19508801,0.6772386,0.49038175,0.5136464,0.43762445,0.545505,0.49169576,0.2757237,0.57671803,0.27185678,0.2910881,0.55080616,0.34335047,0.40534037,0.571703,0.5935037,0.47593778,0.34526727,0.4851772,0.4184148,0.46061626,0.44617411,0.32048988,0.52533185,0.49636024,0.27069426,0.76246005,0.26241675,0.5027783,0.41242784,0.5886772,0.18549559,0.284292,0.45776838,0.5355085,0.3681911,0.590545,0.46917093,0.48608622,0.39780965,0.5954617,0.75575083,0.29838896,0.19740887,0.39738816,0.45317993,0.3680829,0.5141368,0.36807248,0.55434084,0.31658912,0.293838,0.4118009,0.67445153,0.3984894,0.38106456,0.24026768,0.36877596,0.5931095],[0.23647916,0.26928982,0.27204567,0.22221269,0.28929496,0.26484358,0.45120928,0.4037177,0.5738108,0.31521186,0.47390658,0.44064856,0.5105731,0.34543353,0.3387005,0.4267614,0.31987232,0.40788174,0.3758383,0.38678148,0.5860095,0.29317847,0.4109564,0.40334788,0.64247084,0.7049404,0.4822842,0.51456404,0.4428189,0.516646,1.0000002,0.398952,0.5666202,0.2720162,0.5486715,0.2973832,0.23671192,0.20135166,0.5025914,0.47459376,0.21753225,0.29262498,0.48230055,0.3341295,0.20510726,0.41122073,0.42428616,0.44218585,0.22830471,0.2749684,0.29099983,0.44349018,0.5673619,0.29897082,0.2044932,0.29934043,0.5603345,0.45449722,0.2926919,0.23766397,0.39804313,0.719184,0.50100976,0.4188086,0.28052104,0.38874584,0.22546135,0.5425599,0.39379618,0.4923906,0.53897405,0.32540554,0.4272257,0.3756455,0.28742656,0.42907494,0.326839,0.47786435,0.50616586,0.37685287,0.3683438,0.279222,0.3836653,0.34413132,0.34776583,0.32637906,0.41921294,0.49976414,0.25878185,0.24590601,0.25833723,0.29850945,0.23741885,0.42529434,0.63699746,0.40314153],[0.35460767,0.30921397,0.21524791,0.6460427,0.26215833,0.5920781,0.31249446,0.442615,0.34452036,0.6200242,0.55774355,0.33339018,0.41405603,0.5253574,0.62158984,0.4416125,0.5794432,0.4940439,0.6984574,0.52709293,0.31271568,0.61791223,0.35342544,0.7302241,0.4187438,0.59987676,0.3261208,0.46298787,0.7765784,0.4728728,0.398952,1.0000002,0.68572384,0.33748543,0.58544004,0.5788766,0.6817725,0.34038955,0.51181763,0.37896678,0.5581331,0.56062365,0.3578791,0.46227503,0.2628056,0.4326691,0.28342542,0.27972698,0.45998782,0.4690853,0.5942629,0.7294256,0.39837295,0.60281885,0.21395966,0.6728312,0.48030636,0.38176647,0.82783455,0.32049924,0.8365804,0.48083612,0.368672,0.31268898,0.23776637,0.65749717,0.50015104,0.6468436,0.22463328,0.47059557,0.4592802,0.450545,0.26290336,0.28924704,0.6954121,0.41245753,0.5096233,0.50768375,0.39085007,0.4390859,0.3252666,0.53086853,0.52599233,0.5034786,0.7010481,0.3733866,0.70106375,0.46333382,0.5222521,0.624039,0.49635074,0.39223054,0.48738757,0.2745694,0.4358108,0.32322553],[0.37674937,0.3555524,0.26849073,0.46625978,0.44500005,0.40115374,0.3978023,0.51208025,0.43924788,0.45014164,0.7178003,0.5237145,0.55012864,0.36916232,0.39429918,0.4012935,0.38482067,0.5198539,0.46151516,0.5077979,0.34195343,0.44795746,0.23560059,0.48310852,0.53717995,0.63110393,0.4503224,0.42523965,0.70738685,0.46574357,0.5666202,0.68572384,0.9999998,0.6279406,0.5104139,0.4360334,0.4150014,0.3964732,0.47626746,0.6268904,0.40410113,0.4675619,0.32009947,0.36521554,0.3102092,0.29789364,0.3980662,0.3706733,0.4180252,0.45413196,0.4588047,0.5342397,0.3585023,0.40444404,0.25776967,0.4195622,0.43804508,0.5124509,0.53893834,0.3832377,0.5429143,0.64930695,0.4476913,0.46450338,0.22829603,0.4770663,0.43068787,0.547286,0.30876893,0.4102913,0.4592677,0.31454617,0.24662256,0.2539746,0.46088064,0.3377662,0.38207728,0.4245816,0.5834651,0.5786418,0.42398858,0.4904086,0.46722436,0.36695537,0.477342,0.23559323,0.50395393,0.46858242,0.6680712,0.41657308,0.36663547,0.31202164,0.29640225,0.39130995,0.65027034,0.528802],[0.36244726,0.3116924,0.30299821,0.25112262,0.55840486,0.19173566,0.28178066,0.34987965,0.3264296,0.26995662,0.49772093,0.48730126,0.40999627,0.15610509,0.11196035,0.17752783,0.1181595,0.3308332,0.2058297,0.39656004,0.21896926,0.18066573,0.05955002,0.16383833,0.30743644,0.29803833,0.32014388,0.14327891,0.64023536,0.21670519,0.2720162,0.33748543,0.6279406,1.0,0.21912403,0.26202023,0.12021967,0.6156505,0.18526962,0.5007443,0.21343017,0.2360522,0.18964921,0.15921703,0.530812,0.10631454,0.42178965,0.3148773,0.18306687,0.24206701,0.1825473,0.19616796,0.13640146,0.1826561,0.36344245,0.22605257,0.14152817,0.29693168,0.25095987,0.47682652,0.18481553,0.21491562,0.21120666,0.3499767,0.08076103,0.13089953,0.27189058,0.265593,0.3139026,0.26000404,0.23774096,0.16705966,0.105316944,0.15476301,0.18681635,0.123620264,0.11810631,0.22307149,0.35589582,0.34983042,0.29998067,0.35821304,0.24626796,0.1524157,0.18410476,0.050905112,0.24687028,0.27750078,0.6172151,0.19755794,0.17809413,0.1381293,0.08928926,0.37098455,0.43178156,0.3838052],[0.2654518,0.2236846,0.16131549,0.41921565,0.15948606,0.40953338,0.253819,0.42973107,0.41091222,0.4093566,0.48158947,0.26586658,0.40515324,0.41812503,0.43339372,0.45246416,0.40557247,0.49709502,0.53820425,0.45675257,0.55562544,0.4708355,0.4078556,0.618345,0.41357875,0.5513099,0.42912492,0.51024395,0.53916097,0.39335933,0.5486715,0.58544004,0.5104139,0.21912403,1.0000004,0.4092004,0.40782893,0.19090657,0.4720608,0.30252033,0.34106094,0.43097425,0.44486523,0.44974202,0.19689888,0.3873798,0.24130692,0.3412085,0.34306866,0.38396195,0.5221724,0.61899304,0.4401515,0.531524,0.12546808,0.41259274,0.586307,0.4119026,0.5243939,0.21635726,0.6174017,0.50596446,0.66425973,0.23020999,0.2641427,0.59232855,0.4063402,0.61099005,0.16686757,0.4386697,0.4536578,0.37415686,0.51263356,0.37628344,0.4189467,0.4166637,0.41541785,0.4496678,0.3156827,0.45828715,0.26384977,0.3809774,0.53081065,0.5793617,0.62893283,0.35392123,0.44028774,0.5064407,0.29388613,0.36699286,0.3286575,0.30298784,0.33960074,0.236354,0.56101096,0.2347227],[0.36338168,0.33931682,0.191319,0.6979563,0.19967858,0.5699785,0.16735254,0.3739766,0.30999398,0.5363907,0.5377847,0.26237038,0.3760409,0.4825095,0.5699825,0.44291392,0.5278741,0.4123496,0.48807856,0.4961765,0.28976706,0.5440672,0.4301778,0.48997086,0.40381524,0.44703838,0.52796125,0.43299899,0.5711239,0.5181648,0.2973832,0.5788766,0.4360334,0.26202023,0.4092004,1.0,0.54888463,0.2839092,0.49760726,0.27794594,0.45596337,0.49114648,0.4614591,0.6365445,0.21928404,0.4720072,0.3260521,0.37894246,0.3628633,0.52732563,0.5171887,0.57336915,0.52288896,0.5590434,0.204884,0.5595656,0.47029823,0.31047052,0.5370547,0.2959222,0.6369778,0.29415172,0.30801058,0.34686723,0.3602339,0.56038076,0.6755785,0.6323543,0.12245294,0.37447628,0.43468165,0.6366701,0.3624479,0.4825608,0.6662192,0.45162234,0.42637387,0.49178156,0.3657598,0.41379884,0.2288145,0.4190024,0.6734681,0.43183318,0.6028885,0.40214324,0.8085052,0.2945556,0.40446317,0.5520493,0.5054343,0.4151238,0.43538523,0.25589687,0.21660985,0.24962884],[0.32180005,0.188062,0.20556855,0.77866507,0.10508199,0.55595565,0.20167495,0.34979856,0.2906291,0.75492334,0.3863832,0.09368725,0.3035858,0.539177,0.8366513,0.4652115,0.80701584,0.46901956,0.5341354,0.44648433,0.27342123,0.80553246,0.37510586,0.65326947,0.27107504,0.4167772,0.2298011,0.4124316,0.45175785,0.539862,0.23671192,0.6817725,0.4150014,0.12021967,0.40782893,0.54888463,1.0,0.1750668,0.5965819,0.16822398,0.7930089,0.4417103,0.34677273,0.4859619,0.15633012,0.4650953,0.073448285,0.21908548,0.6321661,0.42244175,0.56653935,0.598195,0.36440977,0.7119714,0.11821783,0.6970765,0.4089438,0.34399873,0.71136487,0.2200002,0.76926315,0.27595538,0.21801089,0.24238552,0.20744945,0.6621717,0.4753799,0.56066185,0.16330387,0.2852432,0.42058197,0.54651016,0.26950002,0.45238104,0.5472084,0.45312262,0.50669724,0.48131424,0.40279764,0.37947756,0.24685264,0.37649462,0.45363578,0.4216461,0.7062997,0.36966902,0.4889374,0.3859613,0.40872508,0.7840859,0.6901908,0.41897607,0.49863407,0.042456973,0.18645787,0.26528662],[0.4706342,0.3282211,0.23902449,0.22167991,0.3542663,0.24344973,0.1538443,0.2472974,0.2643344,0.2542234,0.41926402,0.41759214,0.3862741,0.19197068,0.16250385,0.22152466,0.20575738,0.33118162,0.19924852,0.53842396,0.19567966,0.22465295,0.17196794,0.21041971,0.3260574,0.22579166,0.30039677,0.1476146,0.5829665,0.19508801,0.20135166,0.34038955,0.3964732,0.6156505,0.19090657,0.2839092,0.1750668,0.99999976,0.2411789,0.39017013,0.23835371,0.21598643,0.18728918,0.15913881,0.7133003,0.17044513,0.4960951,0.31372124,0.24675989,0.27197137,0.20939128,0.20326206,0.13575175,0.19220307,0.4403514,0.25901625,0.133429,0.2741473,0.26808563,0.41430596,0.2778215,0.09949422,0.16354442,0.31424442,0.17634536,0.13822475,0.2960263,0.28004572,0.20373029,0.28803888,0.26220325,0.20869538,0.14230242,0.21095686,0.27316326,0.13677828,0.12086796,0.21436827,0.2710619,0.2416367,0.18123558,0.29675877,0.24702804,0.16640502,0.19314384,0.11765036,0.31532678,0.24032712,0.36166087,0.19467585,0.17581789,0.1589335,0.14756964,0.46037284,0.2516324,0.3863493],[0.3078246,0.20976152,0.17372626,0.5052284,0.14621806,0.44429222,0.23058343,0.40167436,0.42967075,0.5059124,0.480001,0.2445331,0.45269993,0.44776893,0.58627784,0.49091184,0.60225165,0.46363056,0.46334216,0.5397342,0.39865592,0.6111686,0.4138877,0.5576043,0.46001396,0.6434258,0.44262385,0.45938534,0.5582693,0.6772386,0.5025914,0.51181763,0.47626746,0.18526962,0.4720608,0.49760726,0.5965819,0.2411789,1.0,0.48855096,0.5593156,0.4315188,0.46939045,0.47822833,0.20437261,0.4954308,0.25547045,0.38670927,0.66340166,0.40809855,0.52835673,0.5243051,0.5981047,0.5503875,0.16272771,0.46337014,0.5519408,0.54116136,0.5157095,0.2225586,0.6243644,0.4441004,0.36533833,0.4868106,0.2918691,0.54861933,0.4769899,0.6633419,0.15136111,0.35129535,0.7715019,0.49775174,0.42316538,0.5247109,0.4229304,0.4946173,0.3876235,0.5316443,0.711333,0.38827112,0.19483675,0.37914422,0.56206125,0.5066238,0.5360491,0.3759758,0.4757013,0.47878897,0.30312228,0.47016406,0.5973542,0.40564507,0.34998176,0.22311173,0.38318074,0.53131586],[0.2353861,0.23425853,0.16625904,0.18468793,0.34553105,0.24538076,0.18049729,0.41426808,0.36758548,0.22326481,0.47975814,0.40895915,0.5808872,0.20771569,0.18954512,0.233535,0.22938514,0.31540087,0.23654324,0.41956836,0.26130658,0.27714345,0.08639239,0.30504164,0.4037614,0.5971489,0.38365376,0.21194299,0.5974858,0.49038175,0.47459376,0.37896678,0.6268904,0.5007443,0.30252033,0.27794594,0.16822398,0.39017013,0.48855096,0.9999996,0.2280077,0.27245665,0.23159763,0.18980345,0.2603186,0.19017713,0.48963416,0.3540944,0.33692163,0.2577401,0.2891998,0.33660772,0.30422154,0.1946535,0.21834448,0.23243013,0.2942843,0.4980206,0.29603055,0.23321584,0.2894542,0.4397056,0.27942663,0.6343736,0.04826719,0.28315863,0.28927442,0.39402688,0.14640042,0.19851631,0.38246652,0.20122893,0.16876598,0.20410009,0.30205366,0.18333125,0.15100683,0.27363536,0.59517074,0.2865326,0.25678015,0.2686248,0.3239796,0.24840212,0.25781187,0.10848568,0.37494916,0.33756793,0.41198835,0.20744267,0.2826514,0.14580975,0.10282,0.41476867,0.61787224,0.6921462],[0.36195162,0.17831159,0.2107614,0.677714,0.12191095,0.4076011,0.12914073,0.28969684,0.2209614,0.73787034,0.39923036,0.10636083,0.2477009,0.35841024,0.6971061,0.31826064,0.7345808,0.38742405,0.38922074,0.45997488,0.20737514,0.73072666,0.22767343,0.53522027,0.21998043,0.4120238,0.2125559,0.31147483,0.4659164,0.5136464,0.21753225,0.5581331,0.40410113,0.21343017,0.34106094,0.45596337,0.7930089,0.23835371,0.5593156,0.2280077,1.0000004,0.37240782,0.25276995,0.3251123,0.15673794,0.31008488,0.05267993,0.14322573,0.7143636,0.30352703,0.44790572,0.48665038,0.2778312,0.6287957,0.098056145,0.5058412,0.32326314,0.31006235,0.5684204,0.20553876,0.62252283,0.21087936,0.17610861,0.26175833,0.122023836,0.5022412,0.3884857,0.4789645,0.15972242,0.17004043,0.32823622,0.41366318,0.17888853,0.517898,0.42934877,0.3164305,0.33954608,0.33849984,0.45924598,0.2938751,0.20510027,0.3869425,0.36381686,0.30805686,0.57458574,0.2132159,0.41012028,0.2977208,0.53120744,0.78053635,0.7207481,0.29574257,0.3451844,0.06541968,0.16759364,0.3376382],[0.37349513,0.34888843,0.1689085,0.55063957,0.10220477,0.4528404,0.28953648,0.26787472,0.35674122,0.48136708,0.47062287,0.21028756,0.2772437,0.4705491,0.4990799,0.45168546,0.40580428,0.43029568,0.562787,0.4445102,0.311218,0.45165527,0.34060112,0.47515112,0.34095028,0.4764771,0.42629194,0.41487595,0.57802576,0.43762445,0.29262498,0.56062365,0.4675619,0.2360522,0.43097425,0.49114648,0.4417103,0.21598643,0.4315188,0.27245665,0.37240782,0.9999998,0.33580336,0.6022895,0.2956991,0.39154398,0.30394408,0.39981288,0.30279687,0.7560551,0.44927543,0.4915453,0.3531064,0.4392662,0.47930273,0.45934004,0.3586325,0.23865542,0.47919723,0.37797812,0.5810115,0.36817947,0.24341096,0.3208645,0.38711867,0.54529935,0.49642223,0.5589653,0.18507041,0.4581266,0.3664352,0.44838533,0.24192323,0.2592426,0.45606887,0.44563198,0.43937138,0.5025349,0.36407942,0.42769036,0.29729062,0.7811994,0.567399,0.3369446,0.5015694,0.31477642,0.57792693,0.27248558,0.3032691,0.36241663,0.40550438,0.38226637,0.4302002,0.26811293,0.22833122,0.25971335],[0.30105802,0.20758368,0.26781243,0.33953145,0.17163804,0.43226427,0.21454884,0.26741922,0.511006,0.3948699,0.3586959,0.18389912,0.34670922,0.6116255,0.5635552,0.6720291,0.43579513,0.40132445,0.36099076,0.38636193,0.4369923,0.38178337,0.5709204,0.39917526,0.4410946,0.513586,0.5037654,0.53740704,0.40382063,0.545505,0.48230055,0.3578791,0.32009947,0.18964921,0.44486523,0.4614591,0.34677273,0.18728918,0.46939045,0.23159763,0.25276995,0.33580336,1.0000004,0.61059755,0.22195116,0.6250241,0.18456422,0.33420864,0.25141263,0.3373445,0.3621535,0.5661248,0.6533504,0.37754282,0.17527543,0.44264036,0.49937126,0.32332897,0.3330652,0.27927455,0.4860363,0.4252321,0.2919949,0.31048733,0.5545082,0.4962588,0.36996347,0.6047818,0.17677131,0.31553885,0.40326294,0.52551204,0.56024545,0.54286015,0.33852637,0.6645366,0.48843062,0.7128484,0.35014877,0.31700456,0.24497809,0.3140004,0.48430148,0.36844715,0.468165,0.54428416,0.42681342,0.3034977,0.13842696,0.29661828,0.30883932,0.54438055,0.45315105,0.17399293,0.22712155,0.28500116],[0.31688377,0.19547938,0.1830944,0.6370297,0.13690788,0.573853,0.22077222,0.28771836,0.49551374,0.5000081,0.4091572,0.14211474,0.29771045,0.7557585,0.6847219,0.65103656,0.5013225,0.45141226,0.45659027,0.44105807,0.39516115,0.47446844,0.63314265,0.45468405,0.38927305,0.44949928,0.5781257,0.56013596,0.44007558,0.49169576,0.3341295,0.46227503,0.36521554,0.15921703,0.44974202,0.6365445,0.4859619,0.15913881,0.47822833,0.18980345,0.3251123,0.6022895,0.61059755,1.0000001,0.16364065,0.6884078,0.113601,0.48811933,0.2858381,0.62874323,0.4674696,0.57253593,0.5745973,0.49134317,0.18443754,0.6080046,0.5306449,0.30532128,0.44062233,0.2585264,0.59937996,0.34803736,0.32989952,0.2666131,0.5864761,0.63152516,0.63986737,0.6670397,0.12540342,0.34199625,0.39736927,0.6177004,0.5344174,0.46892148,0.39939773,0.7422553,0.6793102,0.72439957,0.32901582,0.34867585,0.2759443,0.4035601,0.798435,0.36986703,0.5406268,0.61046576,0.5039908,0.29089972,0.19869697,0.39592394,0.41124848,0.7078503,0.66226053,0.1832328,0.18273084,0.22220802],[0.39983383,0.27873662,0.24168682,0.23181376,0.32643068,0.17631699,0.1507656,0.12781249,0.24917167,0.2615191,0.40512183,0.45230374,0.2517285,0.1648131,0.16499893,0.23119731,0.17664039,0.29448956,0.1733604,0.39860478,0.24097338,0.18633665,0.14328371,0.16806433,0.31484842,0.19005674,0.29375938,0.13906813,0.502155,0.2757237,0.20510726,0.2628056,0.3102092,0.530812,0.19689888,0.21928404,0.15633012,0.7133003,0.20437261,0.2603186,0.15673794,0.2956991,0.22195116,0.16364065,0.9999999,0.14756435,0.45565128,0.3268785,0.17517531,0.28882763,0.20908675,0.17082189,0.15437882,0.16697435,0.76467955,0.18885478,0.11947012,0.1515986,0.17945845,0.63543963,0.23791349,0.07116617,0.17958327,0.36767063,0.20457089,0.16276696,0.22012323,0.27458256,0.23024961,0.27735838,0.23193425,0.1810433,0.17239827,0.16427656,0.2000328,0.1325538,0.12023668,0.20274444,0.2682184,0.26305383,0.14857547,0.40504563,0.23284152,0.17073394,0.18464437,0.080841884,0.26702824,0.19564179,0.25422767,0.15036531,0.14410526,0.14313607,0.11223497,0.45278662,0.19056995,0.25483477],[0.27619186,0.18559125,0.18255806,0.367797,0.12906784,0.68762565,0.20408241,0.33484048,0.4599711,0.50623703,0.34647486,0.13720708,0.29590726,0.768532,0.68015283,0.6160866,0.5350689,0.39193693,0.45649576,0.3891547,0.35298577,0.40597773,0.64743525,0.42894986,0.3629888,0.516087,0.40012258,0.6092868,0.38142508,0.57671803,0.41122073,0.4326691,0.29789364,0.10631454,0.3873798,0.4720072,0.4650953,0.17044513,0.4954308,0.19017713,0.31008488,0.39154398,0.6250241,0.6884078,0.14756435,0.9999998,0.13588598,0.2805075,0.3010936,0.36894238,0.3717248,0.5411766,0.58292115,0.43824998,0.10569867,0.6028051,0.44370714,0.3039011,0.41026965,0.2186106,0.5125516,0.40188456,0.28192112,0.28243628,0.4285042,0.5470555,0.37300467,0.5953087,0.124422446,0.31978104,0.42439878,0.6603704,0.48133156,0.5131934,0.35995984,0.7734007,0.6418766,0.78558064,0.35682723,0.25462124,0.1938214,0.30065423,0.45230547,0.3571792,0.48390675,0.6417965,0.4239235,0.34147295,0.145719,0.34487212,0.426094,0.70166206,0.6714447,0.1547441,0.22741894,0.22359072],[0.39478433,0.4461919,0.2246764,0.12461755,0.35039383,0.17744406,0.27926785,0.30905035,0.27073884,0.18668866,0.414643,0.5877738,0.38079706,0.11303455,0.06411487,0.15135936,0.079355136,0.26079297,0.27106842,0.41543108,0.2799838,0.15936173,0.14898956,0.15328753,0.34322566,0.33861235,0.33974165,0.15484256,0.48313403,0.27185678,0.42428616,0.28342542,0.3980662,0.42178965,0.24130692,0.3260521,0.073448285,0.4960951,0.25547045,0.48963416,0.05267993,0.30394408,0.18456422,0.113601,0.45565128,0.13588598,0.99999976,0.4936378,0.115667775,0.36485448,0.1936947,0.22473419,0.19660428,0.091363534,0.51476854,0.1784243,0.12773219,0.29835504,0.17023061,0.3612257,0.18484351,0.2491214,0.19655809,0.40451407,0.19186221,0.11688314,0.26793364,0.26777288,0.2761874,0.500761,0.32732743,0.18641545,0.112467326,0.13612224,0.35347942,0.09841029,0.07461903,0.16068791,0.32027483,0.33864415,0.19704014,0.32888952,0.23652408,0.20672427,0.15521127,0.07302237,0.51105267,0.26456657,0.26264003,0.100319155,0.13538633,0.08283465,0.035800505,0.5407902,0.46525455,0.32041505],[0.34257734,0.19237988,0.15469296,0.36512795,0.23782936,0.25426388,0.23779787,0.31238344,0.32896408,0.28132832,0.52929574,0.4578726,0.43327996,0.295439,0.24513707,0.3791487,0.23514734,0.34823605,0.29430026,0.5314881,0.3676647,0.3524148,0.40666714,0.37251815,0.47893158,0.362426,0.650967,0.3403484,0.41755944,0.2910881,0.44218585,0.27972698,0.3706733,0.3148773,0.3412085,0.37894246,0.21908548,0.31372124,0.38670927,0.3540944,0.14322573,0.39981288,0.33420864,0.48811933,0.3268785,0.2805075,0.4936378,1.0000001,0.1832936,0.55474526,0.42044407,0.2992126,0.42598698,0.311811,0.29513958,0.27194422,0.3999116,0.40302458,0.22204986,0.23554757,0.34795976,0.3118394,0.34855202,0.2446195,0.3311238,0.291139,0.4500752,0.46171692,0.16925028,0.47037628,0.47195753,0.28793654,0.43672863,0.31066817,0.23347734,0.28626156,0.20591958,0.30608308,0.32455352,0.36918774,0.214049,0.26505944,0.64496195,0.40918955,0.23985015,0.2870935,0.33657053,0.33291537,0.24300258,0.20627223,0.2503363,0.25466388,0.16587603,0.37771124,0.34540126,0.30053645],[0.32483774,0.1674099,0.15259238,0.52818674,0.09926784,0.3328056,0.1407373,0.3744117,0.23083925,0.45168364,0.42113608,0.15658993,0.26871562,0.3141057,0.5156033,0.30103785,0.5447062,0.38122526,0.360174,0.50135016,0.2140378,0.6801755,0.20305929,0.43023086,0.19654353,0.3977067,0.20563222,0.30040073,0.42379487,0.55080616,0.22830471,0.45998782,0.4180252,0.18306687,0.34306866,0.3628633,0.6321661,0.24675989,0.66340166,0.33692163,0.7143636,0.30279687,0.25141263,0.2858381,0.17517531,0.3010936,0.115667775,0.1832936,0.9999998,0.2888709,0.46319884,0.39954096,0.3140355,0.4904943,0.092455596,0.38596627,0.3115841,0.4835588,0.49022946,0.1746092,0.522671,0.26205543,0.25092104,0.37126005,0.12507024,0.45398897,0.36228064,0.45616233,0.11985356,0.21154994,0.43759885,0.3242334,0.22544748,0.43775025,0.3444531,0.2877378,0.306998,0.3085147,0.6246387,0.35375142,0.1548634,0.3053424,0.35506916,0.38834283,0.45937368,0.16762507,0.3199176,0.35754222,0.38026604,0.5146329,0.65690714,0.26142895,0.24006815,0.10119393,0.29070467,0.49204674],[0.39387062,0.2583205,0.18026507,0.58595955,0.114696555,0.41962013,0.29572967,0.35072803,0.36209416,0.4196241,0.49833536,0.2382392,0.33983585,0.44612145,0.44628578,0.50659424,0.39378217,0.4913768,0.4685,0.49096608,0.3415856,0.5014671,0.37500703,0.4211598,0.3456292,0.34366196,0.54832923,0.36960024,0.47515705,0.34335047,0.2749684,0.4690853,0.45413196,0.24206701,0.38396195,0.52732563,0.42244175,0.27197137,0.40809855,0.2577401,0.30352703,0.7560551,0.3373445,0.62874323,0.28882763,0.36894238,0.36485448,0.55474526,0.2888709,0.9999996,0.49804652,0.4357859,0.38545015,0.46850935,0.40972018,0.3974632,0.4360072,0.3304811,0.4305775,0.3183598,0.5487407,0.25109762,0.3269306,0.2802102,0.43744618,0.49541733,0.5527394,0.56843656,0.2074704,0.50936043,0.38582698,0.43413773,0.34723073,0.2475861,0.39899758,0.41427457,0.37904283,0.44172934,0.34030202,0.47984233,0.34241483,0.5254113,0.64910054,0.40110108,0.43637553,0.35337198,0.52717,0.30263495,0.2922797,0.37517485,0.37630486,0.4120763,0.35559654,0.22175306,0.23552923,0.27752796],[0.4400377,0.2294232,0.17913988,0.5789484,0.18792251,0.4711777,0.21824932,0.37717712,0.32552856,0.46307144,0.55286604,0.28168553,0.41466728,0.41390622,0.51488304,0.53805244,0.5103815,0.46973997,0.5256384,0.5789308,0.42511946,0.65360296,0.4228377,0.6859291,0.4094549,0.41757783,0.42018807,0.4450523,0.52225894,0.40534037,0.29099983,0.5942629,0.4588047,0.1825473,0.5221724,0.5171887,0.56653935,0.20939128,0.52835673,0.2891998,0.44790572,0.44927543,0.3621535,0.4674696,0.20908675,0.3717248,0.1936947,0.42044407,0.46319884,0.49804652,0.99999994,0.54663616,0.47423953,0.60181785,0.10737339,0.49131173,0.4912927,0.3821754,0.51957655,0.3077269,0.70684385,0.3541814,0.42494056,0.22391827,0.3072748,0.62843865,0.54682755,0.66159445,0.155203,0.4224436,0.45412412,0.4368013,0.45281914,0.33023733,0.47796375,0.3883162,0.41961113,0.4038828,0.34075812,0.55364686,0.27478522,0.42411128,0.56681144,0.65982616,0.61224234,0.35517496,0.44615936,0.35923067,0.39096692,0.4895766,0.46856317,0.3459068,0.397743,0.1983292,0.29065764,0.2569238],[0.2735248,0.21604937,0.15549952,0.5516325,0.16646293,0.5513757,0.18740748,0.33919856,0.3808201,0.5739546,0.46729195,0.25306967,0.36441493,0.5914539,0.67462134,0.51368725,0.5949707,0.43641296,0.5430036,0.48589292,0.32565027,0.5673502,0.42585233,0.59444976,0.43710706,0.6949564,0.4088853,0.5332887,0.60823375,0.571703,0.44349018,0.7294256,0.5342397,0.19616796,0.61899304,0.57336915,0.598195,0.20326206,0.5243051,0.33660772,0.48665038,0.4915453,0.5661248,0.57253593,0.17082189,0.5411766,0.22473419,0.2992126,0.39954096,0.4357859,0.54663616,1.0,0.4502716,0.51237714,0.138006,0.6115853,0.43509445,0.33548567,0.60645956,0.2698988,0.7409999,0.5551677,0.27973256,0.33743188,0.3435584,0.68638927,0.4682578,0.6448515,0.11584849,0.31108218,0.40326503,0.48511684,0.30434057,0.3989897,0.5704492,0.5558771,0.6066842,0.6279752,0.41291445,0.33623648,0.2079646,0.4289627,0.5733875,0.41960618,0.6960081,0.39662886,0.65311486,0.36072928,0.35711685,0.543022,0.45055896,0.47669768,0.5246161,0.24100526,0.35620838,0.30264202],[0.23986447,0.19193071,0.14916997,0.39786857,0.1238999,0.4331819,0.19425115,0.2763628,0.501121,0.39226517,0.34819606,0.1482215,0.42523232,0.50219756,0.5125139,0.64657116,0.3917747,0.43057397,0.37850976,0.43967035,0.5495481,0.45882908,0.62679887,0.5427934,0.4929458,0.52487314,0.5211595,0.5120577,0.42869115,0.5935037,0.5673619,0.39837295,0.3585023,0.13640146,0.4401515,0.52288896,0.36440977,0.13575175,0.5981047,0.30422154,0.2778312,0.3531064,0.6533504,0.5745973,0.15437882,0.58292115,0.19660428,0.42598698,0.3140355,0.38545015,0.47423953,0.4502716,1.0000001,0.47015736,0.1431299,0.41535202,0.66730314,0.41089636,0.37254018,0.22056264,0.5233006,0.42350936,0.4155911,0.34599066,0.52030927,0.48355585,0.40641162,0.7377833,0.14013036,0.38883117,0.4660341,0.5620509,0.68169326,0.57118005,0.36487943,0.5638646,0.38212484,0.62714887,0.44391283,0.34714842,0.21974476,0.32623595,0.5738001,0.50692195,0.4509787,0.5780939,0.48288724,0.36356893,0.1688471,0.3233625,0.3576694,0.45870504,0.40087032,0.17533882,0.34748507,0.35136312],[0.3011032,0.1926503,0.18790579,0.6748863,0.17959592,0.580409,0.17380728,0.37801212,0.2955186,0.6763434,0.41291094,0.11543371,0.32743248,0.4572008,0.70504403,0.48247406,0.6536677,0.46704242,0.4857764,0.41887647,0.40217692,0.660425,0.46147242,0.75928867,0.29844525,0.37086806,0.3413044,0.43073767,0.4568589,0.47593778,0.29897082,0.60281885,0.40444404,0.1826561,0.531524,0.5590434,0.7119714,0.19220307,0.5503875,0.1946535,0.6287957,0.4392662,0.37754282,0.49134317,0.16697435,0.43824998,0.091363534,0.311811,0.4904943,0.46850935,0.60181785,0.51237714,0.47015736,1.0000001,0.09873244,0.5404617,0.57480305,0.33859813,0.62761545,0.23970534,0.73500925,0.27502167,0.44015953,0.21532516,0.2389823,0.59360725,0.54974896,0.6236627,0.14758937,0.30419528,0.38505316,0.6160149,0.50093514,0.5040354,0.4892507,0.40612057,0.42650172,0.40484673,0.26956806,0.3931828,0.27809742,0.3659652,0.53956294,0.6016761,0.66906375,0.44989276,0.43971235,0.37202546,0.41961545,0.6799183,0.65702873,0.33522946,0.41656387,0.09420025,0.20990655,0.23084436],[0.2605277,0.3254829,0.21109197,0.23693743,0.20587167,0.11851524,0.15439989,0.07557358,0.22183122,0.20089558,0.27879182,0.35780758,0.14712335,0.11723679,0.1249546,0.15130092,0.102677785,0.23795162,0.14968286,0.20960654,0.21137957,0.08345511,0.08619309,0.08578969,0.20074408,0.206826,0.21981978,0.09613394,0.38969973,0.34526727,0.2044932,0.21395966,0.25776967,0.36344245,0.12546808,0.204884,0.11821783,0.4403514,0.16272771,0.21834448,0.098056145,0.47930273,0.17527543,0.18443754,0.76467955,0.10569867,0.51476854,0.29513958,0.092455596,0.40972018,0.10737339,0.138006,0.1431299,0.09873244,1.0000005,0.15441947,0.040631585,0.1194416,0.13816425,0.5890506,0.13742256,0.056387216,0.10574577,0.44365302,0.19919135,0.11183504,0.22507238,0.18418546,0.27341598,0.3031497,0.15898196,0.15914625,0.10251258,0.11931589,0.2612452,0.12015526,0.075074054,0.16659473,0.28342283,0.22249441,0.15325497,0.48691633,0.20514208,0.087040275,0.1463238,0.035825793,0.385428,0.14295572,0.18157767,0.06710557,0.1524532,0.107806966,0.094263166,0.41049314,0.17912234,0.23676257],[0.34689113,0.24666849,0.25937414,0.5412969,0.19810727,0.6546565,0.2218161,0.37883607,0.42500523,0.6213542,0.42508835,0.1819325,0.42655557,0.7444901,0.7160596,0.5360437,0.6201468,0.5045047,0.5216396,0.49381405,0.28731748,0.5438619,0.49364027,0.5228132,0.35662818,0.4448349,0.2975866,0.46918833,0.55705476,0.4851772,0.29934043,0.6728312,0.4195622,0.22605257,0.41259274,0.5595656,0.6970765,0.25901625,0.46337014,0.23243013,0.5058412,0.45934004,0.44264036,0.6080046,0.18885478,0.6028051,0.1784243,0.27194422,0.38596627,0.3974632,0.49131173,0.6115853,0.41535202,0.5404617,0.15441947,0.99999976,0.4106171,0.2748079,0.6328164,0.2873883,0.6676091,0.293884,0.26552266,0.26415238,0.30297768,0.5607251,0.44846615,0.5787924,0.18032612,0.26208055,0.42209128,0.6066339,0.34385026,0.38585863,0.556685,0.5945324,0.64902824,0.66022795,0.3069677,0.29118508,0.29643553,0.40267816,0.49943203,0.37213787,0.6218023,0.5389751,0.5512103,0.33633408,0.3237583,0.5510686,0.4906804,0.58461565,0.6878656,0.20606217,0.20874804,0.22686318],[0.26000893,0.16150625,0.16093889,0.45991066,0.13551351,0.45434943,0.24894002,0.34433782,0.43369323,0.40235814,0.47311527,0.19309232,0.36921135,0.473601,0.47199938,0.52107376,0.4061196,0.44076145,0.42109886,0.42938566,0.44117704,0.45741287,0.55184734,0.6012224,0.43889025,0.4826739,0.6061014,0.5151883,0.4109639,0.4184148,0.5603345,0.48030636,0.43804508,0.14152817,0.586307,0.47029823,0.4089438,0.133429,0.5519408,0.2942843,0.32326314,0.3586325,0.49937126,0.5306449,0.11947012,0.44370714,0.12773219,0.3999116,0.3115841,0.4360072,0.4912927,0.43509445,0.66730314,0.57480305,0.040631585,0.4106171,1.0000001,0.33246347,0.46212247,0.15984538,0.6579142,0.42374235,0.5392082,0.21809007,0.38436288,0.59213185,0.4353904,0.71347946,0.17851147,0.38213903,0.49708897,0.49605218,0.5512573,0.39351657,0.35233963,0.47689116,0.38964325,0.509834,0.3127316,0.43149838,0.23434566,0.30979067,0.60150623,0.49835172,0.5410129,0.6826763,0.4007869,0.42275915,0.2666494,0.40511984,0.36387447,0.38909462,0.37757134,0.156349,0.30853242,0.2384588],[0.2834873,0.21813202,0.15255867,0.32282022,0.15762088,0.29249552,0.23095307,0.7034927,0.33979917,0.2673467,0.4176828,0.24300644,0.53011364,0.25642723,0.3067298,0.39293423,0.3589146,0.46190706,0.32629475,0.44232717,0.38603657,0.5185554,0.2333766,0.37541187,0.35091245,0.47668317,0.32639807,0.32413882,0.42585495,0.46061626,0.45449722,0.38176647,0.5124509,0.29693168,0.4119026,0.31047052,0.34399873,0.2741473,0.54116136,0.4980206,0.31006235,0.23865542,0.32332897,0.30532128,0.1515986,0.3039011,0.29835504,0.40302458,0.4835588,0.3304811,0.3821754,0.33548567,0.41089636,0.33859813,0.1194416,0.2748079,0.33246347,1.0000002,0.46298876,0.16235833,0.35649568,0.43683425,0.32957867,0.48614803,0.19557984,0.29287204,0.3612846,0.41625687,0.16970463,0.37587425,0.5470422,0.25802702,0.34248236,0.43967494,0.3030796,0.29767987,0.2367556,0.3164029,0.61622095,0.39552724,0.32821304,0.23068175,0.38067812,0.51605546,0.27497935,0.14989471,0.30637833,0.6362949,0.2926694,0.31009,0.32183853,0.20777419,0.16208303,0.16817893,0.5648909,0.78211415],[0.3238087,0.35039663,0.17089818,0.6122722,0.12010879,0.5794237,0.27868348,0.5216981,0.36986417,0.57130694,0.40891328,0.1741559,0.40488824,0.465677,0.60060334,0.4558676,0.6135447,0.6884283,0.6250081,0.4575624,0.365724,0.62378913,0.30231354,0.63316965,0.29962632,0.4623206,0.2390785,0.3809248,0.6302091,0.44617411,0.2926919,0.82783455,0.53893834,0.25095987,0.5243939,0.5370547,0.71136487,0.26808563,0.5157095,0.29603055,0.5684204,0.47919723,0.3330652,0.44062233,0.17945845,0.41026965,0.17023061,0.22204986,0.49022946,0.4305775,0.51957655,0.60645956,0.37254018,0.62761545,0.13816425,0.6328164,0.46212247,0.46298876,1.0000004,0.24857204,0.7320316,0.34537366,0.3186688,0.290716,0.17332566,0.5525214,0.5159892,0.5519402,0.19721766,0.37242472,0.4444601,0.44744205,0.27398795,0.4219124,0.74121225,0.41033497,0.44449076,0.46866506,0.37848553,0.36294156,0.33087158,0.4622991,0.4687459,0.57116574,0.61556774,0.31414643,0.582568,0.6320713,0.37373498,0.6260922,0.488106,0.30772027,0.4077,0.18411867,0.3593744,0.3378583],[0.40665787,0.39104962,0.20729339,0.30537704,0.23625702,0.22966652,0.19997258,0.21938471,0.31895164,0.27316105,0.37404907,0.33393276,0.31867912,0.27459618,0.25893643,0.3367639,0.20963033,0.36670172,0.24054413,0.399696,0.28952304,0.24474986,0.18887658,0.22499906,0.37117723,0.2598704,0.3223583,0.20100066,0.45891362,0.32048988,0.23766397,0.32049924,0.3832377,0.47682652,0.21635726,0.2959222,0.2200002,0.41430596,0.2225586,0.23321584,0.20553876,0.37797812,0.27927455,0.2585264,0.63543963,0.2186106,0.3612257,0.23554757,0.1746092,0.3183598,0.3077269,0.2698988,0.22056264,0.23970534,0.5890506,0.2873883,0.15984538,0.16235833,0.24857204,1.0,0.31337395,0.1545176,0.15074633,0.3236315,0.2305776,0.22292273,0.27455655,0.34135914,0.24183595,0.305688,0.21240968,0.27078322,0.19638203,0.16872822,0.22869729,0.2371034,0.22326043,0.30334073,0.2626987,0.31353188,0.26690692,0.6345739,0.31669682,0.22977427,0.27092928,0.17531312,0.29950356,0.20922554,0.26485258,0.22554187,0.18063982,0.24290018,0.18582113,0.39111885,0.16763724,0.19710995],[0.40123934,0.22330208,0.1739858,0.74615675,0.1547807,0.6480483,0.20092788,0.38203344,0.34539852,0.6804812,0.57178885,0.21646567,0.41686317,0.602532,0.75153893,0.56713516,0.6708908,0.48403367,0.62352484,0.620313,0.36411133,0.74448156,0.5037709,0.81506336,0.4731619,0.56269467,0.46162194,0.5307325,0.65395164,0.52533185,0.39804313,0.8365804,0.5429143,0.18481553,0.6174017,0.6369778,0.76926315,0.2778215,0.6243644,0.2894542,0.62252283,0.5810115,0.4860363,0.59937996,0.23791349,0.5125516,0.18484351,0.34795976,0.522671,0.5487407,0.70684385,0.7409999,0.5233006,0.73500925,0.13742256,0.6676091,0.6579142,0.35649568,0.7320316,0.31337395,1.0000001,0.45460474,0.37916678,0.28377378,0.35844404,0.8283699,0.59560287,0.79626757,0.120429575,0.4013549,0.49653226,0.57265335,0.38855946,0.40456253,0.57937753,0.51266724,0.54845816,0.579769,0.36591607,0.4573471,0.23044829,0.50462914,0.6720232,0.5517659,0.7924713,0.52563274,0.60629845,0.3854847,0.4230581,0.6784998,0.6004047,0.48891252,0.5223649,0.20989259,0.28237823,0.2829436],[0.21899001,0.22721675,0.14360876,0.2664782,0.20159277,0.30344063,0.35019058,0.37795967,0.3747532,0.34120467,0.53382766,0.4157722,0.38433105,0.3857985,0.3742786,0.41634127,0.33449322,0.35116512,0.41854104,0.35990638,0.38255352,0.32015824,0.3170106,0.4450993,0.57619333,0.7617599,0.4229706,0.5661148,0.4403107,0.49636024,0.719184,0.48083612,0.64930695,0.21491562,0.50596446,0.29415172,0.27595538,0.09949422,0.4441004,0.4397056,0.21087936,0.36817947,0.4252321,0.34803736,0.07116617,0.40188456,0.2491214,0.3118394,0.26205543,0.25109762,0.3541814,0.5551677,0.42350936,0.27502167,0.056387216,0.293884,0.42374235,0.43683425,0.34537366,0.1545176,0.45460474,0.99999946,0.40134934,0.37825254,0.27853668,0.47783354,0.25202644,0.49056005,0.19557647,0.36099494,0.42394006,0.2734711,0.29806587,0.2631735,0.3308076,0.39136544,0.4461725,0.49167114,0.5288651,0.36944664,0.28178006,0.3174227,0.36842403,0.31408516,0.3902149,0.27046427,0.39099967,0.41051936,0.27112755,0.2446717,0.2648301,0.29882234,0.28961307,0.3047952,0.5357183,0.38436314],[0.2546946,0.21211274,0.23937637,0.2383551,0.25411454,0.30388162,0.31814215,0.35594127,0.43429378,0.25148898,0.5026829,0.38198534,0.3704536,0.2635782,0.2359039,0.38333225,0.23420858,0.45781067,0.31265268,0.33709538,0.55816025,0.29499555,0.38153395,0.48049676,0.4151382,0.32931364,0.42789227,0.4227835,0.33610398,0.27069426,0.50100976,0.368672,0.4476913,0.21120666,0.66425973,0.30801058,0.21801089,0.16354442,0.36533833,0.27942663,0.17610861,0.24341096,0.2919949,0.32989952,0.17958327,0.28192112,0.19655809,0.34855202,0.25092104,0.3269306,0.42494056,0.27973256,0.4155911,0.44015953,0.10574577,0.26552266,0.5392082,0.32957867,0.3186688,0.15074633,0.37916678,0.40134934,1.0000001,0.16538867,0.24347128,0.37700257,0.2993473,0.5001959,0.27294442,0.3800825,0.4268241,0.25852177,0.70607877,0.25283098,0.26036292,0.29563853,0.28171673,0.2900646,0.2797098,0.42339295,0.3729342,0.21498062,0.37911218,0.49926725,0.43302226,0.29763862,0.27789018,0.3967523,0.2437753,0.2259227,0.21175791,0.22171003,0.16476005,0.30936128,0.46614966,0.19181663],[0.19209027,0.22339952,0.19691467,0.27975726,0.20246904,0.24642117,0.19188972,0.26936057,0.33686975,0.25088698,0.36005196,0.27825108,0.37980562,0.25144982,0.27991858,0.26681566,0.2991955,0.28876498,0.24713525,0.32388768,0.2294521,0.31065574,0.11676224,0.22517051,0.29796854,0.5806466,0.29501238,0.21014152,0.49815524,0.76246005,0.4188086,0.31268898,0.46450338,0.3499767,0.23020999,0.34686723,0.24238552,0.31424442,0.4868106,0.6343736,0.26175833,0.3208645,0.31048733,0.2666131,0.36767063,0.28243628,0.40451407,0.2446195,0.37126005,0.2802102,0.22391827,0.33743188,0.34599066,0.21532516,0.44365302,0.26415238,0.21809007,0.48614803,0.290716,0.3236315,0.28377378,0.37825254,0.16538867,0.99999976,0.11401839,0.25338918,0.3345697,0.37573394,0.19548722,0.1902458,0.3723907,0.26888913,0.16305992,0.35302052,0.35216445,0.2466646,0.19582164,0.3379462,0.77308637,0.22472923,0.16673435,0.29823452,0.33259082,0.19885905,0.2338781,0.10755619,0.42044607,0.2501674,0.23884685,0.19551311,0.45176277,0.18394047,0.14240685,0.29359862,0.37544638,0.7220301],[0.3875131,0.20188248,0.14159186,0.27259842,0.1094486,0.30683303,0.23949574,0.16504502,0.33084258,0.25008246,0.3166648,0.17077081,0.23469548,0.48494992,0.40857,0.51602095,0.2508082,0.34492362,0.33290672,0.3544322,0.42839038,0.28572747,0.6382583,0.22058222,0.39786702,0.27046287,0.4953514,0.501175,0.21834287,0.26241675,0.28052104,0.23776637,0.22829603,0.08076103,0.2641427,0.3602339,0.20744945,0.17634536,0.2918691,0.04826719,0.122023836,0.38711867,0.5545082,0.5864761,0.20457089,0.4285042,0.19186221,0.3311238,0.12507024,0.43744618,0.3072748,0.3435584,0.52030927,0.2389823,0.19919135,0.30297768,0.38436288,0.19557984,0.17332566,0.2305776,0.35844404,0.27853668,0.24347128,0.11401839,1.0,0.38709614,0.29572636,0.45150253,0.13008453,0.4808255,0.338185,0.37853703,0.4966938,0.3605592,0.21487719,0.5396531,0.5236471,0.45948794,0.18792069,0.36157683,0.15442088,0.2917191,0.424627,0.24404827,0.29712793,0.49347416,0.31088573,0.21031772,0.071309745,0.16571693,0.13900107,0.54706025,0.396091,0.15346847,0.15448177,0.112006135],[0.31638253,0.1536964,0.17742047,0.62118435,0.13966659,0.6450416,0.2344689,0.31734726,0.34662232,0.5855819,0.5237203,0.16919437,0.36710015,0.63173705,0.7024803,0.5270973,0.5996381,0.38812116,0.576933,0.48812634,0.3347018,0.6455535,0.5235938,0.66283697,0.42318654,0.5473621,0.45340306,0.55921555,0.5298476,0.5027783,0.38874584,0.65749717,0.4770663,0.13089953,0.59232855,0.56038076,0.6621717,0.13822475,0.54861933,0.28315863,0.5022412,0.54529935,0.4962588,0.63152516,0.16276696,0.5470555,0.11688314,0.291139,0.45398897,0.49541733,0.62843865,0.68638927,0.48355585,0.59360725,0.11183504,0.5607251,0.59213185,0.29287204,0.5525214,0.22292273,0.8283699,0.47783354,0.37700257,0.25338918,0.38709614,0.9999996,0.5432575,0.7226139,0.12883314,0.3585914,0.43196657,0.5719513,0.38016272,0.34150645,0.46048468,0.5503725,0.56898475,0.57551056,0.34478998,0.4447062,0.24445628,0.45002663,0.60830003,0.44028205,0.75446254,0.52986884,0.5043879,0.316626,0.34951746,0.53335726,0.5173472,0.52491444,0.55487573,0.15366912,0.26755634,0.22226292],[0.3846921,0.31376758,0.16692324,0.6633349,0.18441373,0.52779686,0.1254779,0.4151705,0.2840319,0.42784464,0.5101649,0.20272112,0.42217523,0.37468946,0.45422363,0.39965227,0.48575065,0.43211186,0.40925515,0.5490825,0.33430243,0.5395684,0.34346858,0.4387606,0.39553058,0.40188733,0.5084239,0.3724469,0.55560005,0.41242784,0.22546135,0.50015104,0.43068787,0.27189058,0.4063402,0.6755785,0.4753799,0.2960263,0.4769899,0.28927442,0.3884857,0.49642223,0.36996347,0.63986737,0.22012323,0.37300467,0.26793364,0.4500752,0.36228064,0.5527394,0.54682755,0.4682578,0.40641162,0.54974896,0.22507238,0.44846615,0.4353904,0.3612846,0.5159892,0.27455655,0.59560287,0.25202644,0.2993473,0.3345697,0.29572636,0.5432575,1.0000001,0.59978485,0.07881805,0.29877403,0.40630695,0.54117686,0.33368617,0.4094764,0.50081384,0.37642062,0.3119754,0.37267625,0.31662464,0.39923912,0.23686278,0.41787234,0.7774636,0.4651174,0.5041308,0.28726172,0.53322625,0.33014467,0.36213878,0.4715039,0.49978542,0.34330562,0.32074603,0.25648463,0.17957528,0.26303053],[0.44527373,0.2617613,0.2693244,0.592821,0.22951446,0.5891433,0.2679437,0.37008548,0.5825341,0.5647409,0.61404455,0.28431246,0.48906788,0.61000603,0.6507911,0.6820076,0.56397367,0.523467,0.5536637,0.636582,0.49317107,0.63248366,0.5810405,0.6969983,0.59194595,0.6165603,0.62942237,0.6387714,0.6652342,0.5886772,0.5425599,0.6468436,0.547286,0.265593,0.61099005,0.6323543,0.56066185,0.28004572,0.6633419,0.39402688,0.4789645,0.5589653,0.6047818,0.6670397,0.27458256,0.5953087,0.26777288,0.46171692,0.45616233,0.56843656,0.66159445,0.6448515,0.7377833,0.6236627,0.18418546,0.5787924,0.71347946,0.41625687,0.5519402,0.34135914,0.79626757,0.49056005,0.5001959,0.37573394,0.45150253,0.7226139,0.59978485,0.9999998,0.2035979,0.44496226,0.5590702,0.62023014,0.55466306,0.5045704,0.46910477,0.60488355,0.53853947,0.70997375,0.464743,0.5029988,0.31380853,0.51897776,0.74697345,0.55633926,0.66456765,0.5660317,0.6007532,0.39118233,0.36309266,0.5086053,0.49770877,0.53213125,0.5208424,0.30575496,0.32065058,0.38656333],[0.2920559,0.27856648,0.710863,0.13467363,0.4173368,0.07264097,0.7456014,0.2328397,0.5179312,0.15274665,0.23802891,0.3571705,0.2166089,0.1285182,0.15052293,0.19960727,0.123723924,0.34132594,0.3041523,0.13401105,0.34548116,0.13817677,0.13232453,0.1338427,0.18940659,0.15625255,0.19778232,0.16078283,0.1944803,0.18549559,0.39379618,0.22463328,0.30876893,0.3139026,0.16686757,0.12245294,0.16330387,0.20373029,0.15136111,0.14640042,0.15972242,0.18507041,0.17677131,0.12540342,0.23024961,0.124422446,0.2761874,0.16925028,0.11985356,0.2074704,0.155203,0.11584849,0.14013036,0.14758937,0.27341598,0.18032612,0.17851147,0.16970463,0.19721766,0.24183595,0.120429575,0.19557647,0.27294442,0.19548722,0.13008453,0.12883314,0.07881805,0.2035979,1.0000002,0.4528159,0.27133816,0.1291372,0.15374511,0.12036075,0.18469368,0.18905252,0.13720183,0.20405173,0.24065886,0.33782104,0.6180875,0.2485724,0.0857904,0.14961159,0.15530758,0.08583247,0.21748742,0.2955017,0.20953731,0.11722308,0.14538561,0.11538924,0.11215089,0.21657524,0.25865963,0.17116939],[0.3664806,0.33221406,0.27130324,0.30187097,0.17802525,0.279505,0.6760312,0.41174996,0.40941364,0.3034025,0.45435748,0.39730385,0.40794486,0.31041798,0.30006614,0.39359865,0.2693909,0.40761554,0.7414925,0.40387705,0.49377194,0.34592733,0.46900094,0.32431296,0.36792812,0.30589366,0.44117525,0.4611638,0.39771494,0.284292,0.4923906,0.47059557,0.4102913,0.26000404,0.4386697,0.37447628,0.2852432,0.28803888,0.35129535,0.19851631,0.17004043,0.4581266,0.31553885,0.34199625,0.27735838,0.31978104,0.500761,0.47037628,0.21154994,0.50936043,0.4224436,0.31108218,0.38883117,0.30419528,0.3031497,0.26208055,0.38213903,0.37587425,0.37242472,0.305688,0.4013549,0.36099494,0.3800825,0.1902458,0.4808255,0.3585914,0.29877403,0.44496226,0.4528159,1.0000002,0.5598478,0.3137237,0.33685696,0.26407057,0.37076122,0.30431294,0.30190676,0.33911598,0.3208445,0.65004206,0.36495265,0.4144574,0.36197618,0.4153445,0.35010308,0.31024334,0.44875526,0.5379599,0.24156213,0.25634447,0.23794937,0.29235694,0.25238982,0.2734415,0.5076487,0.17840071],[0.296446,0.22220111,0.22962157,0.3416126,0.21380438,0.3854646,0.40566313,0.50257,0.4192247,0.3718387,0.5133927,0.33855847,0.58059746,0.40554708,0.39961004,0.4204577,0.42288917,0.4504484,0.5200901,0.5511724,0.4538179,0.4810403,0.43264848,0.39240435,0.54788023,0.4973523,0.44800174,0.5171009,0.49828497,0.45776838,0.53897405,0.4592802,0.4592677,0.23774096,0.4536578,0.43468165,0.42058197,0.26220325,0.7715019,0.38246652,0.32823622,0.3664352,0.40326294,0.39736927,0.23193425,0.42439878,0.32732743,0.47195753,0.43759885,0.38582698,0.45412412,0.40326503,0.4660341,0.38505316,0.15898196,0.42209128,0.49708897,0.5470422,0.4444601,0.21240968,0.49653226,0.42394006,0.4268241,0.3723907,0.338185,0.43196657,0.40630695,0.5590702,0.27133816,0.5598478,1.0000001,0.38031137,0.42577562,0.4053365,0.3631457,0.41200063,0.370951,0.42494196,0.575461,0.47958624,0.26311594,0.31036785,0.4992176,0.49104494,0.3930087,0.32898965,0.4131034,0.64235973,0.24964696,0.33333227,0.40012544,0.35236853,0.3108549,0.25194103,0.40924692,0.3766598],[0.3094754,0.20468219,0.19608632,0.49990332,0.1537368,0.6252434,0.16946746,0.26814556,0.34399176,0.55261356,0.33709884,0.08840631,0.34800285,0.5988102,0.65692425,0.5225462,0.5971544,0.38434622,0.46905962,0.46700415,0.30613935,0.4976862,0.6607026,0.4768679,0.37030798,0.43128538,0.41642728,0.5187045,0.44169953,0.5355085,0.32540554,0.450545,0.31454617,0.16705966,0.37415686,0.6366701,0.54651016,0.20869538,0.49775174,0.20122893,0.41366318,0.44838533,0.52551204,0.6177004,0.1810433,0.6603704,0.18641545,0.28793654,0.3242334,0.43413773,0.4368013,0.48511684,0.5620509,0.6160149,0.15914625,0.6066339,0.49605218,0.25802702,0.44744205,0.27078322,0.57265335,0.2734711,0.25852177,0.26888913,0.37853703,0.5719513,0.54117686,0.62023014,0.1291372,0.3137237,0.38031137,1.0,0.4478582,0.5204011,0.4406724,0.55126625,0.5102861,0.58288676,0.26931384,0.3205635,0.21184531,0.377725,0.5538558,0.39660576,0.5538192,0.6057723,0.5105522,0.2953162,0.229302,0.458057,0.52319545,0.5269841,0.5939773,0.16141345,0.17034663,0.21575966],[0.26395547,0.16590789,0.18847111,0.27129862,0.16500665,0.3470341,0.18281032,0.291242,0.45526803,0.285351,0.3145352,0.18065691,0.3851436,0.45434344,0.3992284,0.64729524,0.32156122,0.5138054,0.26528692,0.37026283,0.6934204,0.35649574,0.6610368,0.5296874,0.45819584,0.30649033,0.48684272,0.48334998,0.23915884,0.3681911,0.4272257,0.26290336,0.24662256,0.105316944,0.51263356,0.3624479,0.26950002,0.14230242,0.42316538,0.16876598,0.17888853,0.24192323,0.56024545,0.5344174,0.17239827,0.48133156,0.112467326,0.43672863,0.22544748,0.34723073,0.45281914,0.30434057,0.68169326,0.50093514,0.10251258,0.34385026,0.5512573,0.34248236,0.27398795,0.19638203,0.38855946,0.29806587,0.70607877,0.16305992,0.4966938,0.38016272,0.33368617,0.55466306,0.15374511,0.33685696,0.42577562,0.4478582,0.9999994,0.5006281,0.23945135,0.48201454,0.37103346,0.4681937,0.24130085,0.29353216,0.2655036,0.18733478,0.47381198,0.5958224,0.4192037,0.51376987,0.2556111,0.37809482,0.08279218,0.21802181,0.23798463,0.39511526,0.31802043,0.16366215,0.26558092,0.18783684],[0.29642248,0.20887423,0.16413164,0.4239113,0.085787706,0.41129214,0.11974779,0.37137225,0.34908286,0.47960502,0.265562,0.05811386,0.30061287,0.3956483,0.5437985,0.48059797,0.55281264,0.4771682,0.28635547,0.35057956,0.43477774,0.46036908,0.4622819,0.39150146,0.31412536,0.4017525,0.37041605,0.4583353,0.32356817,0.590545,0.3756455,0.28924704,0.2539746,0.15476301,0.37628344,0.4825608,0.45238104,0.21095686,0.5247109,0.20410009,0.517898,0.2592426,0.54286015,0.46892148,0.16427656,0.5131934,0.13612224,0.31066817,0.43775025,0.2475861,0.33023733,0.3989897,0.57118005,0.5040354,0.11931589,0.38585863,0.39351657,0.43967494,0.4219124,0.16872822,0.40456253,0.2631735,0.25283098,0.35302052,0.3605592,0.34150645,0.4094764,0.5045704,0.12036075,0.26407057,0.4053365,0.5204011,0.5006281,0.99999976,0.35850245,0.46738893,0.35377342,0.44860616,0.41252732,0.24338944,0.13971403,0.20241907,0.43469277,0.3799268,0.37868452,0.3414081,0.37069055,0.44677567,0.18869983,0.4380631,0.5286718,0.32899135,0.31107286,0.114512004,0.1999133,0.37331414],[0.30138215,0.3912979,0.1456974,0.4988342,0.112931974,0.49769068,0.21227956,0.37154764,0.2993337,0.46726462,0.3770316,0.257646,0.35592872,0.4037452,0.49672577,0.36075822,0.4804805,0.513849,0.55926216,0.40434223,0.3119121,0.4623626,0.32717097,0.5016229,0.28260887,0.44404438,0.2532341,0.3267843,0.58419126,0.46917093,0.28742656,0.6954121,0.46088064,0.18681635,0.4189467,0.6662192,0.5472084,0.27316326,0.4229304,0.30205366,0.42934877,0.45606887,0.33852637,0.39939773,0.2000328,0.35995984,0.35347942,0.23347734,0.3444531,0.39899758,0.47796375,0.5704492,0.36487943,0.4892507,0.2612452,0.556685,0.35233963,0.3030796,0.74121225,0.22869729,0.57937753,0.3308076,0.26036292,0.35216445,0.21487719,0.46048468,0.50081384,0.46910477,0.18469368,0.37076122,0.3631457,0.4406724,0.23945135,0.35850245,0.99999976,0.33213583,0.35689557,0.4298894,0.33846825,0.333244,0.22810192,0.4183668,0.4062828,0.44562268,0.52265435,0.28947437,0.8058656,0.40857908,0.28585142,0.46533552,0.4147716,0.27132496,0.38382286,0.2872984,0.30895635,0.25709727],[0.29770422,0.24751824,0.23382078,0.38465902,0.17374247,0.53071976,0.25739217,0.2826034,0.5442455,0.45590216,0.3489399,0.1399368,0.32121685,0.7692706,0.6941695,0.64667606,0.49783525,0.42413837,0.42866275,0.38969055,0.4033989,0.40506935,0.6357913,0.42025807,0.38238743,0.49145988,0.42311388,0.57177067,0.38055748,0.48608622,0.42907494,0.41245753,0.3377662,0.123620264,0.4166637,0.45162234,0.45312262,0.13677828,0.4946173,0.18333125,0.3164305,0.44563198,0.6645366,0.7422553,0.1325538,0.7734007,0.09841029,0.28626156,0.2877378,0.41427457,0.3883162,0.5558771,0.5638646,0.40612057,0.12015526,0.5945324,0.47689116,0.29767987,0.41033497,0.2371034,0.51266724,0.39136544,0.29563853,0.2466646,0.5396531,0.5503725,0.37642062,0.60488355,0.18905252,0.30431294,0.41200063,0.55126625,0.48201454,0.46738893,0.33213583,1.0000005,0.7594174,0.8028834,0.35238406,0.28668526,0.27235934,0.34570083,0.4904769,0.3343056,0.51829416,0.5993543,0.42045367,0.31836978,0.173892,0.3424968,0.36881983,0.709451,0.6870116,0.15865386,0.21256065,0.22959542],[0.30625352,0.20650448,0.20732722,0.40716505,0.16610415,0.55790013,0.22443895,0.28524208,0.39416203,0.48158726,0.3538325,0.1380263,0.26859802,0.76351744,0.7127267,0.5509946,0.5233745,0.40582052,0.4538347,0.3620777,0.29412237,0.4267755,0.5402722,0.4217788,0.35885575,0.42459494,0.30221745,0.6600526,0.36364043,0.39780965,0.326839,0.5096233,0.38207728,0.11810631,0.41541785,0.42637387,0.50669724,0.12086796,0.3876235,0.15100683,0.33954608,0.43937138,0.48843062,0.6793102,0.12023668,0.6418766,0.07461903,0.20591958,0.306998,0.37904283,0.41961113,0.6066842,0.38212484,0.42650172,0.075074054,0.64902824,0.38964325,0.2367556,0.44449076,0.22326043,0.54845816,0.4461725,0.28171673,0.19582164,0.5236471,0.56898475,0.3119754,0.53853947,0.13720183,0.30190676,0.370951,0.5102861,0.37103346,0.35377342,0.35689557,0.7594174,0.9999995,0.6544009,0.2764494,0.3170414,0.27257317,0.33159533,0.44817084,0.2903119,0.55989987,0.525043,0.3897754,0.30772975,0.20739901,0.40916672,0.3340643,0.69159794,0.7432321,0.15627988,0.17637561,0.16160437],[0.34187427,0.24185483,0.2451968,0.40854344,0.13996379,0.5672572,0.30021173,0.29697984,0.67007416,0.52735335,0.42840797,0.1891768,0.36144716,0.8368844,0.70190716,0.7345664,0.4950427,0.49427408,0.48592073,0.45743966,0.394656,0.43845525,0.5983483,0.4803243,0.42332506,0.5959143,0.5096958,0.54489696,0.49621627,0.5954617,0.47786435,0.50768375,0.4245816,0.22307149,0.4496678,0.49178156,0.48131424,0.21436827,0.5316443,0.27363536,0.33849984,0.5025349,0.7128484,0.72439957,0.20274444,0.78558064,0.16068791,0.30608308,0.3085147,0.44172934,0.4038828,0.6279752,0.62714887,0.40484673,0.16659473,0.66022795,0.509834,0.3164029,0.46866506,0.30334073,0.579769,0.49167114,0.2900646,0.3379462,0.45948794,0.57551056,0.37267625,0.70997375,0.20405173,0.33911598,0.42494196,0.58288676,0.4681937,0.44860616,0.4298894,0.8028834,0.6544009,0.9999998,0.4444478,0.29432997,0.31024107,0.428442,0.5119241,0.32982966,0.5310254,0.6692238,0.51515096,0.3175871,0.17912297,0.35828802,0.3832517,0.6769656,0.6695609,0.2180244,0.25612178,0.31758174],[0.27095836,0.19913332,0.19203353,0.3897396,0.19883822,0.2548345,0.3134956,0.3721453,0.40790042,0.38485783,0.4906694,0.34877935,0.43811637,0.32125843,0.39550522,0.37478548,0.4061423,0.3975615,0.38008842,0.4542876,0.29968384,0.48734093,0.18189697,0.32694927,0.3601865,0.6780564,0.36359158,0.3075712,0.5351057,0.75575083,0.50616586,0.39085007,0.5834651,0.35589582,0.3156827,0.3657598,0.40279764,0.2710619,0.711333,0.59517074,0.45924598,0.36407942,0.35014877,0.32901582,0.2682184,0.35682723,0.32027483,0.32455352,0.6246387,0.34030202,0.34075812,0.41291445,0.44391283,0.26956806,0.28342283,0.3069677,0.3127316,0.61622095,0.37848553,0.2626987,0.36591607,0.5288651,0.2797098,0.77308637,0.18792069,0.34478998,0.31662464,0.464743,0.24065886,0.3208445,0.575461,0.26931384,0.24130085,0.41252732,0.33846825,0.35238406,0.2764494,0.4444478,0.99999964,0.36452612,0.23034891,0.34496507,0.39792433,0.3129501,0.31546667,0.15117723,0.41141376,0.40113965,0.36052144,0.31015834,0.50503844,0.26618925,0.19907406,0.26183555,0.48198375,0.73396873],[0.38181913,0.27265853,0.30542222,0.40766916,0.28874168,0.36254266,0.46971047,0.4231982,0.3466931,0.31011423,0.59897274,0.36426413,0.4136273,0.2943569,0.32745877,0.38612902,0.34114578,0.43188328,0.5097513,0.43241915,0.3807522,0.45798337,0.3469493,0.34502763,0.37659037,0.3073117,0.37735876,0.44301206,0.41817975,0.29838896,0.37685287,0.4390859,0.5786418,0.34983042,0.45828715,0.41379884,0.37947756,0.2416367,0.38827112,0.2865326,0.2938751,0.42769036,0.31700456,0.34867585,0.26305383,0.25462124,0.33864415,0.36918774,0.35375142,0.47984233,0.55364686,0.33623648,0.34714842,0.3931828,0.22249441,0.29118508,0.43149838,0.39552724,0.36294156,0.31353188,0.4573471,0.36944664,0.42339295,0.22472923,0.36157683,0.4447062,0.39923912,0.5029988,0.33782104,0.65004206,0.47958624,0.3205635,0.29353216,0.24338944,0.333244,0.28668526,0.3170414,0.29432997,0.36452612,1.0000001,0.3849833,0.4552344,0.42171755,0.39746517,0.4158325,0.24610366,0.3639453,0.40818664,0.39825365,0.33041498,0.2950874,0.33192942,0.28082964,0.22348629,0.4735956,0.259189],[0.3454162,0.3627936,0.5770073,0.20111467,0.39660302,0.23033302,0.5858151,0.4369725,0.60418826,0.1996789,0.32131413,0.30699423,0.2870979,0.28743643,0.27576545,0.48347375,0.2707312,0.4664708,0.30305704,0.20071755,0.39548174,0.23620096,0.13833036,0.26148683,0.2566242,0.21555391,0.24098642,0.21478316,0.27727345,0.19740887,0.3683438,0.3252666,0.42398858,0.29998067,0.26384977,0.2288145,0.24685264,0.18123558,0.19483675,0.25678015,0.20510027,0.29729062,0.24497809,0.2759443,0.14857547,0.1938214,0.19704014,0.214049,0.1548634,0.34241483,0.27478522,0.2079646,0.21974476,0.27809742,0.15325497,0.29643553,0.23434566,0.32821304,0.33087158,0.26690692,0.23044829,0.28178006,0.3729342,0.16673435,0.15442088,0.24445628,0.23686278,0.31380853,0.6180875,0.36495265,0.26311594,0.21184531,0.2655036,0.13971403,0.22810192,0.27235934,0.27257317,0.31024107,0.23034891,0.3849833,0.99999964,0.31909135,0.21528688,0.24727276,0.27745703,0.1629269,0.26166672,0.31815547,0.2711966,0.238391,0.1643832,0.19413128,0.2443045,0.26062775,0.31283656,0.24902709],[0.4889896,0.552999,0.2127431,0.46185404,0.17431024,0.37500814,0.2569736,0.30220237,0.3517432,0.40981713,0.48521316,0.28814027,0.34693557,0.38001987,0.4144107,0.38191074,0.3371814,0.43250027,0.4710357,0.4905475,0.27218187,0.43775773,0.24200298,0.3728557,0.37195757,0.4577351,0.33832192,0.33800367,0.62372583,0.39738816,0.279222,0.53086853,0.4904086,0.35821304,0.3809774,0.4190024,0.37649462,0.29675877,0.37914422,0.2686248,0.3869425,0.7811994,0.3140004,0.4035601,0.40504563,0.30065423,0.32888952,0.26505944,0.3053424,0.5254113,0.42411128,0.4289627,0.32623595,0.3659652,0.48691633,0.40267816,0.30979067,0.23068175,0.4622991,0.6345739,0.50462914,0.3174227,0.21498062,0.29823452,0.2917191,0.45002663,0.41787234,0.51897776,0.2485724,0.4144574,0.31036785,0.377725,0.18733478,0.20241907,0.4183668,0.34570083,0.33159533,0.428442,0.34496507,0.4552344,0.31909135,0.9999999,0.43676057,0.3325174,0.4615423,0.2455381,0.4847925,0.26722428,0.34452835,0.35003778,0.32463363,0.31221622,0.31618184,0.3653234,0.22028355,0.24465472],[0.3344352,0.20539655,0.14421493,0.69547206,0.16309,0.48826388,0.16527373,0.31357297,0.37793663,0.44810495,0.5573956,0.24376866,0.43662572,0.48409238,0.5169435,0.5259634,0.47780597,0.44063967,0.4409527,0.5999286,0.3775952,0.54543304,0.4768975,0.5364319,0.51472294,0.50559556,0.6746871,0.5116604,0.58071136,0.45317993,0.3836653,0.52599233,0.46722436,0.24626796,0.53081065,0.6734681,0.45363578,0.24702804,0.56206125,0.3239796,0.36381686,0.567399,0.48430148,0.798435,0.23284152,0.45230547,0.23652408,0.64496195,0.35506916,0.64910054,0.56681144,0.5733875,0.5738001,0.53956294,0.20514208,0.49943203,0.60150623,0.38067812,0.4687459,0.31669682,0.6720232,0.36842403,0.37911218,0.33259082,0.424627,0.60830003,0.7774636,0.74697345,0.0857904,0.36197618,0.4992176,0.5538558,0.47381198,0.43469277,0.4062828,0.4904769,0.44817084,0.5119241,0.39792433,0.42171755,0.21528688,0.43676057,1.0,0.48232347,0.5457377,0.43026155,0.51362044,0.3448501,0.29903913,0.42316294,0.4530035,0.45692936,0.40596166,0.25784272,0.24379122,0.30859643],[0.32480812,0.261234,0.14976071,0.4020947,0.17324777,0.380623,0.19593495,0.5289716,0.3328591,0.33225152,0.36425647,0.24091356,0.4626744,0.30907091,0.3639151,0.49943554,0.3700114,0.5597189,0.43838066,0.4892651,0.6057554,0.545422,0.42730796,0.6657814,0.36258855,0.35581806,0.31211945,0.39434385,0.44486535,0.3680829,0.34413132,0.5034786,0.36695537,0.1524157,0.5793617,0.43183318,0.4216461,0.16640502,0.5066238,0.24840212,0.30805686,0.3369446,0.36844715,0.36986703,0.17073394,0.3571792,0.20672427,0.40918955,0.38834283,0.40110108,0.65982616,0.41960618,0.50692195,0.6016761,0.087040275,0.37213787,0.49835172,0.51605546,0.57116574,0.22977427,0.5517659,0.31408516,0.49926725,0.19885905,0.24404827,0.44028205,0.4651174,0.55633926,0.14961159,0.4153445,0.49104494,0.39660576,0.5958224,0.3799268,0.44562268,0.3343056,0.2903119,0.32982966,0.3129501,0.39746517,0.24727276,0.3325174,0.48232347,0.9999996,0.5133862,0.2990352,0.3840857,0.6051014,0.23539008,0.36901864,0.33276266,0.24213558,0.26017562,0.17595993,0.3778425,0.25378877],[0.29765087,0.27075595,0.19434471,0.643934,0.18041043,0.5981284,0.21952872,0.34576127,0.3516556,0.64286447,0.48195335,0.22391595,0.34197673,0.5827313,0.7249426,0.49705672,0.6442675,0.42450193,0.57868993,0.4721117,0.36584553,0.65660566,0.4592659,0.68932503,0.40080678,0.524456,0.3830961,0.49598154,0.5449076,0.5141368,0.34776583,0.7010481,0.477342,0.18410476,0.62893283,0.6028885,0.7062997,0.19314384,0.5360491,0.25781187,0.57458574,0.5015694,0.468165,0.5406268,0.18464437,0.48390675,0.15521127,0.23985015,0.45937368,0.43637553,0.61224234,0.6960081,0.4509787,0.66906375,0.1463238,0.6218023,0.5410129,0.27497935,0.61556774,0.27092928,0.7924713,0.3902149,0.43302226,0.2338781,0.29712793,0.75446254,0.5041308,0.66456765,0.15530758,0.35010308,0.3930087,0.5538192,0.4192037,0.37868452,0.52265435,0.51829416,0.55989987,0.5310254,0.31546667,0.4158325,0.27745703,0.4615423,0.5457377,0.5133862,1.0,0.4836447,0.5542209,0.34498867,0.42706206,0.63239026,0.5496657,0.45493332,0.5383256,0.18252037,0.28319156,0.19819109],[0.21612006,0.092289,0.11794286,0.30113828,0.050476544,0.54757404,0.12968662,0.19421473,0.36755553,0.41959614,0.30062655,0.050390404,0.23675917,0.7572249,0.57807225,0.5524701,0.37918904,0.3064086,0.36633384,0.34891784,0.2598091,0.3332805,0.7633778,0.4682839,0.30440155,0.3365229,0.46942452,0.4936793,0.25947356,0.36807248,0.32637906,0.3733866,0.23559323,0.050905112,0.35392123,0.40214324,0.36966902,0.11765036,0.3759758,0.10848568,0.2132159,0.31477642,0.54428416,0.61046576,0.080841884,0.6417965,0.07302237,0.2870935,0.16762507,0.35337198,0.35517496,0.39662886,0.5780939,0.44989276,0.035825793,0.5389751,0.6826763,0.14989471,0.31414643,0.17531312,0.52563274,0.27046427,0.29763862,0.10755619,0.49347416,0.52986884,0.28726172,0.5660317,0.08583247,0.31024334,0.32898965,0.6057723,0.51376987,0.3414081,0.28947437,0.5993543,0.525043,0.6692238,0.15117723,0.24610366,0.1629269,0.2455381,0.43026155,0.2990352,0.4836447,0.99999976,0.33384186,0.18830101,0.082757086,0.27719557,0.30796552,0.6144443,0.6602011,0.05010072,0.10628314,0.0879708],[0.30625007,0.38252616,0.18679127,0.55083156,0.19550623,0.47764426,0.23576199,0.3458002,0.3741152,0.5019964,0.47759908,0.33820435,0.34428945,0.44368562,0.50893193,0.3896499,0.4378048,0.41084802,0.5558343,0.45152193,0.2911407,0.453614,0.3685344,0.5026516,0.38666657,0.5710772,0.4109745,0.38452855,0.6803295,0.55434084,0.41921294,0.70106375,0.50395393,0.24687028,0.44028774,0.8085052,0.4889374,0.31532678,0.4757013,0.37494916,0.41012028,0.57792693,0.42681342,0.5039908,0.26702824,0.4239235,0.51105267,0.33657053,0.3199176,0.52717,0.44615936,0.65311486,0.48288724,0.43971235,0.385428,0.5512103,0.4007869,0.30637833,0.582568,0.29950356,0.60629845,0.39099967,0.27789018,0.42044607,0.31088573,0.5043879,0.53322625,0.6007532,0.21748742,0.44875526,0.4131034,0.5105522,0.2556111,0.37069055,0.8058656,0.42045367,0.3897754,0.51515096,0.41141376,0.3639453,0.26166672,0.4847925,0.51362044,0.3840857,0.5542209,0.33384186,1.0000005,0.314795,0.36714557,0.4381307,0.42617103,0.34755793,0.42269337,0.3912594,0.34461164,0.3056784],[0.24857004,0.26927722,0.17279916,0.29069746,0.17203917,0.3212074,0.42503622,0.67515254,0.3718344,0.32662708,0.3498422,0.27569857,0.5704432,0.2776623,0.314352,0.41140556,0.39746204,0.6656056,0.50952923,0.40597773,0.5579389,0.41160074,0.29074508,0.35740313,0.36648512,0.41887847,0.2874272,0.41915175,0.400351,0.31658912,0.49976414,0.46333382,0.46858242,0.27750078,0.5064407,0.2945556,0.3859613,0.24032712,0.47878897,0.33756793,0.2977208,0.27248558,0.3034977,0.29089972,0.19564179,0.34147295,0.26456657,0.33291537,0.35754222,0.30263495,0.35923067,0.36072928,0.36356893,0.37202546,0.14295572,0.33633408,0.42275915,0.6362949,0.6320713,0.20922554,0.3854847,0.41051936,0.3967523,0.2501674,0.21031772,0.316626,0.33014467,0.39118233,0.2955017,0.5379599,0.64235973,0.2953162,0.37809482,0.44677567,0.40857908,0.31836978,0.30772975,0.3175871,0.40113965,0.40818664,0.31815547,0.26722428,0.3448501,0.6051014,0.34498867,0.18830101,0.314795,0.99999976,0.22054943,0.3599838,0.26665482,0.19136237,0.19107239,0.19167393,0.5443055,0.34045148],[0.30201593,0.2509724,0.2175141,0.54518074,0.47527263,0.3313468,0.22496581,0.3771303,0.22765505,0.5070575,0.605611,0.40764022,0.3024924,0.17371398,0.33427083,0.1417919,0.33632222,0.23071799,0.3074727,0.4007103,0.12582205,0.43862638,0.06699439,0.39691246,0.2837989,0.36814138,0.311291,0.21816713,0.59301245,0.293838,0.25878185,0.5222521,0.6680712,0.6172151,0.29388613,0.40446317,0.40872508,0.36166087,0.30312228,0.41198835,0.53120744,0.3032691,0.13842696,0.19869697,0.25422767,0.145719,0.26264003,0.24300258,0.38026604,0.2922797,0.39096692,0.35711685,0.1688471,0.41961545,0.18157767,0.3237583,0.2666494,0.2926694,0.37373498,0.26485258,0.4230581,0.27112755,0.2437753,0.23884685,0.071309745,0.34951746,0.36213878,0.36309266,0.20953731,0.24156213,0.24964696,0.229302,0.08279218,0.18869983,0.28585142,0.173892,0.20739901,0.17912297,0.36052144,0.39825365,0.2711966,0.34452835,0.29903913,0.23539008,0.42706206,0.082757086,0.36714557,0.22054943,1.0000002,0.564625,0.39861035,0.1491738,0.17955805,0.2360532,0.38775235,0.30639032],[0.3120381,0.20074174,0.16314052,0.7471646,0.15627858,0.5081713,0.17652224,0.3885734,0.2432512,0.7651188,0.41674247,0.14529343,0.30488643,0.42053217,0.7115741,0.3802691,0.7491331,0.39555228,0.446491,0.46351877,0.24866527,0.7480541,0.28631467,0.56759596,0.2622971,0.3760325,0.28877872,0.37803224,0.45729277,0.4118009,0.24590601,0.624039,0.41657308,0.19755794,0.36699286,0.5520493,0.7840859,0.19467585,0.47016406,0.20744267,0.78053635,0.36241663,0.29661828,0.39592394,0.15036531,0.34487212,0.100319155,0.20627223,0.5146329,0.37517485,0.4895766,0.543022,0.3233625,0.6799183,0.06710557,0.5510686,0.40511984,0.31009,0.6260922,0.22554187,0.6784998,0.2446717,0.2259227,0.19551311,0.16571693,0.53335726,0.4715039,0.5086053,0.11722308,0.25634447,0.33333227,0.458057,0.21802181,0.4380631,0.46533552,0.3424968,0.40916672,0.35828802,0.31015834,0.33041498,0.238391,0.35003778,0.42316294,0.36901864,0.63239026,0.27719557,0.4381307,0.3599838,0.564625,1.0000004,0.6135367,0.32417864,0.36188084,0.08314676,0.22234061,0.21803166],[0.2797305,0.15257517,0.15609217,0.62018484,0.123979926,0.4858676,0.14003363,0.28413314,0.22571015,0.6278695,0.42681012,0.124423884,0.26019013,0.41543317,0.6603377,0.33047432,0.74013054,0.3193177,0.4336546,0.4362531,0.23350264,0.62400705,0.3096426,0.50197196,0.22472426,0.4295512,0.31360933,0.36212295,0.44512063,0.67445153,0.25833723,0.49635074,0.36663547,0.17809413,0.3286575,0.5054343,0.6901908,0.17581789,0.5973542,0.2826514,0.7207481,0.40550438,0.30883932,0.41124848,0.14410526,0.426094,0.13538633,0.2503363,0.65690714,0.37630486,0.46856317,0.45055896,0.3576694,0.65702873,0.1524532,0.4906804,0.36387447,0.32183853,0.488106,0.18063982,0.6004047,0.2648301,0.21175791,0.45176277,0.13900107,0.5173472,0.49978542,0.49770877,0.14538561,0.23794937,0.40012544,0.52319545,0.23798463,0.5286718,0.4147716,0.36881983,0.3340643,0.3832517,0.50503844,0.2950874,0.1643832,0.32463363,0.4530035,0.33276266,0.5496657,0.30796552,0.42617103,0.26665482,0.39861035,0.6135367,0.9999998,0.35057694,0.36118418,0.1049124,0.21260506,0.3837442],[0.27758387,0.12289717,0.1584253,0.37703648,0.13157414,0.5560128,0.17924322,0.22818303,0.39514938,0.48558918,0.32632855,0.11647349,0.26764843,0.7793743,0.65048146,0.558054,0.47226757,0.3233033,0.38064328,0.38480017,0.2952909,0.38546553,0.6152681,0.34313235,0.37614405,0.36784792,0.36424768,0.5194078,0.3324961,0.3984894,0.29850945,0.39223054,0.31202164,0.1381293,0.30298784,0.4151238,0.41897607,0.1589335,0.40564507,0.14580975,0.29574257,0.38226637,0.54438055,0.7078503,0.14313607,0.70166206,0.08283465,0.25466388,0.26142895,0.4120763,0.3459068,0.47669768,0.45870504,0.33522946,0.107806966,0.58461565,0.38909462,0.20777419,0.30772027,0.24290018,0.48891252,0.29882234,0.22171003,0.18394047,0.54706025,0.52491444,0.34330562,0.53213125,0.11538924,0.29235694,0.35236853,0.5269841,0.39511526,0.32899135,0.27132496,0.709451,0.69159794,0.6769656,0.26618925,0.33192942,0.19413128,0.31221622,0.45692936,0.24213558,0.45493332,0.6144443,0.34755793,0.19136237,0.1491738,0.32417864,0.35057694,1.0000006,0.72233903,0.13973121,0.18102327,0.16782226],[0.24049482,0.15563399,0.16027819,0.37445197,0.1382691,0.6046986,0.18147123,0.1950783,0.3910871,0.5252383,0.29774955,0.094601646,0.24598119,0.81740206,0.7194395,0.49885234,0.51827383,0.30529058,0.4792259,0.3508101,0.21647565,0.37809667,0.5996537,0.43743315,0.30327556,0.36184093,0.27523658,0.54014796,0.36197668,0.38106456,0.23741885,0.48738757,0.29640225,0.08928926,0.33960074,0.43538523,0.49863407,0.14756964,0.34998176,0.10282,0.3451844,0.4302002,0.45315105,0.66226053,0.11223497,0.6714447,0.035800505,0.16587603,0.24006815,0.35559654,0.397743,0.5246161,0.40087032,0.41656387,0.094263166,0.6878656,0.37757134,0.16208303,0.4077,0.18582113,0.5223649,0.28961307,0.16476005,0.14240685,0.396091,0.55487573,0.32074603,0.5208424,0.11215089,0.25238982,0.3108549,0.5939773,0.31802043,0.31107286,0.38382286,0.6870116,0.7432321,0.6695609,0.19907406,0.28082964,0.2443045,0.31618184,0.40596166,0.26017562,0.5383256,0.6602011,0.42269337,0.19107239,0.17955805,0.36188084,0.36118418,0.72233903,1.0000001,0.12402778,0.096992165,0.12388921],[0.40628156,0.43952543,0.26910776,0.10172674,0.42828658,0.17079143,0.2313151,0.1891615,0.39160615,0.18466419,0.45825696,0.6640941,0.38789108,0.1702185,0.110457286,0.1643046,0.114136375,0.3057715,0.1622333,0.40795404,0.29273564,0.090848505,0.0845628,0.16808401,0.43679273,0.34864247,0.31820247,0.1516126,0.4670067,0.24026768,0.42529434,0.2745694,0.39130995,0.37098455,0.236354,0.25589687,0.042456973,0.46037284,0.22311173,0.41476867,0.06541968,0.26811293,0.17399293,0.1832328,0.45278662,0.1547441,0.5407902,0.37771124,0.10119393,0.22175306,0.1983292,0.24100526,0.17533882,0.09420025,0.41049314,0.20606217,0.156349,0.16817893,0.18411867,0.39111885,0.20989259,0.3047952,0.30936128,0.29359862,0.15346847,0.15366912,0.25648463,0.30575496,0.21657524,0.2734415,0.25194103,0.16141345,0.16366215,0.114512004,0.2872984,0.15865386,0.15627988,0.2180244,0.26183555,0.22348629,0.26062775,0.3653234,0.25784272,0.17595993,0.18252037,0.05010072,0.3912594,0.19167393,0.2360532,0.08314676,0.1049124,0.13973121,0.12402778,0.99999994,0.30415237,0.17611524],[0.18124987,0.2452975,0.14177655,0.20179655,0.28098157,0.22507243,0.3966019,0.52398515,0.37361145,0.22905914,0.42217922,0.4274576,0.51177675,0.19781473,0.17631571,0.24843726,0.20460257,0.3837017,0.42587483,0.3270475,0.49283522,0.2562196,0.22600746,0.3253662,0.36211452,0.52506727,0.2931735,0.30523595,0.46800026,0.36877596,0.63699746,0.4358108,0.65027034,0.43178156,0.56101096,0.21660985,0.18645787,0.2516324,0.38318074,0.61787224,0.16759364,0.22833122,0.22712155,0.18273084,0.19056995,0.22741894,0.46525455,0.34540126,0.29070467,0.23552923,0.29065764,0.35620838,0.34748507,0.20990655,0.17912234,0.20874804,0.30853242,0.5648909,0.3593744,0.16763724,0.28237823,0.5357183,0.46614966,0.37544638,0.15448177,0.26755634,0.17957528,0.32065058,0.25865963,0.5076487,0.40924692,0.17034663,0.26558092,0.1999133,0.30895635,0.21256065,0.17637561,0.25612178,0.48198375,0.4735956,0.31283656,0.22028355,0.24379122,0.3778425,0.28319156,0.10628314,0.34461164,0.5443055,0.38775235,0.22234061,0.21260506,0.18102327,0.096992165,0.30415237,1.0000001,0.46586928],[0.26829326,0.18465798,0.18411946,0.24959587,0.18052539,0.19356972,0.1377304,0.37040025,0.33084425,0.2380009,0.37631822,0.20183615,0.42234793,0.20844422,0.28004032,0.29753673,0.31824064,0.35541463,0.19741495,0.38109285,0.23053043,0.40635696,0.11749526,0.2944083,0.31403452,0.534594,0.29845867,0.19952103,0.49140948,0.5931095,0.40314153,0.32322553,0.528802,0.3838052,0.2347227,0.24962884,0.26528662,0.3863493,0.53131586,0.6921462,0.3376382,0.25971335,0.28500116,0.22220802,0.25483477,0.22359072,0.32041505,0.30053645,0.49204674,0.27752796,0.2569238,0.30264202,0.35136312,0.23084436,0.23676257,0.22686318,0.2384588,0.78211415,0.3378583,0.19710995,0.2829436,0.38436314,0.19181663,0.7220301,0.112006135,0.22226292,0.26303053,0.38656333,0.17116939,0.17840071,0.3766598,0.21575966,0.18783684,0.37331414,0.25709727,0.22959542,0.16160437,0.31758174,0.73396873,0.259189,0.24902709,0.24465472,0.30859643,0.25378877,0.19819109,0.0879708,0.3056784,0.34045148,0.30639032,0.21803166,0.3837442,0.16782226,0.12388921,0.17611524,0.46586928,1.0000002]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"x: %{x}\\u003cbr\\u003ey: %{y}\\u003cbr\\u003eSimilarity Score: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\"},\"coloraxis\":{\"colorbar\":{\"title\":{\"text\":\"Similarity Score\"}},\"colorscale\":[[0.0,\"rgb(247,252,240)\"],[0.125,\"rgb(224,243,219)\"],[0.25,\"rgb(204,235,197)\"],[0.375,\"rgb(168,221,181)\"],[0.5,\"rgb(123,204,196)\"],[0.625,\"rgb(78,179,211)\"],[0.75,\"rgb(43,140,190)\"],[0.875,\"rgb(8,104,172)\"],[1.0,\"rgb(8,64,129)\"]]},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"\\u003cb\\u003eSimilarity Matrix\\u003c\\u002fb\\u003e\",\"y\":0.95,\"x\":0.55,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"width\":800,\"height\":800,\"showlegend\":true,\"legend\":{\"title\":{\"text\":\"Trend\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1372f23c-0944-4dbc-b1cb-58b41806314e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "topic_model.visualize_heatmap()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "iaNyTOFBhCS_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "e95397e4-566c-4913-869f-26301597cd3f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e837e48b-8427-477a-bc7d-07cde1a20634\" class=\"plotly-graph-div\" style=\"height:500px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e837e48b-8427-477a-bc7d-07cde1a20634\")) {                    Plotly.newPlot(                        \"e837e48b-8427-477a-bc7d-07cde1a20634\",                        [{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.008624875082246247,0.008786773057233344,0.011983380236548878,0.01381362013570704,0.014970624068037501],\"y\":[\"hole  \",\"energy  \",\"galaxy  \",\"star  \",\"mass  \"],\"type\":\"bar\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":\"#0072B2\"},\"orientation\":\"h\",\"x\":[0.009571152289153085,0.011649336296020935,0.013382253614142437,0.0145139315917993,0.030122121477152024],\"y\":[\"magnetic  \",\"phase  \",\"spin  \",\"state  \",\"quantum  \"],\"type\":\"bar\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":\"#CC79A7\"},\"orientation\":\"h\",\"x\":[0.0175753596361455,0.018901972858344766,0.024597267811082072,0.030602801140532244,0.031499316009204074],\"y\":[\"prove  \",\"category  \",\"mathbb  \",\"algebra  \",\"group  \"],\"type\":\"bar\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":\"#E69F00\"},\"orientation\":\"h\",\"x\":[0.012505867290626286,0.019389716107162558,0.022140019977261737,0.025850240000596315,0.03043973495450948],\"y\":[\"mri  \",\"imaging  \",\"medical  \",\"segmentation  \",\"image  \"],\"type\":\"bar\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":\"#56B4E9\"},\"orientation\":\"h\",\"x\":[0.025579462973813707,0.025769903186004358,0.027995616612954542,0.029070546980595864,0.03328697325265449],\"y\":[\"operator  \",\"space  \",\"solution  \",\"mathbb  \",\"equation  \"],\"type\":\"bar\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"color\":\"#009E73\"},\"orientation\":\"h\",\"x\":[0.0207984022619394,0.02100872618771466,0.02636931947358891,0.0403671324436754,0.05703001747335356],\"y\":[\"music  \",\"asr  \",\"speaker  \",\"audio  \",\"speech  \"],\"type\":\"bar\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"},{\"marker\":{\"color\":\"#F0E442\"},\"orientation\":\"h\",\"x\":[0.01965804964090584,0.022920688658874044,0.031587222852225996,0.0546243779112571,0.08135332723427045],\"y\":[\"tree  \",\"number  \",\"edge  \",\"vertex  \",\"graph  \"],\"type\":\"bar\",\"xaxis\":\"x7\",\"yaxis\":\"y7\"},{\"marker\":{\"color\":\"#D55E00\"},\"orientation\":\"h\",\"x\":[0.017594716048184283,0.02030258239785785,0.022627341383985485,0.027507321861855852,0.029263344452234108],\"y\":[\"antenna  \",\"ri  \",\"wireless  \",\"communication  \",\"channel  \"],\"type\":\"bar\",\"xaxis\":\"x8\",\"yaxis\":\"y8\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.6000000000000001,1.0],\"showgrid\":true},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.6000000000000001,1.0],\"showgrid\":true},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.6000000000000001,1.0],\"showgrid\":true},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.6000000000000001,1.0],\"showgrid\":true},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.0,0.175],\"showgrid\":true},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,0.4],\"showgrid\":true},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.275,0.45],\"showgrid\":true},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,0.4],\"showgrid\":true},\"xaxis7\":{\"anchor\":\"y7\",\"domain\":[0.55,0.7250000000000001],\"showgrid\":true},\"yaxis7\":{\"anchor\":\"x7\",\"domain\":[0.0,0.4],\"showgrid\":true},\"xaxis8\":{\"anchor\":\"y8\",\"domain\":[0.825,1.0],\"showgrid\":true},\"yaxis8\":{\"anchor\":\"x8\",\"domain\":[0.0,0.4],\"showgrid\":true},\"annotations\":[{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 0\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 1\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 2\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 3\",\"x\":0.9125,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":1.0,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 4\",\"x\":0.0875,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.4,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 5\",\"x\":0.36250000000000004,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.4,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 6\",\"x\":0.6375000000000001,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.4,\"yanchor\":\"bottom\",\"yref\":\"paper\"},{\"font\":{\"size\":16},\"showarrow\":false,\"text\":\"Topic 7\",\"x\":0.9125,\"xanchor\":\"center\",\"xref\":\"paper\",\"y\":0.4,\"yanchor\":\"bottom\",\"yref\":\"paper\"}],\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"Topic Word Scores\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"showlegend\":false,\"width\":1000,\"height\":500},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e837e48b-8427-477a-bc7d-07cde1a20634');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "topic_model.visualize_barchart()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "urD3WQY6Sg54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "980d09bc-5c88-47b7-c960-4a47ed73c9e5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"64c7210b-3040-4fc7-ad58-55618a699c98\" class=\"plotly-graph-div\" style=\"height:650px; width:650px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"64c7210b-3040-4fc7-ad58-55618a699c98\")) {                    Plotly.newPlot(                        \"64c7210b-3040-4fc7-ad58-55618a699c98\",                        [{\"customdata\":[[0,\"mass | star | galaxy | energy | hole\",9571],[1,\"quantum | state | spin | phase | magnetic\",7030],[2,\"group | algebra | mathbb | category | prove\",3053],[3,\"image | segmentation | medical | imaging | mri\",1418],[4,\"equation | mathbb | solution | space | operator\",1293],[5,\"speech | audio | speaker | asr | music\",1162],[6,\"graph | vertex | edge | number | tree\",874],[7,\"channel | communication | wireless | ri | antenna\",753],[8,\"logic | proof | automaton | program | semantics\",707],[9,\"image | diffusion | text | generative | generation\",583],[10,\"estimator | distribution | posterior | likelihood | bayesian\",554],[11,\"random | stochastic | equation | process | brownian\",539],[12,\"power | grid | energy | load | system\",507],[13,\"language | translation | llm | multilingual | english\",434],[14,\"image | visual | text | language | vision\",386],[15,\"code | software | bug | vulnerability | developer\",374],[16,\"video | frame | action | temporal | compression\",361],[17,\"memory | hardware | cache | gpu | performance\",355],[18,\"graph | node | gnns | gnn | network\",344],[19,\"climate | forecast | forecasting | weather | ice\",331],[20,\"blockchain | transaction | contract | protocol | smart\",331],[21,\"crop | image | remote | imagery | sensing\",315],[22,\"news | social | medium | twitter | sentiment\",315],[23,\"attack | adversarial | backdoor | robustness | defense\",312],[24,\"market | price | financial | stock | portfolio\",309],[25,\"rl | policy | reward | reinforcement | offline\",309],[26,\"causal | treatment | effect | estimator | trial\",295],[27,\"recommendation | item | user | recommender | ranking\",295],[28,\"neural | equation | pdes | pde | network\",290],[29,\"robot | tactile | grasp | manipulation | human\",288],[30,\"agent | game | nash | equilibrium | player\",283],[31,\"network | pruning | neural | deep | training\",279],[32,\"optimization | convergence | gradient | algorithm | convex\",272],[33,\"element | numerical | equation | method | finite\",252],[34,\"fl | client | federated | learning | privacy\",252],[35,\"brain | eeg | fmri | subject | functional\",252],[36,\"segmentation | transformer | semantic | attention | vision\",246],[37,\"flow | turbulent | vortex | turbulence | wall\",238],[38,\"driving | vehicle | autonomous | traffic | road\",230],[39,\"control | controller | disturbance | system | nonlinear\",228],[40,\"scene | nerf | view | rendering | depth\",225],[41,\"protein | drug | molecule | molecular | chemical\",220],[42,\"student | education | course | educational | ai\",207],[43,\"clinical | medical | biomedical | patient | llm\",198],[44,\"droplet | flow | shear | particle | fluid\",194],[45,\"dialogue | conversational | conversation | intent | response\",188],[46,\"oscillator | bifurcation | synchronization | chimera | phase\",188],[47,\"epidemic | infection | covid | disease | pandemic\",182],[48,\"lidar | sensor | slam | point | cloud\",172],[49,\"gene | cell | genome | dna | sequencing\",168],[50,\"anomaly | detection | log | outlier | data\",163],[51,\"continual | forgetting | learning | meta | task\",159],[52,\"ai | human | decision | trust | ethical\",150],[53,\"face | recognition | deepfake | attack | image\",147],[54,\"polymer | cell | active | membrane | force\",146],[55,\"transformer | attention | layer | sequence | token\",145],[56,\"fairness | bias | fair | attribute | group\",141],[57,\"uav | uavs | aerial | unmanned | drone\",120],[58,\"dnn | quantization | bit | dnns | inference\",118],[59,\"fracture | dislocation | strain | stress | alloy\",117],[60,\"calibration | class | ensemble | training | deep\",114],[61,\"bandit | regret | arm | algorithm | armed\",112],[62,\"privacy | private | dp | differentially | differential\",107],[63,\"robot | locomotion | controller | gait | legged\",107],[64,\"citation | publication | scientific | research | topic\",105],[65,\"label | learning | noisy | instance | active\",102],[66,\"ecg | heart | cardiac | signal | ppg\",102],[67,\"explanation | feature | shapley | xai | explainable\",101],[68,\"matroid | matroids | lattice | polytope | tiling\",100],[69,\"network | community | node | hypergraphs | centrality\",100],[70,\"traffic | travel | mobility | passenger | trip\",100],[71,\"emotion | affective | emotional | facial | expression\",99],[72,\"privacy | cybersecurity | cyber | user | threat\",97],[73,\"metaverse | vr | virtual | reality | user\",97],[74,\"spiking | snns | snn | neuromorphic | spike\",93],[75,\"question | answer | qa | answering | table\",89],[76,\"retrieval | query | document | retriever | lm\",87],[77,\"reasoning | cot | llm | prompting | thought\",86],[78,\"robot | planning | path | environment | planner\",82],[79,\"clustering | cluster | algorithm | mean | distance\",81],[80,\"code | cyclic | mathbb | length | linear\",78],[81,\"crystal | structure | atom | material | atomic\",77],[82,\"patient | survival | risk | clinical | healthcare\",76],[83,\"iot | device | attack | security | internet\",75],[84,\"ssl | supervised | contrastive | learning | self\",75],[85,\"bias | gender | stereotype | social | language\",74],[86,\"neuron | neural | brain | biological | network\",73],[87,\"edge | network | service | caching | computing\",70],[88,\"inverse | problem | regularization | image | reconstruction\",70],[89,\"image | restoration | degradation | resolution | super\",68],[90,\"pose | human | motion | hpe | joint\",63],[91,\"summarization | summary | document | abstractive | text\",63],[92,\"sentence | embeddings | word | embedding | similarity\",63],[93,\"entropy | thermodynamics | thermodynamic | equilibrium | heat\",62],[94,\"distributed | consensus | agent | algorithm | convergence\",60],[95,\"aerial | flight | control | trajectory | quadrotor\",60]],\"hovertemplate\":\"\\u003cb\\u003eTopic %{customdata[0]}\\u003c\\u002fb\\u003e\\u003cbr\\u003e%{customdata[1]}\\u003cbr\\u003eSize: %{customdata[2]}\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#B0BEC5\",\"size\":[9571,7030,3053,1418,1293,1162,874,753,707,583,554,539,507,434,386,374,361,355,344,331,331,315,315,312,309,309,295,295,290,288,283,279,272,252,252,252,246,238,230,228,225,220,207,198,194,188,188,182,172,168,163,159,150,147,146,145,141,120,118,117,114,112,107,107,105,102,102,101,100,100,100,99,97,97,93,89,87,86,82,81,78,77,76,75,75,74,73,70,70,68,63,63,63,62,60,60],\"sizemode\":\"area\",\"sizeref\":5.981875,\"symbol\":\"circle\",\"line\":{\"color\":\"DarkSlateGrey\",\"width\":2}},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[3.5370636,13.050012,6.985167,3.7480073,15.212195,-5.353973,7.0286736,8.444567,-5.0400352,3.86574,18.474382,15.163012,3.4913795,-4.517755,3.9476514,-4.6798716,4.135251,0.4293466,10.853428,3.518191,17.702013,3.7035604,-0.2202887,1.0597619,5.505425,5.804489,18.56171,-4.969082,0.08727376,-1.0054476,5.5701222,0.17040819,18.241184,0.124009155,17.857868,11.142921,3.8691776,14.845291,8.083787,7.9939547,4.348441,13.324805,-4.7445326,-2.3034797,15.036347,-5.1616306,15.100177,18.657063,4.43885,13.383934,1.0028759,1.0699356,0.45293987,1.1091357,15.043556,-4.4426723,0.32240817,8.260891,0.24297012,15.012472,1.063872,5.7850714,17.835842,-0.8751911,-0.109525084,1.0460879,-2.3013682,0.6318746,6.970577,10.937245,8.036675,-0.24059187,17.754538,-1.1725042,11.255646,-4.858588,-4.8353515,-4.6071005,-0.75516117,11.108871,6.8272533,13.121133,-2.390175,1.0660318,1.188757,-0.42662394,11.218099,8.457699,18.169641,3.8027556,4.200905,-4.431534,-4.6206784,15.308893,18.30099,8.094897],\"xaxis\":\"x\",\"y\":[11.49005,-4.67834,-2.7934973,12.5927515,1.8245177,-4.672717,-2.7503822,17.872805,-4.469568,12.197085,4.9149632,1.7700475,11.43359,-5.543371,12.457435,-4.6770353,12.406559,3.1988237,0.03233042,11.526099,-5.4319506,11.977515,-1.615184,1.7861263,8.490917,8.196085,5.0058746,-5.8094773,3.3582067,9.691013,8.42748,2.9344783,4.676075,3.4505558,-5.587562,3.7491586,12.489885,-4.7929187,14.5357485,18.321535,12.818064,-4.398978,-4.571471,1.3594118,-4.9830027,-4.722175,1.7039472,5.1016393,12.882676,-4.340303,2.3926501,2.524318,2.447572,1.6249752,-4.990651,-5.527987,2.2676334,18.056967,3.0097418,-4.95894,2.4808657,8.214623,-5.564567,9.560327,-1.5030259,2.307295,1.3582398,2.525983,-2.8083758,0.11605339,14.486092,-1.6336529,-5.4841824,9.859314,3.6350152,-4.8260226,-5.7545543,-4.765246,9.440642,0.28768238,-2.9516275,-4.6045456,1.2989215,1.6992127,2.512704,-1.8203135,3.6736617,17.85946,4.603502,12.682242,12.335402,-5.495734,-5.7110496,1.9143317,4.736057,18.221272],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"},\"visible\":false,\"range\":[-6.157068848609924,21.455621910095214]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"\"},\"visible\":false,\"range\":[-6.680898928642273,21.06976537704468]},\"legend\":{\"tracegroupgap\":0,\"itemsizing\":\"constant\"},\"margin\":{\"t\":60},\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"\\u003cb\\u003eIntertopic Distance Map\\u003c\\u002fb\\u003e\",\"y\":0.95,\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"width\":650,\"height\":650,\"sliders\":[{\"active\":0,\"pad\":{\"t\":50},\"steps\":[{\"args\":[{\"marker.color\":[[\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 0\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 1\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 2\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 3\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 4\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 5\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 6\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 7\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 8\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 9\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 10\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 11\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 12\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 13\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 14\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 15\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 16\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 17\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 18\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 19\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 20\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 21\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 22\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 23\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 24\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 25\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 26\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 27\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 28\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 29\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 30\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 31\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 32\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 33\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 34\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 35\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 36\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 37\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 38\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 39\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 40\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 41\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 42\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 43\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 44\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 45\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 46\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 47\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 48\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 49\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 50\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 51\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 52\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 53\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 54\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 55\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 56\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 57\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 58\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 59\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 60\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 61\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 62\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 63\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 64\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 65\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 66\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 67\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 68\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 69\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 70\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 71\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 72\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 73\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 74\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 75\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 76\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 77\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 78\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 79\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 80\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 81\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 82\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 83\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 84\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 85\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 86\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 87\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 88\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 89\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 90\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 91\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 92\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\",\"#B0BEC5\"]]}],\"label\":\"Topic 93\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\",\"#B0BEC5\"]]}],\"label\":\"Topic 94\",\"method\":\"update\"},{\"args\":[{\"marker.color\":[[\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"#B0BEC5\",\"red\"]]}],\"label\":\"Topic 95\",\"method\":\"update\"}]}],\"shapes\":[{\"line\":{\"color\":\"#CFD8DC\",\"width\":2},\"type\":\"line\",\"x0\":7.649276530742645,\"x1\":7.649276530742645,\"y0\":-6.680898928642273,\"y1\":21.06976537704468},{\"line\":{\"color\":\"#9E9E9E\",\"width\":2},\"type\":\"line\",\"x0\":-6.157068848609924,\"x1\":21.455621910095214,\"y0\":7.194433224201203,\"y1\":7.194433224201203}],\"annotations\":[{\"showarrow\":false,\"text\":\"D1\",\"x\":-6.157068848609924,\"y\":7.194433224201203,\"yshift\":10},{\"showarrow\":false,\"text\":\"D2\",\"x\":7.649276530742645,\"xshift\":10,\"y\":21.06976537704468}]},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('64c7210b-3040-4fc7-ad58-55618a699c98');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "topic_model.visualize_topics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PfBV2gZ4UqyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "373c80e7-4271-4b0f-c124-cec83b84b6f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"9f48e36e-9a53-432f-8022-4976314e2e79\" class=\"plotly-graph-div\" style=\"height:1640px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9f48e36e-9a53-432f-8022-4976314e2e79\")) {                    Plotly.newPlot(                        \"9f48e36e-9a53-432f-8022-4976314e2e79\",                        [{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.6384111628223521,0.6384111628223521,0.0],\"xaxis\":\"x\",\"y\":[-5.0,-5.0,-15.0,-15.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.0,0.6243628144307345,0.6243628144307345,0.0],\"xaxis\":\"x\",\"y\":[-25.0,-25.0,-35.0,-35.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.0,0.687551906285172,0.687551906285172,0.0],\"xaxis\":\"x\",\"y\":[-45.0,-45.0,-55.0,-55.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.687551906285172,0.7552368762596936,0.7552368762596936,0.0],\"xaxis\":\"x\",\"y\":[-50.0,-50.0,-65.0,-65.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.0,0.6860925790222222,0.6860925790222222,0.0],\"xaxis\":\"x\",\"y\":[-85.0,-85.0,-95.0,-95.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.6860925790222222,0.8043388702328728,0.8043388702328728,0.0],\"xaxis\":\"x\",\"y\":[-90.0,-90.0,-105.0,-105.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.0,0.8411510660734975,0.8411510660734975,0.8043388702328728],\"xaxis\":\"x\",\"y\":[-75.0,-75.0,-97.5,-97.5],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.8411510660734975,0.8541543220316704,0.8541543220316704,0.0],\"xaxis\":\"x\",\"y\":[-86.25,-86.25,-115.0,-115.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.7552368762596936,0.8859697759743032,0.8859697759743032,0.8541543220316704],\"xaxis\":\"x\",\"y\":[-57.5,-57.5,-100.625,-100.625],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.6243628144307345,0.9602166003676391,0.9602166003676391,0.8859697759743032],\"xaxis\":\"x\",\"y\":[-30.0,-30.0,-79.0625,-79.0625],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[0.6384111628223521,1.0659664365670793,1.0659664365670793,0.9602166003676391],\"xaxis\":\"x\",\"y\":[-10.0,-10.0,-54.53125,-54.53125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.0,0.6801513098130529,0.6801513098130529,0.0],\"xaxis\":\"x\",\"y\":[-125.0,-125.0,-135.0,-135.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.0,0.5390972525353777,0.5390972525353777,0.0],\"xaxis\":\"x\",\"y\":[-155.0,-155.0,-165.0,-165.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.5390972525353777,0.6684213589875283,0.6684213589875283,0.0],\"xaxis\":\"x\",\"y\":[-160.0,-160.0,-175.0,-175.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.0,0.7226375370973013,0.7226375370973013,0.6684213589875283],\"xaxis\":\"x\",\"y\":[-145.0,-145.0,-167.5,-167.5],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.7226375370973013,0.7419285518984374,0.7419285518984374,0.0],\"xaxis\":\"x\",\"y\":[-156.25,-156.25,-185.0,-185.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.7419285518984374,0.8061354060372208,0.8061354060372208,0.0],\"xaxis\":\"x\",\"y\":[-170.625,-170.625,-195.0,-195.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.6801513098130529,0.8347442066157235,0.8347442066157235,0.8061354060372208],\"xaxis\":\"x\",\"y\":[-130.0,-130.0,-182.8125,-182.8125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[1.0659664365670793,1.1742289743526864,1.1742289743526864,0.8347442066157235],\"xaxis\":\"x\",\"y\":[-32.265625,-32.265625,-156.40625,-156.40625],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.0,0.559769633258998,0.559769633258998,0.0],\"xaxis\":\"x\",\"y\":[-215.0,-215.0,-225.0,-225.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.0,0.6463652265344918,0.6463652265344918,0.559769633258998],\"xaxis\":\"x\",\"y\":[-205.0,-205.0,-220.0,-220.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.0,0.6436736703544388,0.6436736703544388,0.0],\"xaxis\":\"x\",\"y\":[-235.0,-235.0,-245.0,-245.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.0,0.38141817614947515,0.38141817614947515,0.0],\"xaxis\":\"x\",\"y\":[-265.0,-265.0,-275.0,-275.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.0,0.4459702707376606,0.4459702707376606,0.38141817614947515],\"xaxis\":\"x\",\"y\":[-255.0,-255.0,-270.0,-270.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.0,0.426752542512163,0.426752542512163,0.0],\"xaxis\":\"x\",\"y\":[-285.0,-285.0,-295.0,-295.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.4459702707376606,0.5935798035207598,0.5935798035207598,0.426752542512163],\"xaxis\":\"x\",\"y\":[-262.5,-262.5,-290.0,-290.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.5935798035207598,0.6162457576272493,0.6162457576272493,0.0],\"xaxis\":\"x\",\"y\":[-276.25,-276.25,-305.0,-305.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.6436736703544388,0.7133840286352998,0.7133840286352998,0.6162457576272493],\"xaxis\":\"x\",\"y\":[-240.0,-240.0,-290.625,-290.625],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.6463652265344918,0.8728204273024374,0.8728204273024374,0.7133840286352998],\"xaxis\":\"x\",\"y\":[-212.5,-212.5,-265.3125,-265.3125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,220,0)\"},\"mode\":\"lines\",\"x\":[0.0,0.43445895218492825,0.43445895218492825,0.0],\"xaxis\":\"x\",\"y\":[-325.0,-325.0,-335.0,-335.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,220,0)\"},\"mode\":\"lines\",\"x\":[0.0,0.7577077104843696,0.7577077104843696,0.43445895218492825],\"xaxis\":\"x\",\"y\":[-315.0,-315.0,-330.0,-330.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.0,0.6169209497936565,0.6169209497936565,0.0],\"xaxis\":\"x\",\"y\":[-345.0,-345.0,-355.0,-355.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.6169209497936565,0.7213653462928926,0.7213653462928926,0.0],\"xaxis\":\"x\",\"y\":[-350.0,-350.0,-365.0,-365.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[0.7577077104843696,1.0000563503639228,1.0000563503639228,0.7213653462928926],\"xaxis\":\"x\",\"y\":[-322.5,-322.5,-357.5,-357.5],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.5496785643003234,0.5496785643003234,0.0],\"xaxis\":\"x\",\"y\":[-375.0,-375.0,-385.0,-385.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.4811226110625898,0.4811226110625898,0.0],\"xaxis\":\"x\",\"y\":[-395.0,-395.0,-405.0,-405.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.5496785643003234,0.6942200201655395,0.6942200201655395,0.4811226110625898],\"xaxis\":\"x\",\"y\":[-380.0,-380.0,-400.0,-400.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.5916034123065621,0.5916034123065621,0.0],\"xaxis\":\"x\",\"y\":[-415.0,-415.0,-425.0,-425.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.6942200201655395,0.9614605652940141,0.9614605652940141,0.5916034123065621],\"xaxis\":\"x\",\"y\":[-390.0,-390.0,-420.0,-420.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[1.0000563503639228,1.14315610127018,1.14315610127018,0.9614605652940141],\"xaxis\":\"x\",\"y\":[-340.0,-340.0,-405.0,-405.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.0,0.5031771776252576,0.5031771776252576,0.0],\"xaxis\":\"x\",\"y\":[-435.0,-435.0,-445.0,-445.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.0,0.6729997526571534,0.6729997526571534,0.0],\"xaxis\":\"x\",\"y\":[-455.0,-455.0,-465.0,-465.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.5031771776252576,0.7441986485993638,0.7441986485993638,0.6729997526571534],\"xaxis\":\"x\",\"y\":[-440.0,-440.0,-460.0,-460.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.0,0.5971259044552326,0.5971259044552326,0.0],\"xaxis\":\"x\",\"y\":[-485.0,-485.0,-495.0,-495.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.0,0.738552836795875,0.738552836795875,0.5971259044552326],\"xaxis\":\"x\",\"y\":[-475.0,-475.0,-490.0,-490.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.7441986485993638,0.9583385486966911,0.9583385486966911,0.738552836795875],\"xaxis\":\"x\",\"y\":[-450.0,-450.0,-482.5,-482.5],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.0,0.48382551158079223,0.48382551158079223,0.0],\"xaxis\":\"x\",\"y\":[-515.0,-515.0,-525.0,-525.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.0,0.6612835983718081,0.6612835983718081,0.48382551158079223],\"xaxis\":\"x\",\"y\":[-505.0,-505.0,-520.0,-520.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.0,0.6296675785195146,0.6296675785195146,0.0],\"xaxis\":\"x\",\"y\":[-535.0,-535.0,-545.0,-545.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.6612835983718081,0.7052489338269927,0.7052489338269927,0.6296675785195146],\"xaxis\":\"x\",\"y\":[-512.5,-512.5,-540.0,-540.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[0.9583385486966911,1.044363716227613,1.044363716227613,0.7052489338269927],\"xaxis\":\"x\",\"y\":[-466.25,-466.25,-526.25,-526.25],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.7948147529822062,0.7948147529822062,0.0],\"xaxis\":\"x\",\"y\":[-555.0,-555.0,-565.0,-565.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.0,0.48924018674887515,0.48924018674887515,0.0],\"xaxis\":\"x\",\"y\":[-575.0,-575.0,-585.0,-585.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.48924018674887515,0.5863825706429919,0.5863825706429919,0.0],\"xaxis\":\"x\",\"y\":[-580.0,-580.0,-595.0,-595.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(61,153,112)\"},\"mode\":\"lines\",\"x\":[0.7948147529822062,0.8871475591580851,0.8871475591580851,0.5863825706429919],\"xaxis\":\"x\",\"y\":[-560.0,-560.0,-587.5,-587.5],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[1.044363716227613,1.1035085671714049,1.1035085671714049,0.8871475591580851],\"xaxis\":\"x\",\"y\":[-496.25,-496.25,-573.75,-573.75],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[1.14315610127018,1.2038051582621179,1.2038051582621179,1.1035085671714049],\"xaxis\":\"x\",\"y\":[-372.5,-372.5,-535.0,-535.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[0.8728204273024374,1.3492926976040487,1.3492926976040487,1.2038051582621179],\"xaxis\":\"x\",\"y\":[-238.90625,-238.90625,-453.75,-453.75],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[1.1742289743526864,1.4073155319266266,1.4073155319266266,1.3492926976040487],\"xaxis\":\"x\",\"y\":[-94.3359375,-94.3359375,-346.328125,-346.328125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.0,0.3709201900521888,0.3709201900521888,0.0],\"xaxis\":\"x\",\"y\":[-615.0,-615.0,-625.0,-625.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.3709201900521888,0.5400259166338433,0.5400259166338433,0.0],\"xaxis\":\"x\",\"y\":[-620.0,-620.0,-635.0,-635.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.5400259166338433,0.7133149400794143,0.7133149400794143,0.0],\"xaxis\":\"x\",\"y\":[-627.5,-627.5,-645.0,-645.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,65,54)\"},\"mode\":\"lines\",\"x\":[0.0,0.7386665358754193,0.7386665358754193,0.7133149400794143],\"xaxis\":\"x\",\"y\":[-605.0,-605.0,-636.25,-636.25],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.0,0.4216973051870685,0.4216973051870685,0.0],\"xaxis\":\"x\",\"y\":[-665.0,-665.0,-675.0,-675.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.4216973051870685,0.6360893648112083,0.6360893648112083,0.0],\"xaxis\":\"x\",\"y\":[-670.0,-670.0,-685.0,-685.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.0,0.7516134734829509,0.7516134734829509,0.6360893648112083],\"xaxis\":\"x\",\"y\":[-655.0,-655.0,-677.5,-677.5],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.0,0.4779032346841411,0.4779032346841411,0.0],\"xaxis\":\"x\",\"y\":[-695.0,-695.0,-705.0,-705.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.4779032346841411,0.6195577697764846,0.6195577697764846,0.0],\"xaxis\":\"x\",\"y\":[-700.0,-700.0,-715.0,-715.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.6195577697764846,0.7118730658803832,0.7118730658803832,0.0],\"xaxis\":\"x\",\"y\":[-707.5,-707.5,-725.0,-725.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(35,205,205)\"},\"mode\":\"lines\",\"x\":[0.7516134734829509,0.8758663118832921,0.8758663118832921,0.7118730658803832],\"xaxis\":\"x\",\"y\":[-666.25,-666.25,-716.25,-716.25],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[0.7386665358754193,1.238772315074591,1.238772315074591,0.8758663118832921],\"xaxis\":\"x\",\"y\":[-620.625,-620.625,-691.25,-691.25],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.0,0.46043962824290874,0.46043962824290874,0.0],\"xaxis\":\"x\",\"y\":[-735.0,-735.0,-745.0,-745.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.46043962824290874,0.5172090507857865,0.5172090507857865,0.0],\"xaxis\":\"x\",\"y\":[-740.0,-740.0,-755.0,-755.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.0,0.5017263066205426,0.5017263066205426,0.0],\"xaxis\":\"x\",\"y\":[-765.0,-765.0,-775.0,-775.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.0,0.5545033334928768,0.5545033334928768,0.0],\"xaxis\":\"x\",\"y\":[-785.0,-785.0,-795.0,-795.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.5017263066205426,0.8856628027654684,0.8856628027654684,0.5545033334928768],\"xaxis\":\"x\",\"y\":[-770.0,-770.0,-790.0,-790.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(133,20,75)\"},\"mode\":\"lines\",\"x\":[0.5172090507857865,0.9885467377403794,0.9885467377403794,0.8856628027654684],\"xaxis\":\"x\",\"y\":[-747.5,-747.5,-780.0,-780.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,220,0)\"},\"mode\":\"lines\",\"x\":[0.0,0.5070153400685782,0.5070153400685782,0.0],\"xaxis\":\"x\",\"y\":[-815.0,-815.0,-825.0,-825.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,220,0)\"},\"mode\":\"lines\",\"x\":[0.0,0.6247726957457755,0.6247726957457755,0.5070153400685782],\"xaxis\":\"x\",\"y\":[-805.0,-805.0,-820.0,-820.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,220,0)\"},\"mode\":\"lines\",\"x\":[0.0,0.45771552904158164,0.45771552904158164,0.0],\"xaxis\":\"x\",\"y\":[-845.0,-845.0,-855.0,-855.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,220,0)\"},\"mode\":\"lines\",\"x\":[0.0,0.5874604815127721,0.5874604815127721,0.45771552904158164],\"xaxis\":\"x\",\"y\":[-835.0,-835.0,-850.0,-850.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(255,220,0)\"},\"mode\":\"lines\",\"x\":[0.6247726957457755,0.7758758851733425,0.7758758851733425,0.5874604815127721],\"xaxis\":\"x\",\"y\":[-812.5,-812.5,-842.5,-842.5],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.0,0.6605456198846501,0.6605456198846501,0.0],\"xaxis\":\"x\",\"y\":[-865.0,-865.0,-875.0,-875.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.0,0.5830951240038356,0.5830951240038356,0.0],\"xaxis\":\"x\",\"y\":[-895.0,-895.0,-905.0,-905.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.0,0.7495198405897804,0.7495198405897804,0.5830951240038356],\"xaxis\":\"x\",\"y\":[-885.0,-885.0,-900.0,-900.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.0,0.4802519052596901,0.4802519052596901,0.0],\"xaxis\":\"x\",\"y\":[-915.0,-915.0,-925.0,-925.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.7495198405897804,0.7696415789026828,0.7696415789026828,0.4802519052596901],\"xaxis\":\"x\",\"y\":[-892.5,-892.5,-920.0,-920.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.6605456198846501,0.8359192512681219,0.8359192512681219,0.7696415789026828],\"xaxis\":\"x\",\"y\":[-870.0,-870.0,-906.25,-906.25],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.0,0.5941368260709922,0.5941368260709922,0.0],\"xaxis\":\"x\",\"y\":[-945.0,-945.0,-955.0,-955.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.0,0.6991419142008823,0.6991419142008823,0.5941368260709922],\"xaxis\":\"x\",\"y\":[-935.0,-935.0,-950.0,-950.0],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(40,35,35)\"},\"mode\":\"lines\",\"x\":[0.8359192512681219,0.9814627135777299,0.9814627135777299,0.6991419142008823],\"xaxis\":\"x\",\"y\":[-888.125,-888.125,-942.5,-942.5],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[0.7758758851733425,1.0306106202174128,1.0306106202174128,0.9814627135777299],\"xaxis\":\"x\",\"y\":[-827.5,-827.5,-915.3125,-915.3125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[0.9885467377403794,1.2581119984920914,1.2581119984920914,1.0306106202174128],\"xaxis\":\"x\",\"y\":[-763.75,-763.75,-871.40625,-871.40625],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[1.238772315074591,1.5068314146711983,1.5068314146711983,1.2581119984920914],\"xaxis\":\"x\",\"y\":[-655.9375,-655.9375,-817.578125,-817.578125],\"yaxis\":\"y\",\"type\":\"scatter\"},{\"hoverinfo\":\"text\",\"marker\":{\"color\":\"rgb(0,116,217)\"},\"mode\":\"lines\",\"x\":[1.4073155319266266,1.9357734752360256,1.9357734752360256,1.5068314146711983],\"xaxis\":\"x\",\"y\":[-220.33203125,-220.33203125,-736.7578125,-736.7578125],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"autosize\":false,\"height\":1640,\"hovermode\":\"closest\",\"showlegend\":false,\"width\":1000,\"xaxis\":{\"mirror\":\"allticks\",\"rangemode\":\"tozero\",\"showgrid\":false,\"showline\":true,\"showticklabels\":true,\"ticks\":\"outside\",\"type\":\"linear\",\"zeroline\":false},\"yaxis\":{\"mirror\":\"allticks\",\"rangemode\":\"tozero\",\"showgrid\":false,\"showline\":true,\"showticklabels\":true,\"tickmode\":\"array\",\"ticks\":\"outside\",\"ticktext\":[\"80_code_cyclic_mathbb\",\"15_code_software_bug\",\"85_bias_gender_stereotype\",\"56_fairness_bias_fair\",\"67_explanation_feature_shap...\",\"52_ai_human_decision\",\"42_student_education_course\",\"64_citation_publication_sci...\",\"27_recommendation_item_user\",\"22_news_social_medium\",\"71_emotion_affective_emotio...\",\"73_metaverse_vr_virtual\",\"55_transformer_attention_la...\",\"92_sentence_embeddings_word\",\"45_dialogue_conversational_...\",\"13_language_translation_llm\",\"77_reasoning_cot_llm\",\"75_question_answer_qa\",\"76_retrieval_query_document\",\"91_summarization_summary_do...\",\"48_lidar_sensor_slam\",\"40_scene_nerf_view\",\"90_pose_human_motion\",\"16_video_frame_action\",\"5_speech_audio_speaker\",\"21_crop_image_remote\",\"3_image_segmentation_medical\",\"36_segmentation_transformer...\",\"14_image_visual_text\",\"9_image_diffusion_text\",\"89_image_restoration_degrad...\",\"34_fl_client_federated\",\"62_privacy_private_dp\",\"72_privacy_cybersecurity_cy...\",\"53_face_recognition_deepfake\",\"23_attack_adversarial_backd...\",\"83_iot_device_attack\",\"7_channel_communication_wir...\",\"87_edge_network_service\",\"17_memory_hardware_cache\",\"58_dnn_quantization_bit\",\"74_spiking_snns_snn\",\"86_neuron_neural_brain\",\"43_clinical_medical_biomedi...\",\"82_patient_survival_risk\",\"66_ecg_heart_cardiac\",\"35_brain_eeg_fmri\",\"49_gene_cell_genome\",\"41_protein_drug_molecule\",\"81_crystal_structure_atom\",\"51_continual_forgetting_lea...\",\"60_calibration_class_ensemble\",\"31_network_pruning_neural\",\"65_label_learning_noisy\",\"84_ssl_supervised_contrastive\",\"50_anomaly_detection_log\",\"79_clustering_cluster_algor...\",\"69_network_community_node\",\"18_graph_node_gnns\",\"6_graph_vertex_edge\",\"68_matroid_matroids_lattice\",\"11_random_stochastic_equation\",\"4_equation_mathbb_solution\",\"2_group_algebra_mathbb\",\"8_logic_proof_automaton\",\"93_entropy_thermodynamics_t...\",\"0_mass_star_galaxy\",\"1_quantum_state_spin\",\"46_oscillator_bifurcation_s...\",\"37_flow_turbulent_vortex\",\"44_droplet_flow_shear\",\"54_polymer_cell_active\",\"59_fracture_dislocation_str...\",\"63_robot_locomotion_control...\",\"29_robot_tactile_grasp\",\"78_robot_planning_path\",\"57_uav_uavs_aerial\",\"95_aerial_flight_control\",\"38_driving_vehicle_autonomous\",\"70_traffic_travel_mobility\",\"39_control_controller_distu...\",\"94_distributed_consensus_ag...\",\"32_optimization_convergence...\",\"88_inverse_problem_regulari...\",\"33_element_numerical_equation\",\"28_neural_equation_pdes\",\"20_blockchain_transaction_c...\",\"24_market_price_financial\",\"47_epidemic_infection_covid\",\"19_climate_forecast_forecas...\",\"12_power_grid_energy\",\"10_estimator_distribution_p...\",\"26_causal_treatment_effect\",\"61_bandit_regret_arm\",\"25_rl_policy_reward\",\"30_agent_game_nash\"],\"tickvals\":[-5.0,-15.0,-25.0,-35.0,-45.0,-55.0,-65.0,-75.0,-85.0,-95.0,-105.0,-115.0,-125.0,-135.0,-145.0,-155.0,-165.0,-175.0,-185.0,-195.0,-205.0,-215.0,-225.0,-235.0,-245.0,-255.0,-265.0,-275.0,-285.0,-295.0,-305.0,-315.0,-325.0,-335.0,-345.0,-355.0,-365.0,-375.0,-385.0,-395.0,-405.0,-415.0,-425.0,-435.0,-445.0,-455.0,-465.0,-475.0,-485.0,-495.0,-505.0,-515.0,-525.0,-535.0,-545.0,-555.0,-565.0,-575.0,-585.0,-595.0,-605.0,-615.0,-625.0,-635.0,-645.0,-655.0,-665.0,-675.0,-685.0,-695.0,-705.0,-715.0,-725.0,-735.0,-745.0,-755.0,-765.0,-775.0,-785.0,-795.0,-805.0,-815.0,-825.0,-835.0,-845.0,-855.0,-865.0,-875.0,-885.0,-895.0,-905.0,-915.0,-925.0,-935.0,-945.0,-955.0],\"type\":\"linear\",\"zeroline\":false,\"range\":[-960.0,0.0]},\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"title\":{\"font\":{\"size\":22,\"color\":\"Black\"},\"text\":\"\\u003cb\\u003eHierarchical Clustering\\u003c\\u002fb\\u003e\",\"x\":0.5,\"xanchor\":\"center\",\"yanchor\":\"top\"},\"hoverlabel\":{\"font\":{\"size\":16,\"family\":\"Rockwell\"},\"bgcolor\":\"white\"},\"plot_bgcolor\":\"#ECEFF1\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9f48e36e-9a53-432f-8022-4976314e2e79');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "topic_model.visualize_hierarchy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9J_hsGGVuFB"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "In this project, we successfully applied BERTopic to the **neuralwork/arxiver** dataset to uncover thematic clusters within research paper abstracts. The key findings include:\n",
        "\n",
        "- **Diverse Topic Distribution**: The dataset encompasses a wide range of scientific domains, reflected in the variety of identified topics.\n",
        "- **High-Confidence Assignments**: A significant number of papers were confidently categorized, indicating the effectiveness of BERTopic in discerning clear themes.\n",
        "- **Insightful Visualizations**: The intertopic distance map and top words per topic provide valuable insights into the relationships and nature of the topics.\n",
        "\n",
        "### Potential Applications\n",
        "\n",
        "- **Literature Review Automation**: Assisting researchers in quickly identifying relevant papers based on thematic clusters.\n",
        "- **Trend Analysis**: Monitoring the evolution of research topics over time to identify emerging areas of interest.\n",
        "- **Recommendation Systems**: Suggesting related papers or topics to researchers based on their areas of interest.\n",
        "\n",
        "### Future Work\n",
        "\n",
        "- **Fine-Tuning BERTopic**: Experimenting with different embedding models or hyperparameters to enhance topic coherence.\n",
        "- **Expanding the Dataset**: Incorporating more recent papers or additional datasets to broaden the scope of analysis.\n",
        "- **Interactive Visualizations**: Creating interactive dashboards for dynamic exploration of topics and their relationships.\n",
        "\n",
        "This project demonstrates the power of advanced topic modeling techniques like BERTopic in organizing and making sense of vast amounts of scientific literature.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM5WBBsJGdjrgy3g/+zLOxI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}